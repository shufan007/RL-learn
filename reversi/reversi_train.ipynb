{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4df7bb34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not fetch URL https://pypi.org/simple/sb3-contrib/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/sb3-contrib/ (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)'))) - skipping\n",
      "Could not fetch URL https://pypi.org/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)'))) - skipping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)'))': /simple/sb3-contrib/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)'))': /simple/sb3-contrib/\n",
      "WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)'))': /simple/sb3-contrib/\n",
      "WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)'))': /simple/sb3-contrib/\n",
      "WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLEOFError(8, 'EOF occurred in violation of protocol (_ssl.c:1125)'))': /simple/sb3-contrib/\n",
      "ERROR: Could not find a version that satisfies the requirement sb3-contrib\n",
      "ERROR: No matching distribution found for sb3-contrib\n"
     ]
    }
   ],
   "source": [
    "pip install sb3-contrib\n",
    "# 注意：如果安装失败，尝试关闭vpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ccedee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sb3_contrib import MaskablePPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1471504",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "415bd733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ec59c0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\apps\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py:38: UserWarning: It seems that your observation space  is an image but the upper and lower bounds are not in [0, 255]. Because the CNN policy normalize automatically the observation you may encounter issue if the values are not in that range.\n",
      "  warnings.warn(\n",
      "D:\\apps\\Anaconda3\\lib\\site-packages\\stable_baselines3\\common\\env_checker.py:51: UserWarning: The minimal resolution for an image is 36x36 for the default `CnnPolicy`. You might need to use a custom features extractor cf. https://stable-baselines3.readthedocs.io/en/master/guide/custom_policy.html\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "from gym_reversi import ReversiEnv\n",
    "\n",
    "env = ReversiEnv(player_color='black', opponent = \"random\", board_size=8)\n",
    "# It will check your custom environment and output additional warnings if needed\n",
    "check_env(env)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68c5a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "??make_vec_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7754847b",
   "metadata": {},
   "outputs": [],
   "source": [
    "??ActionMasker"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b252c64",
   "metadata": {},
   "source": [
    "### Maskable PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d05f812e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inplanes:4\n",
      "planes:64\n",
      "inplanes:64\n",
      "planes:64\n",
      "inplanes:64\n",
      "planes:128\n",
      "Logging to models/ppo_8x8_resnet_debug/PPO_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 30.1     |\n",
      "|    ep_rew_mean     | 0.5      |\n",
      "| time/              |          |\n",
      "|    fps             | 206      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 256      |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.375       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 141         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 512         |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.062315006 |\n",
      "|    clip_fraction        | 0.335       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.218       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0371     |\n",
      "|    n_updates            | 1568        |\n",
      "|    policy_gradient_loss | -0.0391     |\n",
      "|    value_loss           | 0.0327      |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.2       |\n",
      "|    ep_rew_mean          | 0.5        |\n",
      "| time/                   |            |\n",
      "|    fps                  | 128        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 5          |\n",
      "|    total_timesteps      | 768        |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.05087828 |\n",
      "|    clip_fraction        | 0.277      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.64      |\n",
      "|    explained_variance   | -0.158     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0456    |\n",
      "|    n_updates            | 1572       |\n",
      "|    policy_gradient_loss | -0.0388    |\n",
      "|    value_loss           | 0.0669     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.438       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 117         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 1024        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.039254464 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -0.345      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0835     |\n",
      "|    n_updates            | 1576        |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 0.0507      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.1        |\n",
      "|    ep_rew_mean          | 0.25        |\n",
      "| time/                   |             |\n",
      "|    fps                  | 114         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 1280        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.085992575 |\n",
      "|    clip_fraction        | 0.294       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | 0.212       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.103      |\n",
      "|    n_updates            | 1580        |\n",
      "|    policy_gradient_loss | -0.042      |\n",
      "|    value_loss           | 0.052       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.333       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 113         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 1536        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.047597714 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -0.413      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0572     |\n",
      "|    n_updates            | 1584        |\n",
      "|    policy_gradient_loss | -0.0452     |\n",
      "|    value_loss           | 0.0717      |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 30.2      |\n",
      "|    ep_rew_mean          | 0.321     |\n",
      "| time/                   |           |\n",
      "|    fps                  | 113       |\n",
      "|    iterations           | 7         |\n",
      "|    time_elapsed         | 15        |\n",
      "|    total_timesteps      | 1792      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0605711 |\n",
      "|    clip_fraction        | 0.369     |\n",
      "|    clip_range           | 0.2       |\n",
      "|    entropy_loss         | -1.58     |\n",
      "|    explained_variance   | -0.279    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.0476   |\n",
      "|    n_updates            | 1588      |\n",
      "|    policy_gradient_loss | -0.041    |\n",
      "|    value_loss           | 0.0564    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 30.2       |\n",
      "|    ep_rew_mean          | 0.354      |\n",
      "| time/                   |            |\n",
      "|    fps                  | 112        |\n",
      "|    iterations           | 8          |\n",
      "|    time_elapsed         | 18         |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06497264 |\n",
      "|    clip_fraction        | 0.301      |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -1.55      |\n",
      "|    explained_variance   | 0.107      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0832    |\n",
      "|    n_updates            | 1592       |\n",
      "|    policy_gradient_loss | -0.0382    |\n",
      "|    value_loss           | 0.0471     |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.355       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 109         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 20          |\n",
      "|    total_timesteps      | 2304        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.058455497 |\n",
      "|    clip_fraction        | 0.288       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | 0.442       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0535     |\n",
      "|    n_updates            | 1596        |\n",
      "|    policy_gradient_loss | -0.0434     |\n",
      "|    value_loss           | 0.0343      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 30.2        |\n",
      "|    ep_rew_mean          | 0.393       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 108         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 2560        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.063562684 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.62       |\n",
      "|    explained_variance   | 0.496       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0921     |\n",
      "|    n_updates            | 1600        |\n",
      "|    policy_gradient_loss | -0.0458     |\n",
      "|    value_loss           | 0.0279      |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-08982d8f4cb4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    119\u001b[0m \u001b[0mt0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;31m# model.learn(int(2e4))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_timesteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"train time: {time.time()-t0}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\apps\\Anaconda3\\lib\\site-packages\\sb3_contrib\\ppo_mask\\ppo_mask.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, use_masking, progress_bar)\u001b[0m\n\u001b[0;32m    545\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_timesteps\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    548\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[0mcallback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_training_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\apps\\Anaconda3\\lib\\site-packages\\sb3_contrib\\ppo_mask\\ppo_mask.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    446\u001b[0m                 \u001b[1;31m# Value loss using the TD(gae_lambda) target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m                 \u001b[0mvalue_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrollout_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalues_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m                 \u001b[0mvalue_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m                 \u001b[1;31m# Entropy loss favor exploration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# import sys\n",
    "import os\n",
    "# current_path = os.getcwd()\n",
    "# sys.path.append(current_path)\n",
    "import os\n",
    "import time\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.env_util import make_atari_env\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "# from stable_baselines3 import DQN, DDPG, A2C, PPO,SAC,TD3\n",
    "from stable_baselines3 import PPO\n",
    "from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy\n",
    "from sb3_contrib.common.wrappers import ActionMasker\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "\n",
    "import time\n",
    "from gym_reversi import ReversiEnv\n",
    "from custom_feature_extractor import CustomCNN\n",
    "\n",
    "t0=time.time()\n",
    "\n",
    "# There already exists an environment generator\n",
    "# that will make and wrap atari environments correctly.\n",
    "# Here we are also multi-worker training (n_envs=4 => 4 environments)\n",
    "# vec_env = make_atari_env(\"PongNoFrameskip-v4\", n_envs=4, seed=0)\n",
    "# env = make_atari_env(\"BreakoutNoFrameskip-v4\", seed=0)\n",
    "# vec_env = make_atari_env(\"BreakoutNoFrameskip-v4\", n_envs=4, \n",
    "# #                          seed=0\n",
    "#                         )\n",
    "# # Frame-stacking with 4 frames\n",
    "# vec_env = VecFrameStack(vec_env, n_stack=4)\n",
    "\n",
    "def mask_fn(env: gym.Env) -> np.ndarray:\n",
    "    # Do whatever you'd like in this function to return the action mask\n",
    "    # for the current env. In this example, we assume the env has a\n",
    "    # helpful method we can rely on.\n",
    "    return env.valid_action_mask()\n",
    "\n",
    "backbone= 'resnet'\n",
    "# backbone= 'cnn'\n",
    "\n",
    "\n",
    "board_size=8\n",
    "total_timesteps=10_0000\n",
    "# PolicyModel = PPO\n",
    "PolicyModel = MaskablePPO\n",
    "# PolicyModel = TD3\n",
    "n_envs = 4\n",
    "\n",
    "greedy_rate=0\n",
    "verbose = 0\n",
    "\n",
    "tensorboard_log = f\"models/ppo_{board_size}x{board_size}_{backbone}_debug/\"\n",
    "if not os.path.isdir(tensorboard_log):\n",
    "    os.makedirs(tensorboard_log)\n",
    "model_path = os.path.join(tensorboard_log, \"model\")\n",
    "opponent_model_path=\"random\"\n",
    "# opponent_model_path=os.path.join(tensorboard_log, \"opponent_model\")\n",
    "\n",
    "\n",
    "if opponent_model_path != \"random\":\n",
    "    opponent_model = PolicyModel.load(opponent_model_path)\n",
    "else:\n",
    "    opponent_model = \"random\"\n",
    "\n",
    "env = ReversiEnv(opponent=opponent_model, is_train=True, board_size=board_size, n_channels=4,\n",
    "                 greedy_rate=greedy_rate, verbose=verbose)\n",
    "\n",
    "# env = ActionMasker(env, mask_fn)  # Wrap to enable masking\n",
    "\n",
    "vec_env = env\n",
    "if n_envs > 1:\n",
    "    # multi-worker training (n_envs=4 => 4 environments)\n",
    "    vec_env = make_vec_env(ReversiEnv, n_envs=n_envs, seed=None,\n",
    "                           env_kwargs={\n",
    "                               \"opponent\": opponent_model,\n",
    "                               \"is_train\": True,\n",
    "                               \"board_size\": board_size,\n",
    "                               \"greedy_rate\": greedy_rate,\n",
    "                               \"verbose\": verbose},\n",
    "                        )\n",
    "\n",
    "    \n",
    "policy_kwargs = dict(\n",
    "    features_extractor_class=CustomCNN,\n",
    "    features_extractor_kwargs=dict(features_dim=256,\n",
    "                                   backbone=backbone,\n",
    "                                   net_arch=[64, 64, 128],\n",
    "#                                    net_arch=[32, 64, 64],\n",
    "                                   kernel_size=3, \n",
    "                                   stride=1, \n",
    "                                   padding='same', \n",
    "                                   is_batch_norm=False),\n",
    "    net_arch=[256, 256], \n",
    "    normalize_images=False\n",
    ")\n",
    "    \n",
    "try:\n",
    "    model = PolicyModel.load(model_path, env=vec_env)\n",
    "except Exception:\n",
    "    print(f\"load model from self.model_path: {model_path} error\")\n",
    "    model = PolicyModel(MaskableActorCriticPolicy, vec_env,\n",
    "                  policy_kwargs=policy_kwargs,\n",
    "                  learning_rate=2.5e-4,  # learning_rate=2.5e-4,\n",
    "                  ent_coef=0.01,\n",
    "                  n_steps=64, # n_steps=128,\n",
    "                  n_epochs=4,\n",
    "                  batch_size=32, # batch_size=256,\n",
    "                  gamma=0.9,\n",
    "                  gae_lambda=0.9,\n",
    "                  clip_range=0.2,\n",
    "                  vf_coef=0.5,\n",
    "                  verbose=1,\n",
    "                  tensorboard_log=tensorboard_log)\n",
    "\n",
    "t0 = time.time()\n",
    "# model.learn(int(2e4))\n",
    "model.learn(total_timesteps=total_timesteps)\n",
    "model.save(model_path)\n",
    "print(f\"train time: {time.time()-t0}\")\n",
    "\n",
    "# vec_env = make_atari_env(\"BreakoutNoFrameskip-v4\", n_envs=1)\n",
    "# vec_env = VecFrameStack(vec_env, n_stack=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cda6dfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e254047",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensorboard --logdir ./reversi/models/Reversi_ppo/PPO_7/ --port=6016"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e676a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "PolicyModel = PPO\n",
    "\n",
    "model_path = \"models/ppo_8x8_cnn/model_1480w\"\n",
    "# model_path = \"models/model_460w\"\n",
    "state_dict_path = model_path + '_state_dict.pt'\n",
    "\n",
    "sb3_model = PolicyModel.load(model_path)\n",
    "\n",
    "torch.save(sb3_model.policy.state_dict(), state_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffeb0a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from model_deploy.policies import CustomCNN, ActorCriticPolicy\n",
    "\n",
    "\n",
    "features_extractor_kwargs=dict(features_dim=256,\n",
    "#                                net_arch=[64, 128, 256],\n",
    "                               # net_arch=[64, 128, 128],\n",
    "#                                net_arch=[32, 64, 128],\n",
    "                               net_arch=[32, 64, 64],\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding='same',\n",
    "                               is_batch_norm=False\n",
    "                               )\n",
    "\n",
    "observation_space=(4, 8, 8)\n",
    "action_space = [observation_space[1]*observation_space[2]]\n",
    "\n",
    "policy_model = ActorCriticPolicy(\n",
    "        observation_space=observation_space, \n",
    "        action_space=action_space, \n",
    "        net_arch=[256, 256],\n",
    "        features_extractor_class = CustomCNN,\n",
    "        features_extractor_kwargs = features_extractor_kwargs,\n",
    "        share_features_extractor = True,\n",
    "    normalize_images=False\n",
    "\n",
    ")\n",
    "\n",
    "# model_path = \"models/ppo_8x8_cnn/model\"\n",
    "model_path = \"models/ppo_8x8_cnn/model_1480w\"\n",
    "# model_path = \"models/model_460w\"\n",
    "\n",
    "# model_path = \"models/model\"\n",
    "state_dict_path = model_path + '_state_dict.pt'\n",
    "\n",
    "policy_model.load_state_dict(torch.load(state_dict_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "19a7cd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): CustomCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): CustomCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): CustomCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6a84bdc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_model.load_state_dict(torch.load(\"models/ppo_8x8_cnn/model_1480w_state_dict.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "247244ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- round:0 --------\n",
      "total_win:0, total_failure: 1, total_equal:0\n",
      "\n",
      "\n",
      "---- round:1 --------\n",
      "total_win:1, total_failure: 1, total_equal:0\n",
      "\n",
      "\n",
      "---- round:2 --------\n",
      "total_win:2, total_failure: 1, total_equal:0\n",
      "\n",
      "\n",
      "---- round:3 --------\n",
      "total_win:3, total_failure: 1, total_equal:0\n",
      "\n",
      "\n",
      "---- round:4 --------\n",
      "total_win:4, total_failure: 1, total_equal:0\n",
      "\n",
      "\n",
      "---- round:5 --------\n",
      "total_win:5, total_failure: 1, total_equal:0\n",
      "\n",
      "\n",
      "---- round:6 --------\n",
      "total_win:5, total_failure: 2, total_equal:0\n",
      "\n",
      "\n",
      "---- round:7 --------\n",
      "total_win:6, total_failure: 2, total_equal:0\n",
      "\n",
      "\n",
      "---- round:8 --------\n",
      "total_win:6, total_failure: 3, total_equal:0\n",
      "\n",
      "\n",
      "---- round:9 --------\n",
      "total_win:7, total_failure: 3, total_equal:0\n",
      "\n",
      "\n",
      "---- round:10 --------\n",
      "total_win:8, total_failure: 3, total_equal:0\n",
      "\n",
      "\n",
      "---- round:11 --------\n",
      "total_win:8, total_failure: 4, total_equal:0\n",
      "\n",
      "\n",
      "---- round:12 --------\n",
      "total_win:9, total_failure: 4, total_equal:0\n",
      "\n",
      "\n",
      "---- round:13 --------\n",
      "total_win:10, total_failure: 4, total_equal:0\n",
      "\n",
      "\n",
      "---- round:14 --------\n",
      "total_win:11, total_failure: 4, total_equal:0\n",
      "\n",
      "\n",
      "---- round:15 --------\n",
      "total_win:11, total_failure: 4, total_equal:1\n",
      "\n",
      "\n",
      "---- round:16 --------\n",
      "total_win:12, total_failure: 4, total_equal:1\n",
      "\n",
      "\n",
      "---- round:17 --------\n",
      "total_win:12, total_failure: 5, total_equal:1\n",
      "\n",
      "\n",
      "---- round:18 --------\n",
      "total_win:12, total_failure: 6, total_equal:1\n",
      "\n",
      "\n",
      "---- round:19 --------\n",
      "total_win:13, total_failure: 6, total_equal:1\n",
      "\n",
      "\n",
      "---- round:20 --------\n",
      "total_win:13, total_failure: 7, total_equal:1\n",
      "\n",
      "\n",
      "---- round:21 --------\n",
      "total_win:13, total_failure: 7, total_equal:2\n",
      "\n",
      "\n",
      "---- round:22 --------\n",
      "total_win:14, total_failure: 7, total_equal:2\n",
      "\n",
      "\n",
      "---- round:23 --------\n",
      "total_win:15, total_failure: 7, total_equal:2\n",
      "\n",
      "\n",
      "---- round:24 --------\n",
      "total_win:16, total_failure: 7, total_equal:2\n",
      "\n",
      "\n",
      "---- round:25 --------\n",
      "total_win:17, total_failure: 7, total_equal:2\n",
      "\n",
      "\n",
      "---- round:26 --------\n",
      "total_win:18, total_failure: 7, total_equal:2\n",
      "\n",
      "\n",
      "---- round:27 --------\n",
      "total_win:18, total_failure: 8, total_equal:2\n",
      "\n",
      "\n",
      "---- round:28 --------\n",
      "total_win:18, total_failure: 9, total_equal:2\n",
      "\n",
      "\n",
      "---- round:29 --------\n",
      "total_win:19, total_failure: 9, total_equal:2\n",
      "\n",
      "\n",
      "---- round:30 --------\n",
      "total_win:20, total_failure: 9, total_equal:2\n",
      "\n",
      "\n",
      "---- round:31 --------\n",
      "total_win:20, total_failure: 10, total_equal:2\n",
      "\n",
      "\n",
      "---- round:32 --------\n",
      "total_win:21, total_failure: 10, total_equal:2\n",
      "\n",
      "\n",
      "---- round:33 --------\n",
      "total_win:22, total_failure: 10, total_equal:2\n",
      "\n",
      "\n",
      "---- round:34 --------\n",
      "total_win:22, total_failure: 11, total_equal:2\n",
      "\n",
      "\n",
      "---- round:35 --------\n",
      "total_win:22, total_failure: 12, total_equal:2\n",
      "\n",
      "\n",
      "---- round:36 --------\n",
      "total_win:22, total_failure: 13, total_equal:2\n",
      "\n",
      "\n",
      "---- round:37 --------\n",
      "total_win:22, total_failure: 14, total_equal:2\n",
      "\n",
      "\n",
      "---- round:38 --------\n",
      "total_win:23, total_failure: 14, total_equal:2\n",
      "\n",
      "\n",
      "---- round:39 --------\n",
      "total_win:23, total_failure: 15, total_equal:2\n",
      "\n",
      "\n",
      "---- round:40 --------\n",
      "total_win:24, total_failure: 15, total_equal:2\n",
      "\n",
      "\n",
      "---- round:41 --------\n",
      "total_win:25, total_failure: 15, total_equal:2\n",
      "\n",
      "\n",
      "---- round:42 --------\n",
      "total_win:25, total_failure: 16, total_equal:2\n",
      "\n",
      "\n",
      "---- round:43 --------\n",
      "total_win:26, total_failure: 16, total_equal:2\n",
      "\n",
      "\n",
      "---- round:44 --------\n",
      "total_win:27, total_failure: 16, total_equal:2\n",
      "\n",
      "\n",
      "---- round:45 --------\n",
      "total_win:28, total_failure: 16, total_equal:2\n",
      "\n",
      "\n",
      "---- round:46 --------\n",
      "total_win:29, total_failure: 16, total_equal:2\n",
      "\n",
      "\n",
      "---- round:47 --------\n",
      "total_win:30, total_failure: 16, total_equal:2\n",
      "\n",
      "\n",
      "---- round:48 --------\n",
      "total_win:30, total_failure: 17, total_equal:2\n",
      "\n",
      "\n",
      "---- round:49 --------\n",
      "total_win:30, total_failure: 18, total_equal:2\n",
      "\n",
      "\n",
      "---- round:50 --------\n",
      "total_win:30, total_failure: 19, total_equal:2\n",
      "\n",
      "\n",
      "---- round:51 --------\n",
      "total_win:31, total_failure: 19, total_equal:2\n",
      "\n",
      "\n",
      "---- round:52 --------\n",
      "total_win:32, total_failure: 19, total_equal:2\n",
      "\n",
      "\n",
      "---- round:53 --------\n",
      "total_win:33, total_failure: 19, total_equal:2\n",
      "\n",
      "\n",
      "---- round:54 --------\n",
      "total_win:33, total_failure: 20, total_equal:2\n",
      "\n",
      "\n",
      "---- round:55 --------\n",
      "total_win:34, total_failure: 20, total_equal:2\n",
      "\n",
      "\n",
      "---- round:56 --------\n",
      "total_win:34, total_failure: 21, total_equal:2\n",
      "\n",
      "\n",
      "---- round:57 --------\n",
      "total_win:35, total_failure: 21, total_equal:2\n",
      "\n",
      "\n",
      "---- round:58 --------\n",
      "total_win:36, total_failure: 21, total_equal:2\n",
      "\n",
      "\n",
      "---- round:59 --------\n",
      "total_win:36, total_failure: 22, total_equal:2\n",
      "\n",
      "\n",
      "---- round:60 --------\n",
      "total_win:37, total_failure: 22, total_equal:2\n",
      "\n",
      "\n",
      "---- round:61 --------\n",
      "total_win:37, total_failure: 23, total_equal:2\n",
      "\n",
      "\n",
      "---- round:62 --------\n",
      "total_win:37, total_failure: 24, total_equal:2\n",
      "\n",
      "\n",
      "---- round:63 --------\n",
      "total_win:38, total_failure: 24, total_equal:2\n",
      "\n",
      "\n",
      "---- round:64 --------\n",
      "total_win:38, total_failure: 25, total_equal:2\n",
      "\n",
      "\n",
      "---- round:65 --------\n",
      "total_win:38, total_failure: 26, total_equal:2\n",
      "\n",
      "\n",
      "---- round:66 --------\n",
      "total_win:38, total_failure: 26, total_equal:3\n",
      "\n",
      "\n",
      "---- round:67 --------\n",
      "total_win:39, total_failure: 26, total_equal:3\n",
      "\n",
      "\n",
      "---- round:68 --------\n",
      "total_win:39, total_failure: 27, total_equal:3\n",
      "\n",
      "\n",
      "---- round:69 --------\n",
      "total_win:39, total_failure: 28, total_equal:3\n",
      "\n",
      "\n",
      "---- round:70 --------\n",
      "total_win:39, total_failure: 29, total_equal:3\n",
      "\n",
      "\n",
      "---- round:71 --------\n",
      "total_win:40, total_failure: 29, total_equal:3\n",
      "\n",
      "\n",
      "---- round:72 --------\n",
      "total_win:41, total_failure: 29, total_equal:3\n",
      "\n",
      "\n",
      "---- round:73 --------\n",
      "total_win:42, total_failure: 29, total_equal:3\n",
      "\n",
      "\n",
      "---- round:74 --------\n",
      "total_win:43, total_failure: 29, total_equal:3\n",
      "\n",
      "\n",
      "---- round:75 --------\n",
      "total_win:44, total_failure: 29, total_equal:3\n",
      "\n",
      "\n",
      "---- round:76 --------\n",
      "total_win:45, total_failure: 29, total_equal:3\n",
      "\n",
      "\n",
      "---- round:77 --------\n",
      "total_win:46, total_failure: 29, total_equal:3\n",
      "\n",
      "\n",
      "---- round:78 --------\n",
      "total_win:46, total_failure: 30, total_equal:3\n",
      "\n",
      "\n",
      "---- round:79 --------\n",
      "total_win:46, total_failure: 31, total_equal:3\n",
      "\n",
      "\n",
      "---- round:80 --------\n",
      "total_win:47, total_failure: 31, total_equal:3\n",
      "\n",
      "\n",
      "---- round:81 --------\n",
      "total_win:48, total_failure: 31, total_equal:3\n",
      "\n",
      "\n",
      "---- round:82 --------\n",
      "total_win:48, total_failure: 32, total_equal:3\n",
      "\n",
      "\n",
      "---- round:83 --------\n",
      "total_win:49, total_failure: 32, total_equal:3\n",
      "\n",
      "\n",
      "---- round:84 --------\n",
      "total_win:49, total_failure: 33, total_equal:3\n",
      "\n",
      "\n",
      "---- round:85 --------\n",
      "total_win:50, total_failure: 33, total_equal:3\n",
      "\n",
      "\n",
      "---- round:86 --------\n",
      "total_win:51, total_failure: 33, total_equal:3\n",
      "\n",
      "\n",
      "---- round:87 --------\n",
      "total_win:52, total_failure: 33, total_equal:3\n",
      "\n",
      "\n",
      "---- round:88 --------\n",
      "total_win:53, total_failure: 33, total_equal:3\n",
      "\n",
      "\n",
      "---- round:89 --------\n",
      "total_win:54, total_failure: 33, total_equal:3\n",
      "\n",
      "\n",
      "---- round:90 --------\n",
      "total_win:55, total_failure: 33, total_equal:3\n",
      "\n",
      "\n",
      "---- round:91 --------\n",
      "total_win:56, total_failure: 33, total_equal:3\n",
      "\n",
      "\n",
      "---- round:92 --------\n",
      "total_win:56, total_failure: 34, total_equal:3\n",
      "\n",
      "\n",
      "---- round:93 --------\n",
      "total_win:57, total_failure: 34, total_equal:3\n",
      "\n",
      "\n",
      "---- round:94 --------\n",
      "total_win:58, total_failure: 34, total_equal:3\n",
      "\n",
      "\n",
      "---- round:95 --------\n",
      "total_win:58, total_failure: 35, total_equal:3\n",
      "\n",
      "\n",
      "---- round:96 --------\n",
      "total_win:59, total_failure: 35, total_equal:3\n",
      "\n",
      "\n",
      "---- round:97 --------\n",
      "total_win:60, total_failure: 35, total_equal:3\n",
      "\n",
      "\n",
      "---- round:98 --------\n",
      "total_win:61, total_failure: 35, total_equal:3\n",
      "\n",
      "\n",
      "---- round:99 --------\n",
      "total_win:62, total_failure: 35, total_equal:3\n",
      "\n",
      "\n",
      "---- round:100 --------\n",
      "total_win:63, total_failure: 35, total_equal:3\n",
      "\n",
      "\n",
      "---- round:101 --------\n",
      "total_win:64, total_failure: 35, total_equal:3\n",
      "\n",
      "\n",
      "---- round:102 --------\n",
      "total_win:64, total_failure: 36, total_equal:3\n",
      "\n",
      "\n",
      "---- round:103 --------\n",
      "total_win:65, total_failure: 36, total_equal:3\n",
      "\n",
      "\n",
      "---- round:104 --------\n",
      "total_win:66, total_failure: 36, total_equal:3\n",
      "\n",
      "\n",
      "---- round:105 --------\n",
      "total_win:66, total_failure: 37, total_equal:3\n",
      "\n",
      "\n",
      "---- round:106 --------\n",
      "total_win:67, total_failure: 37, total_equal:3\n",
      "\n",
      "\n",
      "---- round:107 --------\n",
      "total_win:68, total_failure: 37, total_equal:3\n",
      "\n",
      "\n",
      "---- round:108 --------\n",
      "total_win:69, total_failure: 37, total_equal:3\n",
      "\n",
      "\n",
      "---- round:109 --------\n",
      "total_win:69, total_failure: 38, total_equal:3\n",
      "\n",
      "\n",
      "---- round:110 --------\n",
      "total_win:69, total_failure: 39, total_equal:3\n",
      "\n",
      "\n",
      "---- round:111 --------\n",
      "total_win:70, total_failure: 39, total_equal:3\n",
      "\n",
      "\n",
      "---- round:112 --------\n",
      "total_win:70, total_failure: 40, total_equal:3\n",
      "\n",
      "\n",
      "---- round:113 --------\n",
      "total_win:71, total_failure: 40, total_equal:3\n",
      "\n",
      "\n",
      "---- round:114 --------\n",
      "total_win:72, total_failure: 40, total_equal:3\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- round:115 --------\n",
      "total_win:72, total_failure: 41, total_equal:3\n",
      "\n",
      "\n",
      "---- round:116 --------\n",
      "total_win:73, total_failure: 41, total_equal:3\n",
      "\n",
      "\n",
      "---- round:117 --------\n",
      "total_win:74, total_failure: 41, total_equal:3\n",
      "\n",
      "\n",
      "---- round:118 --------\n",
      "total_win:75, total_failure: 41, total_equal:3\n",
      "\n",
      "\n",
      "---- round:119 --------\n",
      "total_win:75, total_failure: 41, total_equal:4\n",
      "\n",
      "\n",
      "---- round:120 --------\n",
      "total_win:76, total_failure: 41, total_equal:4\n",
      "\n",
      "\n",
      "---- round:121 --------\n",
      "total_win:76, total_failure: 42, total_equal:4\n",
      "\n",
      "\n",
      "---- round:122 --------\n",
      "total_win:76, total_failure: 43, total_equal:4\n",
      "\n",
      "\n",
      "---- round:123 --------\n",
      "total_win:77, total_failure: 43, total_equal:4\n",
      "\n",
      "\n",
      "---- round:124 --------\n",
      "total_win:77, total_failure: 43, total_equal:5\n",
      "\n",
      "\n",
      "---- round:125 --------\n",
      "total_win:77, total_failure: 44, total_equal:5\n",
      "\n",
      "\n",
      "---- round:126 --------\n",
      "total_win:77, total_failure: 45, total_equal:5\n",
      "\n",
      "\n",
      "---- round:127 --------\n",
      "total_win:77, total_failure: 46, total_equal:5\n",
      "\n",
      "\n",
      "---- round:128 --------\n",
      "total_win:78, total_failure: 46, total_equal:5\n",
      "\n",
      "\n",
      "---- round:129 --------\n",
      "total_win:79, total_failure: 46, total_equal:5\n",
      "\n",
      "\n",
      "---- round:130 --------\n",
      "total_win:80, total_failure: 46, total_equal:5\n",
      "\n",
      "\n",
      "---- round:131 --------\n",
      "total_win:81, total_failure: 46, total_equal:5\n",
      "\n",
      "\n",
      "---- round:132 --------\n",
      "total_win:82, total_failure: 46, total_equal:5\n",
      "\n",
      "\n",
      "---- round:133 --------\n",
      "total_win:83, total_failure: 46, total_equal:5\n",
      "\n",
      "\n",
      "---- round:134 --------\n",
      "total_win:83, total_failure: 47, total_equal:5\n",
      "\n",
      "\n",
      "---- round:135 --------\n",
      "total_win:83, total_failure: 48, total_equal:5\n",
      "\n",
      "\n",
      "---- round:136 --------\n",
      "total_win:84, total_failure: 48, total_equal:5\n",
      "\n",
      "\n",
      "---- round:137 --------\n",
      "total_win:85, total_failure: 48, total_equal:5\n",
      "\n",
      "\n",
      "---- round:138 --------\n",
      "total_win:85, total_failure: 48, total_equal:6\n",
      "\n",
      "\n",
      "---- round:139 --------\n",
      "total_win:85, total_failure: 49, total_equal:6\n",
      "\n",
      "\n",
      "---- round:140 --------\n",
      "total_win:86, total_failure: 49, total_equal:6\n",
      "\n",
      "\n",
      "---- round:141 --------\n",
      "total_win:87, total_failure: 49, total_equal:6\n",
      "\n",
      "\n",
      "---- round:142 --------\n",
      "total_win:88, total_failure: 49, total_equal:6\n",
      "\n",
      "\n",
      "---- round:143 --------\n",
      "total_win:89, total_failure: 49, total_equal:6\n",
      "\n",
      "\n",
      "---- round:144 --------\n",
      "total_win:90, total_failure: 49, total_equal:6\n",
      "\n",
      "\n",
      "---- round:145 --------\n",
      "total_win:91, total_failure: 49, total_equal:6\n",
      "\n",
      "\n",
      "---- round:146 --------\n",
      "total_win:91, total_failure: 50, total_equal:6\n",
      "\n",
      "\n",
      "---- round:147 --------\n",
      "total_win:92, total_failure: 50, total_equal:6\n",
      "\n",
      "\n",
      "---- round:148 --------\n",
      "total_win:93, total_failure: 50, total_equal:6\n",
      "\n",
      "\n",
      "---- round:149 --------\n",
      "total_win:93, total_failure: 51, total_equal:6\n",
      "\n",
      "\n",
      "---- round:150 --------\n",
      "total_win:94, total_failure: 51, total_equal:6\n",
      "\n",
      "\n",
      "---- round:151 --------\n",
      "total_win:95, total_failure: 51, total_equal:6\n",
      "\n",
      "\n",
      "---- round:152 --------\n",
      "total_win:95, total_failure: 51, total_equal:7\n",
      "\n",
      "\n",
      "---- round:153 --------\n",
      "total_win:96, total_failure: 51, total_equal:7\n",
      "\n",
      "\n",
      "---- round:154 --------\n",
      "total_win:96, total_failure: 52, total_equal:7\n",
      "\n",
      "\n",
      "---- round:155 --------\n",
      "total_win:96, total_failure: 53, total_equal:7\n",
      "\n",
      "\n",
      "---- round:156 --------\n",
      "total_win:97, total_failure: 53, total_equal:7\n",
      "\n",
      "\n",
      "---- round:157 --------\n",
      "total_win:97, total_failure: 54, total_equal:7\n",
      "\n",
      "\n",
      "---- round:158 --------\n",
      "total_win:97, total_failure: 54, total_equal:8\n",
      "\n",
      "\n",
      "---- round:159 --------\n",
      "total_win:98, total_failure: 54, total_equal:8\n",
      "\n",
      "\n",
      "---- round:160 --------\n",
      "total_win:98, total_failure: 55, total_equal:8\n",
      "\n",
      "\n",
      "---- round:161 --------\n",
      "total_win:98, total_failure: 56, total_equal:8\n",
      "\n",
      "\n",
      "---- round:162 --------\n",
      "total_win:99, total_failure: 56, total_equal:8\n",
      "\n",
      "\n",
      "---- round:163 --------\n",
      "total_win:99, total_failure: 57, total_equal:8\n",
      "\n",
      "\n",
      "---- round:164 --------\n",
      "total_win:100, total_failure: 57, total_equal:8\n",
      "\n",
      "\n",
      "---- round:165 --------\n",
      "total_win:101, total_failure: 57, total_equal:8\n",
      "\n",
      "\n",
      "---- round:166 --------\n",
      "total_win:102, total_failure: 57, total_equal:8\n",
      "\n",
      "\n",
      "---- round:167 --------\n",
      "total_win:103, total_failure: 57, total_equal:8\n",
      "\n",
      "\n",
      "---- round:168 --------\n",
      "total_win:103, total_failure: 58, total_equal:8\n",
      "\n",
      "\n",
      "---- round:169 --------\n",
      "total_win:104, total_failure: 58, total_equal:8\n",
      "\n",
      "\n",
      "---- round:170 --------\n",
      "total_win:104, total_failure: 59, total_equal:8\n",
      "\n",
      "\n",
      "---- round:171 --------\n",
      "total_win:105, total_failure: 59, total_equal:8\n",
      "\n",
      "\n",
      "---- round:172 --------\n",
      "total_win:106, total_failure: 59, total_equal:8\n",
      "\n",
      "\n",
      "---- round:173 --------\n",
      "total_win:107, total_failure: 59, total_equal:8\n",
      "\n",
      "\n",
      "---- round:174 --------\n",
      "total_win:107, total_failure: 60, total_equal:8\n",
      "\n",
      "\n",
      "---- round:175 --------\n",
      "total_win:107, total_failure: 61, total_equal:8\n",
      "\n",
      "\n",
      "---- round:176 --------\n",
      "total_win:107, total_failure: 62, total_equal:8\n",
      "\n",
      "\n",
      "---- round:177 --------\n",
      "total_win:108, total_failure: 62, total_equal:8\n",
      "\n",
      "\n",
      "---- round:178 --------\n",
      "total_win:109, total_failure: 62, total_equal:8\n",
      "\n",
      "\n",
      "---- round:179 --------\n",
      "total_win:109, total_failure: 62, total_equal:9\n",
      "\n",
      "\n",
      "---- round:180 --------\n",
      "total_win:110, total_failure: 62, total_equal:9\n",
      "\n",
      "\n",
      "---- round:181 --------\n",
      "total_win:111, total_failure: 62, total_equal:9\n",
      "\n",
      "\n",
      "---- round:182 --------\n",
      "total_win:112, total_failure: 62, total_equal:9\n",
      "\n",
      "\n",
      "---- round:183 --------\n",
      "total_win:113, total_failure: 62, total_equal:9\n",
      "\n",
      "\n",
      "---- round:184 --------\n",
      "total_win:114, total_failure: 62, total_equal:9\n",
      "\n",
      "\n",
      "---- round:185 --------\n",
      "total_win:115, total_failure: 62, total_equal:9\n",
      "\n",
      "\n",
      "---- round:186 --------\n",
      "total_win:116, total_failure: 62, total_equal:9\n",
      "\n",
      "\n",
      "---- round:187 --------\n",
      "total_win:117, total_failure: 62, total_equal:9\n",
      "\n",
      "\n",
      "---- round:188 --------\n",
      "total_win:118, total_failure: 62, total_equal:9\n",
      "\n",
      "\n",
      "---- round:189 --------\n",
      "total_win:118, total_failure: 63, total_equal:9\n",
      "\n",
      "\n",
      "---- round:190 --------\n",
      "total_win:119, total_failure: 63, total_equal:9\n",
      "\n",
      "\n",
      "---- round:191 --------\n",
      "total_win:120, total_failure: 63, total_equal:9\n",
      "\n",
      "\n",
      "---- round:192 --------\n",
      "total_win:120, total_failure: 64, total_equal:9\n",
      "\n",
      "\n",
      "---- round:193 --------\n",
      "total_win:120, total_failure: 65, total_equal:9\n",
      "\n",
      "\n",
      "---- round:194 --------\n",
      "total_win:121, total_failure: 65, total_equal:9\n",
      "\n",
      "\n",
      "---- round:195 --------\n",
      "total_win:121, total_failure: 66, total_equal:9\n",
      "\n",
      "\n",
      "---- round:196 --------\n",
      "total_win:121, total_failure: 67, total_equal:9\n",
      "\n",
      "\n",
      "---- round:197 --------\n",
      "total_win:122, total_failure: 67, total_equal:9\n",
      "\n",
      "\n",
      "---- round:198 --------\n",
      "total_win:122, total_failure: 68, total_equal:9\n",
      "\n",
      "\n",
      "---- round:199 --------\n",
      "total_win:123, total_failure: 68, total_equal:9\n",
      "\n",
      "\n",
      "---- round:200 --------\n",
      "total_win:123, total_failure: 69, total_equal:9\n",
      "\n",
      "\n",
      "---- round:201 --------\n",
      "total_win:123, total_failure: 70, total_equal:9\n",
      "\n",
      "\n",
      "---- round:202 --------\n",
      "total_win:123, total_failure: 71, total_equal:9\n",
      "\n",
      "\n",
      "---- round:203 --------\n",
      "total_win:123, total_failure: 72, total_equal:9\n",
      "\n",
      "\n",
      "---- round:204 --------\n",
      "total_win:123, total_failure: 73, total_equal:9\n",
      "\n",
      "\n",
      "---- round:205 --------\n",
      "total_win:123, total_failure: 74, total_equal:9\n",
      "\n",
      "\n",
      "---- round:206 --------\n",
      "total_win:124, total_failure: 74, total_equal:9\n",
      "\n",
      "\n",
      "---- round:207 --------\n",
      "total_win:124, total_failure: 75, total_equal:9\n",
      "\n",
      "\n",
      "---- round:208 --------\n",
      "total_win:125, total_failure: 75, total_equal:9\n",
      "\n",
      "\n",
      "---- round:209 --------\n",
      "total_win:125, total_failure: 76, total_equal:9\n",
      "\n",
      "\n",
      "---- round:210 --------\n",
      "total_win:126, total_failure: 76, total_equal:9\n",
      "\n",
      "\n",
      "---- round:211 --------\n",
      "total_win:127, total_failure: 76, total_equal:9\n",
      "\n",
      "\n",
      "---- round:212 --------\n",
      "total_win:127, total_failure: 77, total_equal:9\n",
      "\n",
      "\n",
      "---- round:213 --------\n",
      "total_win:127, total_failure: 78, total_equal:9\n",
      "\n",
      "\n",
      "---- round:214 --------\n",
      "total_win:128, total_failure: 78, total_equal:9\n",
      "\n",
      "\n",
      "---- round:215 --------\n",
      "total_win:129, total_failure: 78, total_equal:9\n",
      "\n",
      "\n",
      "---- round:216 --------\n",
      "total_win:129, total_failure: 79, total_equal:9\n",
      "\n",
      "\n",
      "---- round:217 --------\n",
      "total_win:129, total_failure: 80, total_equal:9\n",
      "\n",
      "\n",
      "---- round:218 --------\n",
      "total_win:129, total_failure: 81, total_equal:9\n",
      "\n",
      "\n",
      "---- round:219 --------\n",
      "total_win:130, total_failure: 81, total_equal:9\n",
      "\n",
      "\n",
      "---- round:220 --------\n",
      "total_win:130, total_failure: 82, total_equal:9\n",
      "\n",
      "\n",
      "---- round:221 --------\n",
      "total_win:131, total_failure: 82, total_equal:9\n",
      "\n",
      "\n",
      "---- round:222 --------\n",
      "total_win:132, total_failure: 82, total_equal:9\n",
      "\n",
      "\n",
      "---- round:223 --------\n",
      "total_win:132, total_failure: 83, total_equal:9\n",
      "\n",
      "\n",
      "---- round:224 --------\n",
      "total_win:133, total_failure: 83, total_equal:9\n",
      "\n",
      "\n",
      "---- round:225 --------\n",
      "total_win:134, total_failure: 83, total_equal:9\n",
      "\n",
      "\n",
      "---- round:226 --------\n",
      "total_win:135, total_failure: 83, total_equal:9\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- round:227 --------\n",
      "total_win:136, total_failure: 83, total_equal:9\n",
      "\n",
      "\n",
      "---- round:228 --------\n",
      "total_win:136, total_failure: 84, total_equal:9\n",
      "\n",
      "\n",
      "---- round:229 --------\n",
      "total_win:137, total_failure: 84, total_equal:9\n",
      "\n",
      "\n",
      "---- round:230 --------\n",
      "total_win:138, total_failure: 84, total_equal:9\n",
      "\n",
      "\n",
      "---- round:231 --------\n",
      "total_win:139, total_failure: 84, total_equal:9\n",
      "\n",
      "\n",
      "---- round:232 --------\n",
      "total_win:140, total_failure: 84, total_equal:9\n",
      "\n",
      "\n",
      "---- round:233 --------\n",
      "total_win:141, total_failure: 84, total_equal:9\n",
      "\n",
      "\n",
      "---- round:234 --------\n",
      "total_win:141, total_failure: 85, total_equal:9\n",
      "\n",
      "\n",
      "---- round:235 --------\n",
      "total_win:142, total_failure: 85, total_equal:9\n",
      "\n",
      "\n",
      "---- round:236 --------\n",
      "total_win:143, total_failure: 85, total_equal:9\n",
      "\n",
      "\n",
      "---- round:237 --------\n",
      "total_win:144, total_failure: 85, total_equal:9\n",
      "\n",
      "\n",
      "---- round:238 --------\n",
      "total_win:145, total_failure: 85, total_equal:9\n",
      "\n",
      "\n",
      "---- round:239 --------\n",
      "total_win:145, total_failure: 86, total_equal:9\n",
      "\n",
      "\n",
      "---- round:240 --------\n",
      "total_win:146, total_failure: 86, total_equal:9\n",
      "\n",
      "\n",
      "---- round:241 --------\n",
      "total_win:147, total_failure: 86, total_equal:9\n",
      "\n",
      "\n",
      "---- round:242 --------\n",
      "total_win:148, total_failure: 86, total_equal:9\n",
      "\n",
      "\n",
      "---- round:243 --------\n",
      "total_win:148, total_failure: 86, total_equal:10\n",
      "\n",
      "\n",
      "---- round:244 --------\n",
      "total_win:149, total_failure: 86, total_equal:10\n",
      "\n",
      "\n",
      "---- round:245 --------\n",
      "total_win:149, total_failure: 87, total_equal:10\n",
      "\n",
      "\n",
      "---- round:246 --------\n",
      "total_win:149, total_failure: 88, total_equal:10\n",
      "\n",
      "\n",
      "---- round:247 --------\n",
      "total_win:149, total_failure: 89, total_equal:10\n",
      "\n",
      "\n",
      "---- round:248 --------\n",
      "total_win:150, total_failure: 89, total_equal:10\n",
      "\n",
      "\n",
      "---- round:249 --------\n",
      "total_win:150, total_failure: 90, total_equal:10\n",
      "\n",
      "\n",
      "---- round:250 --------\n",
      "total_win:151, total_failure: 90, total_equal:10\n",
      "\n",
      "\n",
      "---- round:251 --------\n",
      "total_win:151, total_failure: 91, total_equal:10\n",
      "\n",
      "\n",
      "---- round:252 --------\n",
      "total_win:152, total_failure: 91, total_equal:10\n",
      "\n",
      "\n",
      "---- round:253 --------\n",
      "total_win:153, total_failure: 91, total_equal:10\n",
      "\n",
      "\n",
      "---- round:254 --------\n",
      "total_win:154, total_failure: 91, total_equal:10\n",
      "\n",
      "\n",
      "---- round:255 --------\n",
      "total_win:155, total_failure: 91, total_equal:10\n",
      "\n",
      "\n",
      "---- round:256 --------\n",
      "total_win:156, total_failure: 91, total_equal:10\n",
      "\n",
      "\n",
      "---- round:257 --------\n",
      "total_win:157, total_failure: 91, total_equal:10\n",
      "\n",
      "\n",
      "---- round:258 --------\n",
      "total_win:158, total_failure: 91, total_equal:10\n",
      "\n",
      "\n",
      "---- round:259 --------\n",
      "total_win:158, total_failure: 92, total_equal:10\n",
      "\n",
      "\n",
      "---- round:260 --------\n",
      "total_win:158, total_failure: 92, total_equal:11\n",
      "\n",
      "\n",
      "---- round:261 --------\n",
      "total_win:159, total_failure: 92, total_equal:11\n",
      "\n",
      "\n",
      "---- round:262 --------\n",
      "total_win:160, total_failure: 92, total_equal:11\n",
      "\n",
      "\n",
      "---- round:263 --------\n",
      "total_win:161, total_failure: 92, total_equal:11\n",
      "\n",
      "\n",
      "---- round:264 --------\n",
      "total_win:162, total_failure: 92, total_equal:11\n",
      "\n",
      "\n",
      "---- round:265 --------\n",
      "total_win:162, total_failure: 93, total_equal:11\n",
      "\n",
      "\n",
      "---- round:266 --------\n",
      "total_win:163, total_failure: 93, total_equal:11\n",
      "\n",
      "\n",
      "---- round:267 --------\n",
      "total_win:164, total_failure: 93, total_equal:11\n",
      "\n",
      "\n",
      "---- round:268 --------\n",
      "total_win:165, total_failure: 93, total_equal:11\n",
      "\n",
      "\n",
      "---- round:269 --------\n",
      "total_win:165, total_failure: 94, total_equal:11\n",
      "\n",
      "\n",
      "---- round:270 --------\n",
      "total_win:166, total_failure: 94, total_equal:11\n",
      "\n",
      "\n",
      "---- round:271 --------\n",
      "total_win:167, total_failure: 94, total_equal:11\n",
      "\n",
      "\n",
      "---- round:272 --------\n",
      "total_win:168, total_failure: 94, total_equal:11\n",
      "\n",
      "\n",
      "---- round:273 --------\n",
      "total_win:168, total_failure: 95, total_equal:11\n",
      "\n",
      "\n",
      "---- round:274 --------\n",
      "total_win:169, total_failure: 95, total_equal:11\n",
      "\n",
      "\n",
      "---- round:275 --------\n",
      "total_win:170, total_failure: 95, total_equal:11\n",
      "\n",
      "\n",
      "---- round:276 --------\n",
      "total_win:171, total_failure: 95, total_equal:11\n",
      "\n",
      "\n",
      "---- round:277 --------\n",
      "total_win:172, total_failure: 95, total_equal:11\n",
      "\n",
      "\n",
      "---- round:278 --------\n",
      "total_win:173, total_failure: 95, total_equal:11\n",
      "\n",
      "\n",
      "---- round:279 --------\n",
      "total_win:174, total_failure: 95, total_equal:11\n",
      "\n",
      "\n",
      "---- round:280 --------\n",
      "total_win:175, total_failure: 95, total_equal:11\n",
      "\n",
      "\n",
      "---- round:281 --------\n",
      "total_win:175, total_failure: 96, total_equal:11\n",
      "\n",
      "\n",
      "---- round:282 --------\n",
      "total_win:176, total_failure: 96, total_equal:11\n",
      "\n",
      "\n",
      "---- round:283 --------\n",
      "total_win:177, total_failure: 96, total_equal:11\n",
      "\n",
      "\n",
      "---- round:284 --------\n",
      "total_win:177, total_failure: 97, total_equal:11\n",
      "\n",
      "\n",
      "---- round:285 --------\n",
      "total_win:177, total_failure: 98, total_equal:11\n",
      "\n",
      "\n",
      "---- round:286 --------\n",
      "total_win:178, total_failure: 98, total_equal:11\n",
      "\n",
      "\n",
      "---- round:287 --------\n",
      "total_win:178, total_failure: 98, total_equal:12\n",
      "\n",
      "\n",
      "---- round:288 --------\n",
      "total_win:178, total_failure: 99, total_equal:12\n",
      "\n",
      "\n",
      "---- round:289 --------\n",
      "total_win:179, total_failure: 99, total_equal:12\n",
      "\n",
      "\n",
      "---- round:290 --------\n",
      "total_win:179, total_failure: 100, total_equal:12\n",
      "\n",
      "\n",
      "---- round:291 --------\n",
      "total_win:179, total_failure: 101, total_equal:12\n",
      "\n",
      "\n",
      "---- round:292 --------\n",
      "total_win:180, total_failure: 101, total_equal:12\n",
      "\n",
      "\n",
      "---- round:293 --------\n",
      "total_win:181, total_failure: 101, total_equal:12\n",
      "\n",
      "\n",
      "---- round:294 --------\n",
      "total_win:182, total_failure: 101, total_equal:12\n",
      "\n",
      "\n",
      "---- round:295 --------\n",
      "total_win:182, total_failure: 102, total_equal:12\n",
      "\n",
      "\n",
      "---- round:296 --------\n",
      "total_win:183, total_failure: 102, total_equal:12\n",
      "\n",
      "\n",
      "---- round:297 --------\n",
      "total_win:184, total_failure: 102, total_equal:12\n",
      "\n",
      "\n",
      "---- round:298 --------\n",
      "total_win:184, total_failure: 103, total_equal:12\n",
      "\n",
      "\n",
      "---- round:299 --------\n",
      "total_win:184, total_failure: 104, total_equal:12\n",
      "\n",
      "\n",
      "---- round:300 --------\n",
      "total_win:184, total_failure: 105, total_equal:12\n",
      "\n",
      "\n",
      "---- round:301 --------\n",
      "total_win:185, total_failure: 105, total_equal:12\n",
      "\n",
      "\n",
      "---- round:302 --------\n",
      "total_win:185, total_failure: 106, total_equal:12\n",
      "\n",
      "\n",
      "---- round:303 --------\n",
      "total_win:186, total_failure: 106, total_equal:12\n",
      "\n",
      "\n",
      "---- round:304 --------\n",
      "total_win:187, total_failure: 106, total_equal:12\n",
      "\n",
      "\n",
      "---- round:305 --------\n",
      "total_win:187, total_failure: 107, total_equal:12\n",
      "\n",
      "\n",
      "---- round:306 --------\n",
      "total_win:187, total_failure: 108, total_equal:12\n",
      "\n",
      "\n",
      "---- round:307 --------\n",
      "total_win:187, total_failure: 109, total_equal:12\n",
      "\n",
      "\n",
      "---- round:308 --------\n",
      "total_win:187, total_failure: 110, total_equal:12\n",
      "\n",
      "\n",
      "---- round:309 --------\n",
      "total_win:188, total_failure: 110, total_equal:12\n",
      "\n",
      "\n",
      "---- round:310 --------\n",
      "total_win:189, total_failure: 110, total_equal:12\n",
      "\n",
      "\n",
      "---- round:311 --------\n",
      "total_win:190, total_failure: 110, total_equal:12\n",
      "\n",
      "\n",
      "---- round:312 --------\n",
      "total_win:190, total_failure: 111, total_equal:12\n",
      "\n",
      "\n",
      "---- round:313 --------\n",
      "total_win:191, total_failure: 111, total_equal:12\n",
      "\n",
      "\n",
      "---- round:314 --------\n",
      "total_win:191, total_failure: 112, total_equal:12\n",
      "\n",
      "\n",
      "---- round:315 --------\n",
      "total_win:191, total_failure: 113, total_equal:12\n",
      "\n",
      "\n",
      "---- round:316 --------\n",
      "total_win:191, total_failure: 114, total_equal:12\n",
      "\n",
      "\n",
      "---- round:317 --------\n",
      "total_win:192, total_failure: 114, total_equal:12\n",
      "\n",
      "\n",
      "---- round:318 --------\n",
      "total_win:193, total_failure: 114, total_equal:12\n",
      "\n",
      "\n",
      "---- round:319 --------\n",
      "total_win:194, total_failure: 114, total_equal:12\n",
      "\n",
      "\n",
      "---- round:320 --------\n",
      "total_win:195, total_failure: 114, total_equal:12\n",
      "\n",
      "\n",
      "---- round:321 --------\n",
      "total_win:195, total_failure: 115, total_equal:12\n",
      "\n",
      "\n",
      "---- round:322 --------\n",
      "total_win:195, total_failure: 116, total_equal:12\n",
      "\n",
      "\n",
      "---- round:323 --------\n",
      "total_win:196, total_failure: 116, total_equal:12\n",
      "\n",
      "\n",
      "---- round:324 --------\n",
      "total_win:196, total_failure: 117, total_equal:12\n",
      "\n",
      "\n",
      "---- round:325 --------\n",
      "total_win:196, total_failure: 118, total_equal:12\n",
      "\n",
      "\n",
      "---- round:326 --------\n",
      "total_win:196, total_failure: 119, total_equal:12\n",
      "\n",
      "\n",
      "---- round:327 --------\n",
      "total_win:197, total_failure: 119, total_equal:12\n",
      "\n",
      "\n",
      "---- round:328 --------\n",
      "total_win:198, total_failure: 119, total_equal:12\n",
      "\n",
      "\n",
      "---- round:329 --------\n",
      "total_win:198, total_failure: 120, total_equal:12\n",
      "\n",
      "\n",
      "---- round:330 --------\n",
      "total_win:199, total_failure: 120, total_equal:12\n",
      "\n",
      "\n",
      "---- round:331 --------\n",
      "total_win:200, total_failure: 120, total_equal:12\n",
      "\n",
      "\n",
      "---- round:332 --------\n",
      "total_win:201, total_failure: 120, total_equal:12\n",
      "\n",
      "\n",
      "---- round:333 --------\n",
      "total_win:202, total_failure: 120, total_equal:12\n",
      "\n",
      "\n",
      "---- round:334 --------\n",
      "total_win:202, total_failure: 121, total_equal:12\n",
      "\n",
      "\n",
      "---- round:335 --------\n",
      "total_win:203, total_failure: 121, total_equal:12\n",
      "\n",
      "\n",
      "---- round:336 --------\n",
      "total_win:203, total_failure: 122, total_equal:12\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- round:337 --------\n",
      "total_win:203, total_failure: 123, total_equal:12\n",
      "\n",
      "\n",
      "---- round:338 --------\n",
      "total_win:204, total_failure: 123, total_equal:12\n",
      "\n",
      "\n",
      "---- round:339 --------\n",
      "total_win:204, total_failure: 124, total_equal:12\n",
      "\n",
      "\n",
      "---- round:340 --------\n",
      "total_win:204, total_failure: 125, total_equal:12\n",
      "\n",
      "\n",
      "---- round:341 --------\n",
      "total_win:205, total_failure: 125, total_equal:12\n",
      "\n",
      "\n",
      "---- round:342 --------\n",
      "total_win:205, total_failure: 126, total_equal:12\n",
      "\n",
      "\n",
      "---- round:343 --------\n",
      "total_win:205, total_failure: 127, total_equal:12\n",
      "\n",
      "\n",
      "---- round:344 --------\n",
      "total_win:206, total_failure: 127, total_equal:12\n",
      "\n",
      "\n",
      "---- round:345 --------\n",
      "total_win:207, total_failure: 127, total_equal:12\n",
      "\n",
      "\n",
      "---- round:346 --------\n",
      "total_win:208, total_failure: 127, total_equal:12\n",
      "\n",
      "\n",
      "---- round:347 --------\n",
      "total_win:208, total_failure: 128, total_equal:12\n",
      "\n",
      "\n",
      "---- round:348 --------\n",
      "total_win:209, total_failure: 128, total_equal:12\n",
      "\n",
      "\n",
      "---- round:349 --------\n",
      "total_win:209, total_failure: 129, total_equal:12\n",
      "\n",
      "\n",
      "---- round:350 --------\n",
      "total_win:210, total_failure: 129, total_equal:12\n",
      "\n",
      "\n",
      "---- round:351 --------\n",
      "total_win:211, total_failure: 129, total_equal:12\n",
      "\n",
      "\n",
      "---- round:352 --------\n",
      "total_win:212, total_failure: 129, total_equal:12\n",
      "\n",
      "\n",
      "---- round:353 --------\n",
      "total_win:212, total_failure: 130, total_equal:12\n",
      "\n",
      "\n",
      "---- round:354 --------\n",
      "total_win:212, total_failure: 131, total_equal:12\n",
      "\n",
      "\n",
      "---- round:355 --------\n",
      "total_win:212, total_failure: 132, total_equal:12\n",
      "\n",
      "\n",
      "---- round:356 --------\n",
      "total_win:213, total_failure: 132, total_equal:12\n",
      "\n",
      "\n",
      "---- round:357 --------\n",
      "total_win:214, total_failure: 132, total_equal:12\n",
      "\n",
      "\n",
      "---- round:358 --------\n",
      "total_win:214, total_failure: 133, total_equal:12\n",
      "\n",
      "\n",
      "---- round:359 --------\n",
      "total_win:215, total_failure: 133, total_equal:12\n",
      "\n",
      "\n",
      "---- round:360 --------\n",
      "total_win:215, total_failure: 134, total_equal:12\n",
      "\n",
      "\n",
      "---- round:361 --------\n",
      "total_win:216, total_failure: 134, total_equal:12\n",
      "\n",
      "\n",
      "---- round:362 --------\n",
      "total_win:216, total_failure: 135, total_equal:12\n",
      "\n",
      "\n",
      "---- round:363 --------\n",
      "total_win:216, total_failure: 136, total_equal:12\n",
      "\n",
      "\n",
      "---- round:364 --------\n",
      "total_win:216, total_failure: 137, total_equal:12\n",
      "\n",
      "\n",
      "---- round:365 --------\n",
      "total_win:217, total_failure: 137, total_equal:12\n",
      "\n",
      "\n",
      "---- round:366 --------\n",
      "total_win:217, total_failure: 138, total_equal:12\n",
      "\n",
      "\n",
      "---- round:367 --------\n",
      "total_win:217, total_failure: 138, total_equal:13\n",
      "\n",
      "\n",
      "---- round:368 --------\n",
      "total_win:218, total_failure: 138, total_equal:13\n",
      "\n",
      "\n",
      "---- round:369 --------\n",
      "total_win:219, total_failure: 138, total_equal:13\n",
      "\n",
      "\n",
      "---- round:370 --------\n",
      "total_win:220, total_failure: 138, total_equal:13\n",
      "\n",
      "\n",
      "---- round:371 --------\n",
      "total_win:220, total_failure: 139, total_equal:13\n",
      "\n",
      "\n",
      "---- round:372 --------\n",
      "total_win:220, total_failure: 140, total_equal:13\n",
      "\n",
      "\n",
      "---- round:373 --------\n",
      "total_win:220, total_failure: 140, total_equal:14\n",
      "\n",
      "\n",
      "---- round:374 --------\n",
      "total_win:221, total_failure: 140, total_equal:14\n",
      "\n",
      "\n",
      "---- round:375 --------\n",
      "total_win:222, total_failure: 140, total_equal:14\n",
      "\n",
      "\n",
      "---- round:376 --------\n",
      "total_win:223, total_failure: 140, total_equal:14\n",
      "\n",
      "\n",
      "---- round:377 --------\n",
      "total_win:223, total_failure: 141, total_equal:14\n",
      "\n",
      "\n",
      "---- round:378 --------\n",
      "total_win:224, total_failure: 141, total_equal:14\n",
      "\n",
      "\n",
      "---- round:379 --------\n",
      "total_win:225, total_failure: 141, total_equal:14\n",
      "\n",
      "\n",
      "---- round:380 --------\n",
      "total_win:226, total_failure: 141, total_equal:14\n",
      "\n",
      "\n",
      "---- round:381 --------\n",
      "total_win:227, total_failure: 141, total_equal:14\n",
      "\n",
      "\n",
      "---- round:382 --------\n",
      "total_win:228, total_failure: 141, total_equal:14\n",
      "\n",
      "\n",
      "---- round:383 --------\n",
      "total_win:229, total_failure: 141, total_equal:14\n",
      "\n",
      "\n",
      "---- round:384 --------\n",
      "total_win:230, total_failure: 141, total_equal:14\n",
      "\n",
      "\n",
      "---- round:385 --------\n",
      "total_win:230, total_failure: 141, total_equal:15\n",
      "\n",
      "\n",
      "---- round:386 --------\n",
      "total_win:230, total_failure: 141, total_equal:16\n",
      "\n",
      "\n",
      "---- round:387 --------\n",
      "total_win:230, total_failure: 142, total_equal:16\n",
      "\n",
      "\n",
      "---- round:388 --------\n",
      "total_win:231, total_failure: 142, total_equal:16\n",
      "\n",
      "\n",
      "---- round:389 --------\n",
      "total_win:232, total_failure: 142, total_equal:16\n",
      "\n",
      "\n",
      "---- round:390 --------\n",
      "total_win:232, total_failure: 143, total_equal:16\n",
      "\n",
      "\n",
      "---- round:391 --------\n",
      "total_win:232, total_failure: 144, total_equal:16\n",
      "\n",
      "\n",
      "---- round:392 --------\n",
      "total_win:232, total_failure: 145, total_equal:16\n",
      "\n",
      "\n",
      "---- round:393 --------\n",
      "total_win:233, total_failure: 145, total_equal:16\n",
      "\n",
      "\n",
      "---- round:394 --------\n",
      "total_win:234, total_failure: 145, total_equal:16\n",
      "\n",
      "\n",
      "---- round:395 --------\n",
      "total_win:234, total_failure: 146, total_equal:16\n",
      "\n",
      "\n",
      "---- round:396 --------\n",
      "total_win:234, total_failure: 147, total_equal:16\n",
      "\n",
      "\n",
      "---- round:397 --------\n",
      "total_win:235, total_failure: 147, total_equal:16\n",
      "\n",
      "\n",
      "---- round:398 --------\n",
      "total_win:235, total_failure: 148, total_equal:16\n",
      "\n",
      "\n",
      "---- round:399 --------\n",
      "total_win:236, total_failure: 148, total_equal:16\n",
      "\n",
      "\n",
      "---- round:400 --------\n",
      "total_win:236, total_failure: 149, total_equal:16\n",
      "\n",
      "\n",
      "---- round:401 --------\n",
      "total_win:237, total_failure: 149, total_equal:16\n",
      "\n",
      "\n",
      "---- round:402 --------\n",
      "total_win:238, total_failure: 149, total_equal:16\n",
      "\n",
      "\n",
      "---- round:403 --------\n",
      "total_win:238, total_failure: 150, total_equal:16\n",
      "\n",
      "\n",
      "---- round:404 --------\n",
      "total_win:239, total_failure: 150, total_equal:16\n",
      "\n",
      "\n",
      "---- round:405 --------\n",
      "total_win:240, total_failure: 150, total_equal:16\n",
      "\n",
      "\n",
      "---- round:406 --------\n",
      "total_win:241, total_failure: 150, total_equal:16\n",
      "\n",
      "\n",
      "---- round:407 --------\n",
      "total_win:241, total_failure: 151, total_equal:16\n",
      "\n",
      "\n",
      "---- round:408 --------\n",
      "total_win:241, total_failure: 152, total_equal:16\n",
      "\n",
      "\n",
      "---- round:409 --------\n",
      "total_win:242, total_failure: 152, total_equal:16\n",
      "\n",
      "\n",
      "---- round:410 --------\n",
      "total_win:242, total_failure: 153, total_equal:16\n",
      "\n",
      "\n",
      "---- round:411 --------\n",
      "total_win:243, total_failure: 153, total_equal:16\n",
      "\n",
      "\n",
      "---- round:412 --------\n",
      "total_win:244, total_failure: 153, total_equal:16\n",
      "\n",
      "\n",
      "---- round:413 --------\n",
      "total_win:244, total_failure: 154, total_equal:16\n",
      "\n",
      "\n",
      "---- round:414 --------\n",
      "total_win:244, total_failure: 155, total_equal:16\n",
      "\n",
      "\n",
      "---- round:415 --------\n",
      "total_win:244, total_failure: 156, total_equal:16\n",
      "\n",
      "\n",
      "---- round:416 --------\n",
      "total_win:245, total_failure: 156, total_equal:16\n",
      "\n",
      "\n",
      "---- round:417 --------\n",
      "total_win:245, total_failure: 157, total_equal:16\n",
      "\n",
      "\n",
      "---- round:418 --------\n",
      "total_win:245, total_failure: 158, total_equal:16\n",
      "\n",
      "\n",
      "---- round:419 --------\n",
      "total_win:246, total_failure: 158, total_equal:16\n",
      "\n",
      "\n",
      "---- round:420 --------\n",
      "total_win:247, total_failure: 158, total_equal:16\n",
      "\n",
      "\n",
      "---- round:421 --------\n",
      "total_win:248, total_failure: 158, total_equal:16\n",
      "\n",
      "\n",
      "---- round:422 --------\n",
      "total_win:249, total_failure: 158, total_equal:16\n",
      "\n",
      "\n",
      "---- round:423 --------\n",
      "total_win:250, total_failure: 158, total_equal:16\n",
      "\n",
      "\n",
      "---- round:424 --------\n",
      "total_win:251, total_failure: 158, total_equal:16\n",
      "\n",
      "\n",
      "---- round:425 --------\n",
      "total_win:251, total_failure: 158, total_equal:17\n",
      "\n",
      "\n",
      "---- round:426 --------\n",
      "total_win:252, total_failure: 158, total_equal:17\n",
      "\n",
      "\n",
      "---- round:427 --------\n",
      "total_win:252, total_failure: 159, total_equal:17\n",
      "\n",
      "\n",
      "---- round:428 --------\n",
      "total_win:252, total_failure: 160, total_equal:17\n",
      "\n",
      "\n",
      "---- round:429 --------\n",
      "total_win:253, total_failure: 160, total_equal:17\n",
      "\n",
      "\n",
      "---- round:430 --------\n",
      "total_win:254, total_failure: 160, total_equal:17\n",
      "\n",
      "\n",
      "---- round:431 --------\n",
      "total_win:255, total_failure: 160, total_equal:17\n",
      "\n",
      "\n",
      "---- round:432 --------\n",
      "total_win:256, total_failure: 160, total_equal:17\n",
      "\n",
      "\n",
      "---- round:433 --------\n",
      "total_win:256, total_failure: 161, total_equal:17\n",
      "\n",
      "\n",
      "---- round:434 --------\n",
      "total_win:257, total_failure: 161, total_equal:17\n",
      "\n",
      "\n",
      "---- round:435 --------\n",
      "total_win:258, total_failure: 161, total_equal:17\n",
      "\n",
      "\n",
      "---- round:436 --------\n",
      "total_win:259, total_failure: 161, total_equal:17\n",
      "\n",
      "\n",
      "---- round:437 --------\n",
      "total_win:259, total_failure: 162, total_equal:17\n",
      "\n",
      "\n",
      "---- round:438 --------\n",
      "total_win:259, total_failure: 163, total_equal:17\n",
      "\n",
      "\n",
      "---- round:439 --------\n",
      "total_win:259, total_failure: 164, total_equal:17\n",
      "\n",
      "\n",
      "---- round:440 --------\n",
      "total_win:259, total_failure: 165, total_equal:17\n",
      "\n",
      "\n",
      "---- round:441 --------\n",
      "total_win:259, total_failure: 166, total_equal:17\n",
      "\n",
      "\n",
      "---- round:442 --------\n",
      "total_win:260, total_failure: 166, total_equal:17\n",
      "\n",
      "\n",
      "---- round:443 --------\n",
      "total_win:261, total_failure: 166, total_equal:17\n",
      "\n",
      "\n",
      "---- round:444 --------\n",
      "total_win:262, total_failure: 166, total_equal:17\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- round:445 --------\n",
      "total_win:263, total_failure: 166, total_equal:17\n",
      "\n",
      "\n",
      "---- round:446 --------\n",
      "total_win:264, total_failure: 166, total_equal:17\n",
      "\n",
      "\n",
      "---- round:447 --------\n",
      "total_win:265, total_failure: 166, total_equal:17\n",
      "\n",
      "\n",
      "---- round:448 --------\n",
      "total_win:265, total_failure: 167, total_equal:17\n",
      "\n",
      "\n",
      "---- round:449 --------\n",
      "total_win:266, total_failure: 167, total_equal:17\n",
      "\n",
      "\n",
      "---- round:450 --------\n",
      "total_win:266, total_failure: 168, total_equal:17\n",
      "\n",
      "\n",
      "---- round:451 --------\n",
      "total_win:267, total_failure: 168, total_equal:17\n",
      "\n",
      "\n",
      "---- round:452 --------\n",
      "total_win:268, total_failure: 168, total_equal:17\n",
      "\n",
      "\n",
      "---- round:453 --------\n",
      "total_win:268, total_failure: 169, total_equal:17\n",
      "\n",
      "\n",
      "---- round:454 --------\n",
      "total_win:269, total_failure: 169, total_equal:17\n",
      "\n",
      "\n",
      "---- round:455 --------\n",
      "total_win:269, total_failure: 170, total_equal:17\n",
      "\n",
      "\n",
      "---- round:456 --------\n",
      "total_win:269, total_failure: 171, total_equal:17\n",
      "\n",
      "\n",
      "---- round:457 --------\n",
      "total_win:270, total_failure: 171, total_equal:17\n",
      "\n",
      "\n",
      "---- round:458 --------\n",
      "total_win:270, total_failure: 172, total_equal:17\n",
      "\n",
      "\n",
      "---- round:459 --------\n",
      "total_win:270, total_failure: 173, total_equal:17\n",
      "\n",
      "\n",
      "---- round:460 --------\n",
      "total_win:270, total_failure: 173, total_equal:18\n",
      "\n",
      "\n",
      "---- round:461 --------\n",
      "total_win:270, total_failure: 174, total_equal:18\n",
      "\n",
      "\n",
      "---- round:462 --------\n",
      "total_win:270, total_failure: 175, total_equal:18\n",
      "\n",
      "\n",
      "---- round:463 --------\n",
      "total_win:270, total_failure: 176, total_equal:18\n",
      "\n",
      "\n",
      "---- round:464 --------\n",
      "total_win:270, total_failure: 177, total_equal:18\n",
      "\n",
      "\n",
      "---- round:465 --------\n",
      "total_win:270, total_failure: 178, total_equal:18\n",
      "\n",
      "\n",
      "---- round:466 --------\n",
      "total_win:271, total_failure: 178, total_equal:18\n",
      "\n",
      "\n",
      "---- round:467 --------\n",
      "total_win:272, total_failure: 178, total_equal:18\n",
      "\n",
      "\n",
      "---- round:468 --------\n",
      "total_win:273, total_failure: 178, total_equal:18\n",
      "\n",
      "\n",
      "---- round:469 --------\n",
      "total_win:274, total_failure: 178, total_equal:18\n",
      "\n",
      "\n",
      "---- round:470 --------\n",
      "total_win:275, total_failure: 178, total_equal:18\n",
      "\n",
      "\n",
      "---- round:471 --------\n",
      "total_win:276, total_failure: 178, total_equal:18\n",
      "\n",
      "\n",
      "---- round:472 --------\n",
      "total_win:277, total_failure: 178, total_equal:18\n",
      "\n",
      "\n",
      "---- round:473 --------\n",
      "total_win:277, total_failure: 179, total_equal:18\n",
      "\n",
      "\n",
      "---- round:474 --------\n",
      "total_win:277, total_failure: 180, total_equal:18\n",
      "\n",
      "\n",
      "---- round:475 --------\n",
      "total_win:278, total_failure: 180, total_equal:18\n",
      "\n",
      "\n",
      "---- round:476 --------\n",
      "total_win:279, total_failure: 180, total_equal:18\n",
      "\n",
      "\n",
      "---- round:477 --------\n",
      "total_win:279, total_failure: 181, total_equal:18\n",
      "\n",
      "\n",
      "---- round:478 --------\n",
      "total_win:279, total_failure: 182, total_equal:18\n",
      "\n",
      "\n",
      "---- round:479 --------\n",
      "total_win:280, total_failure: 182, total_equal:18\n",
      "\n",
      "\n",
      "---- round:480 --------\n",
      "total_win:280, total_failure: 183, total_equal:18\n",
      "\n",
      "\n",
      "---- round:481 --------\n",
      "total_win:280, total_failure: 184, total_equal:18\n",
      "\n",
      "\n",
      "---- round:482 --------\n",
      "total_win:280, total_failure: 185, total_equal:18\n",
      "\n",
      "\n",
      "---- round:483 --------\n",
      "total_win:281, total_failure: 185, total_equal:18\n",
      "\n",
      "\n",
      "---- round:484 --------\n",
      "total_win:282, total_failure: 185, total_equal:18\n",
      "\n",
      "\n",
      "---- round:485 --------\n",
      "total_win:282, total_failure: 186, total_equal:18\n",
      "\n",
      "\n",
      "---- round:486 --------\n",
      "total_win:283, total_failure: 186, total_equal:18\n",
      "\n",
      "\n",
      "---- round:487 --------\n",
      "total_win:283, total_failure: 187, total_equal:18\n",
      "\n",
      "\n",
      "---- round:488 --------\n",
      "total_win:284, total_failure: 187, total_equal:18\n",
      "\n",
      "\n",
      "---- round:489 --------\n",
      "total_win:285, total_failure: 187, total_equal:18\n",
      "\n",
      "\n",
      "---- round:490 --------\n",
      "total_win:285, total_failure: 188, total_equal:18\n",
      "\n",
      "\n",
      "---- round:491 --------\n",
      "total_win:286, total_failure: 188, total_equal:18\n",
      "\n",
      "\n",
      "---- round:492 --------\n",
      "total_win:287, total_failure: 188, total_equal:18\n",
      "\n",
      "\n",
      "---- round:493 --------\n",
      "total_win:288, total_failure: 188, total_equal:18\n",
      "\n",
      "\n",
      "---- round:494 --------\n",
      "total_win:289, total_failure: 188, total_equal:18\n",
      "\n",
      "\n",
      "---- round:495 --------\n",
      "total_win:290, total_failure: 188, total_equal:18\n",
      "\n",
      "\n",
      "---- round:496 --------\n",
      "total_win:291, total_failure: 188, total_equal:18\n",
      "\n",
      "\n",
      "---- round:497 --------\n",
      "total_win:291, total_failure: 189, total_equal:18\n",
      "\n",
      "\n",
      "---- round:498 --------\n",
      "total_win:292, total_failure: 189, total_equal:18\n",
      "\n",
      "\n",
      "---- round:499 --------\n",
      "total_win:293, total_failure: 189, total_equal:18\n",
      "\n",
      "\n",
      "---- round:500 --------\n",
      "total_win:294, total_failure: 189, total_equal:18\n",
      "\n",
      "\n",
      "---- round:501 --------\n",
      "total_win:295, total_failure: 189, total_equal:18\n",
      "\n",
      "\n",
      "---- round:502 --------\n",
      "total_win:295, total_failure: 190, total_equal:18\n",
      "\n",
      "\n",
      "---- round:503 --------\n",
      "total_win:296, total_failure: 190, total_equal:18\n",
      "\n",
      "\n",
      "---- round:504 --------\n",
      "total_win:297, total_failure: 190, total_equal:18\n",
      "\n",
      "\n",
      "---- round:505 --------\n",
      "total_win:297, total_failure: 191, total_equal:18\n",
      "\n",
      "\n",
      "---- round:506 --------\n",
      "total_win:298, total_failure: 191, total_equal:18\n",
      "\n",
      "\n",
      "---- round:507 --------\n",
      "total_win:299, total_failure: 191, total_equal:18\n",
      "\n",
      "\n",
      "---- round:508 --------\n",
      "total_win:299, total_failure: 192, total_equal:18\n",
      "\n",
      "\n",
      "---- round:509 --------\n",
      "total_win:299, total_failure: 193, total_equal:18\n",
      "\n",
      "\n",
      "---- round:510 --------\n",
      "total_win:300, total_failure: 193, total_equal:18\n",
      "\n",
      "\n",
      "---- round:511 --------\n",
      "total_win:301, total_failure: 193, total_equal:18\n",
      "\n",
      "\n",
      "---- round:512 --------\n",
      "total_win:301, total_failure: 194, total_equal:18\n",
      "\n",
      "\n",
      "---- round:513 --------\n",
      "total_win:302, total_failure: 194, total_equal:18\n",
      "\n",
      "\n",
      "---- round:514 --------\n",
      "total_win:302, total_failure: 195, total_equal:18\n",
      "\n",
      "\n",
      "---- round:515 --------\n",
      "total_win:302, total_failure: 196, total_equal:18\n",
      "\n",
      "\n",
      "---- round:516 --------\n",
      "total_win:302, total_failure: 197, total_equal:18\n",
      "\n",
      "\n",
      "---- round:517 --------\n",
      "total_win:302, total_failure: 198, total_equal:18\n",
      "\n",
      "\n",
      "---- round:518 --------\n",
      "total_win:303, total_failure: 198, total_equal:18\n",
      "\n",
      "\n",
      "---- round:519 --------\n",
      "total_win:304, total_failure: 198, total_equal:18\n",
      "\n",
      "\n",
      "---- round:520 --------\n",
      "total_win:305, total_failure: 198, total_equal:18\n",
      "\n",
      "\n",
      "---- round:521 --------\n",
      "total_win:305, total_failure: 199, total_equal:18\n",
      "\n",
      "\n",
      "---- round:522 --------\n",
      "total_win:305, total_failure: 200, total_equal:18\n",
      "\n",
      "\n",
      "---- round:523 --------\n",
      "total_win:305, total_failure: 201, total_equal:18\n",
      "\n",
      "\n",
      "---- round:524 --------\n",
      "total_win:306, total_failure: 201, total_equal:18\n",
      "\n",
      "\n",
      "---- round:525 --------\n",
      "total_win:306, total_failure: 202, total_equal:18\n",
      "\n",
      "\n",
      "---- round:526 --------\n",
      "total_win:307, total_failure: 202, total_equal:18\n",
      "\n",
      "\n",
      "---- round:527 --------\n",
      "total_win:307, total_failure: 203, total_equal:18\n",
      "\n",
      "\n",
      "---- round:528 --------\n",
      "total_win:308, total_failure: 203, total_equal:18\n",
      "\n",
      "\n",
      "---- round:529 --------\n",
      "total_win:309, total_failure: 203, total_equal:18\n",
      "\n",
      "\n",
      "---- round:530 --------\n",
      "total_win:309, total_failure: 204, total_equal:18\n",
      "\n",
      "\n",
      "---- round:531 --------\n",
      "total_win:309, total_failure: 205, total_equal:18\n",
      "\n",
      "\n",
      "---- round:532 --------\n",
      "total_win:309, total_failure: 206, total_equal:18\n",
      "\n",
      "\n",
      "---- round:533 --------\n",
      "total_win:309, total_failure: 207, total_equal:18\n",
      "\n",
      "\n",
      "---- round:534 --------\n",
      "total_win:310, total_failure: 207, total_equal:18\n",
      "\n",
      "\n",
      "---- round:535 --------\n",
      "total_win:311, total_failure: 207, total_equal:18\n",
      "\n",
      "\n",
      "---- round:536 --------\n",
      "total_win:312, total_failure: 207, total_equal:18\n",
      "\n",
      "\n",
      "---- round:537 --------\n",
      "total_win:313, total_failure: 207, total_equal:18\n",
      "\n",
      "\n",
      "---- round:538 --------\n",
      "total_win:314, total_failure: 207, total_equal:18\n",
      "\n",
      "\n",
      "---- round:539 --------\n",
      "total_win:315, total_failure: 207, total_equal:18\n",
      "\n",
      "\n",
      "---- round:540 --------\n",
      "total_win:315, total_failure: 208, total_equal:18\n",
      "\n",
      "\n",
      "---- round:541 --------\n",
      "total_win:315, total_failure: 209, total_equal:18\n",
      "\n",
      "\n",
      "---- round:542 --------\n",
      "total_win:316, total_failure: 209, total_equal:18\n",
      "\n",
      "\n",
      "---- round:543 --------\n",
      "total_win:316, total_failure: 210, total_equal:18\n",
      "\n",
      "\n",
      "---- round:544 --------\n",
      "total_win:317, total_failure: 210, total_equal:18\n",
      "\n",
      "\n",
      "---- round:545 --------\n",
      "total_win:318, total_failure: 210, total_equal:18\n",
      "\n",
      "\n",
      "---- round:546 --------\n",
      "total_win:318, total_failure: 211, total_equal:18\n",
      "\n",
      "\n",
      "---- round:547 --------\n",
      "total_win:319, total_failure: 211, total_equal:18\n",
      "\n",
      "\n",
      "---- round:548 --------\n",
      "total_win:320, total_failure: 211, total_equal:18\n",
      "\n",
      "\n",
      "---- round:549 --------\n",
      "total_win:320, total_failure: 212, total_equal:18\n",
      "\n",
      "\n",
      "---- round:550 --------\n",
      "total_win:320, total_failure: 213, total_equal:18\n",
      "\n",
      "\n",
      "---- round:551 --------\n",
      "total_win:321, total_failure: 213, total_equal:18\n",
      "\n",
      "\n",
      "---- round:552 --------\n",
      "total_win:321, total_failure: 214, total_equal:18\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- round:553 --------\n",
      "total_win:321, total_failure: 215, total_equal:18\n",
      "\n",
      "\n",
      "---- round:554 --------\n",
      "total_win:321, total_failure: 216, total_equal:18\n",
      "\n",
      "\n",
      "---- round:555 --------\n",
      "total_win:321, total_failure: 217, total_equal:18\n",
      "\n",
      "\n",
      "---- round:556 --------\n",
      "total_win:322, total_failure: 217, total_equal:18\n",
      "\n",
      "\n",
      "---- round:557 --------\n",
      "total_win:322, total_failure: 218, total_equal:18\n",
      "\n",
      "\n",
      "---- round:558 --------\n",
      "total_win:323, total_failure: 218, total_equal:18\n",
      "\n",
      "\n",
      "---- round:559 --------\n",
      "total_win:323, total_failure: 219, total_equal:18\n",
      "\n",
      "\n",
      "---- round:560 --------\n",
      "total_win:324, total_failure: 219, total_equal:18\n",
      "\n",
      "\n",
      "---- round:561 --------\n",
      "total_win:325, total_failure: 219, total_equal:18\n",
      "\n",
      "\n",
      "---- round:562 --------\n",
      "total_win:325, total_failure: 220, total_equal:18\n",
      "\n",
      "\n",
      "---- round:563 --------\n",
      "total_win:326, total_failure: 220, total_equal:18\n",
      "\n",
      "\n",
      "---- round:564 --------\n",
      "total_win:326, total_failure: 221, total_equal:18\n",
      "\n",
      "\n",
      "---- round:565 --------\n",
      "total_win:327, total_failure: 221, total_equal:18\n",
      "\n",
      "\n",
      "---- round:566 --------\n",
      "total_win:328, total_failure: 221, total_equal:18\n",
      "\n",
      "\n",
      "---- round:567 --------\n",
      "total_win:329, total_failure: 221, total_equal:18\n",
      "\n",
      "\n",
      "---- round:568 --------\n",
      "total_win:330, total_failure: 221, total_equal:18\n",
      "\n",
      "\n",
      "---- round:569 --------\n",
      "total_win:331, total_failure: 221, total_equal:18\n",
      "\n",
      "\n",
      "---- round:570 --------\n",
      "total_win:332, total_failure: 221, total_equal:18\n",
      "\n",
      "\n",
      "---- round:571 --------\n",
      "total_win:333, total_failure: 221, total_equal:18\n",
      "\n",
      "\n",
      "---- round:572 --------\n",
      "total_win:333, total_failure: 222, total_equal:18\n",
      "\n",
      "\n",
      "---- round:573 --------\n",
      "total_win:334, total_failure: 222, total_equal:18\n",
      "\n",
      "\n",
      "---- round:574 --------\n",
      "total_win:335, total_failure: 222, total_equal:18\n",
      "\n",
      "\n",
      "---- round:575 --------\n",
      "total_win:335, total_failure: 223, total_equal:18\n",
      "\n",
      "\n",
      "---- round:576 --------\n",
      "total_win:336, total_failure: 223, total_equal:18\n",
      "\n",
      "\n",
      "---- round:577 --------\n",
      "total_win:337, total_failure: 223, total_equal:18\n",
      "\n",
      "\n",
      "---- round:578 --------\n",
      "total_win:337, total_failure: 224, total_equal:18\n",
      "\n",
      "\n",
      "---- round:579 --------\n",
      "total_win:338, total_failure: 224, total_equal:18\n",
      "\n",
      "\n",
      "---- round:580 --------\n",
      "total_win:339, total_failure: 224, total_equal:18\n",
      "\n",
      "\n",
      "---- round:581 --------\n",
      "total_win:340, total_failure: 224, total_equal:18\n",
      "\n",
      "\n",
      "---- round:582 --------\n",
      "total_win:341, total_failure: 224, total_equal:18\n",
      "\n",
      "\n",
      "---- round:583 --------\n",
      "total_win:341, total_failure: 225, total_equal:18\n",
      "\n",
      "\n",
      "---- round:584 --------\n",
      "total_win:341, total_failure: 226, total_equal:18\n",
      "\n",
      "\n",
      "---- round:585 --------\n",
      "total_win:342, total_failure: 226, total_equal:18\n",
      "\n",
      "\n",
      "---- round:586 --------\n",
      "total_win:343, total_failure: 226, total_equal:18\n",
      "\n",
      "\n",
      "---- round:587 --------\n",
      "total_win:344, total_failure: 226, total_equal:18\n",
      "\n",
      "\n",
      "---- round:588 --------\n",
      "total_win:345, total_failure: 226, total_equal:18\n",
      "\n",
      "\n",
      "---- round:589 --------\n",
      "total_win:346, total_failure: 226, total_equal:18\n",
      "\n",
      "\n",
      "---- round:590 --------\n",
      "total_win:347, total_failure: 226, total_equal:18\n",
      "\n",
      "\n",
      "---- round:591 --------\n",
      "total_win:347, total_failure: 227, total_equal:18\n",
      "\n",
      "\n",
      "---- round:592 --------\n",
      "total_win:348, total_failure: 227, total_equal:18\n",
      "\n",
      "\n",
      "---- round:593 --------\n",
      "total_win:349, total_failure: 227, total_equal:18\n",
      "\n",
      "\n",
      "---- round:594 --------\n",
      "total_win:349, total_failure: 228, total_equal:18\n",
      "\n",
      "\n",
      "---- round:595 --------\n",
      "total_win:349, total_failure: 229, total_equal:18\n",
      "\n",
      "\n",
      "---- round:596 --------\n",
      "total_win:350, total_failure: 229, total_equal:18\n",
      "\n",
      "\n",
      "---- round:597 --------\n",
      "total_win:351, total_failure: 229, total_equal:18\n",
      "\n",
      "\n",
      "---- round:598 --------\n",
      "total_win:352, total_failure: 229, total_equal:18\n",
      "\n",
      "\n",
      "---- round:599 --------\n",
      "total_win:352, total_failure: 230, total_equal:18\n",
      "\n",
      "\n",
      "---- round:600 --------\n",
      "total_win:353, total_failure: 230, total_equal:18\n",
      "\n",
      "\n",
      "---- round:601 --------\n",
      "total_win:353, total_failure: 231, total_equal:18\n",
      "\n",
      "\n",
      "---- round:602 --------\n",
      "total_win:353, total_failure: 232, total_equal:18\n",
      "\n",
      "\n",
      "---- round:603 --------\n",
      "total_win:353, total_failure: 233, total_equal:18\n",
      "\n",
      "\n",
      "---- round:604 --------\n",
      "total_win:354, total_failure: 233, total_equal:18\n",
      "\n",
      "\n",
      "---- round:605 --------\n",
      "total_win:354, total_failure: 234, total_equal:18\n",
      "\n",
      "\n",
      "---- round:606 --------\n",
      "total_win:354, total_failure: 235, total_equal:18\n",
      "\n",
      "\n",
      "---- round:607 --------\n",
      "total_win:354, total_failure: 236, total_equal:18\n",
      "\n",
      "\n",
      "---- round:608 --------\n",
      "total_win:355, total_failure: 236, total_equal:18\n",
      "\n",
      "\n",
      "---- round:609 --------\n",
      "total_win:355, total_failure: 237, total_equal:18\n",
      "\n",
      "\n",
      "---- round:610 --------\n",
      "total_win:356, total_failure: 237, total_equal:18\n",
      "\n",
      "\n",
      "---- round:611 --------\n",
      "total_win:356, total_failure: 238, total_equal:18\n",
      "\n",
      "\n",
      "---- round:612 --------\n",
      "total_win:357, total_failure: 238, total_equal:18\n",
      "\n",
      "\n",
      "---- round:613 --------\n",
      "total_win:357, total_failure: 239, total_equal:18\n",
      "\n",
      "\n",
      "---- round:614 --------\n",
      "total_win:358, total_failure: 239, total_equal:18\n",
      "\n",
      "\n",
      "---- round:615 --------\n",
      "total_win:359, total_failure: 239, total_equal:18\n",
      "\n",
      "\n",
      "---- round:616 --------\n",
      "total_win:359, total_failure: 240, total_equal:18\n",
      "\n",
      "\n",
      "---- round:617 --------\n",
      "total_win:360, total_failure: 240, total_equal:18\n",
      "\n",
      "\n",
      "---- round:618 --------\n",
      "total_win:360, total_failure: 240, total_equal:19\n",
      "\n",
      "\n",
      "---- round:619 --------\n",
      "total_win:360, total_failure: 241, total_equal:19\n",
      "\n",
      "\n",
      "---- round:620 --------\n",
      "total_win:361, total_failure: 241, total_equal:19\n",
      "\n",
      "\n",
      "---- round:621 --------\n",
      "total_win:362, total_failure: 241, total_equal:19\n",
      "\n",
      "\n",
      "---- round:622 --------\n",
      "total_win:363, total_failure: 241, total_equal:19\n",
      "\n",
      "\n",
      "---- round:623 --------\n",
      "total_win:363, total_failure: 242, total_equal:19\n",
      "\n",
      "\n",
      "---- round:624 --------\n",
      "total_win:364, total_failure: 242, total_equal:19\n",
      "\n",
      "\n",
      "---- round:625 --------\n",
      "total_win:365, total_failure: 242, total_equal:19\n",
      "\n",
      "\n",
      "---- round:626 --------\n",
      "total_win:366, total_failure: 242, total_equal:19\n",
      "\n",
      "\n",
      "---- round:627 --------\n",
      "total_win:367, total_failure: 242, total_equal:19\n",
      "\n",
      "\n",
      "---- round:628 --------\n",
      "total_win:368, total_failure: 242, total_equal:19\n",
      "\n",
      "\n",
      "---- round:629 --------\n",
      "total_win:369, total_failure: 242, total_equal:19\n",
      "\n",
      "\n",
      "---- round:630 --------\n",
      "total_win:370, total_failure: 242, total_equal:19\n",
      "\n",
      "\n",
      "---- round:631 --------\n",
      "total_win:370, total_failure: 242, total_equal:20\n",
      "\n",
      "\n",
      "---- round:632 --------\n",
      "total_win:371, total_failure: 242, total_equal:20\n",
      "\n",
      "\n",
      "---- round:633 --------\n",
      "total_win:371, total_failure: 243, total_equal:20\n",
      "\n",
      "\n",
      "---- round:634 --------\n",
      "total_win:371, total_failure: 244, total_equal:20\n",
      "\n",
      "\n",
      "---- round:635 --------\n",
      "total_win:372, total_failure: 244, total_equal:20\n",
      "\n",
      "\n",
      "---- round:636 --------\n",
      "total_win:373, total_failure: 244, total_equal:20\n",
      "\n",
      "\n",
      "---- round:637 --------\n",
      "total_win:373, total_failure: 245, total_equal:20\n",
      "\n",
      "\n",
      "---- round:638 --------\n",
      "total_win:374, total_failure: 245, total_equal:20\n",
      "\n",
      "\n",
      "---- round:639 --------\n",
      "total_win:374, total_failure: 246, total_equal:20\n",
      "\n",
      "\n",
      "---- round:640 --------\n",
      "total_win:374, total_failure: 247, total_equal:20\n",
      "\n",
      "\n",
      "---- round:641 --------\n",
      "total_win:375, total_failure: 247, total_equal:20\n",
      "\n",
      "\n",
      "---- round:642 --------\n",
      "total_win:376, total_failure: 247, total_equal:20\n",
      "\n",
      "\n",
      "---- round:643 --------\n",
      "total_win:377, total_failure: 247, total_equal:20\n",
      "\n",
      "\n",
      "---- round:644 --------\n",
      "total_win:378, total_failure: 247, total_equal:20\n",
      "\n",
      "\n",
      "---- round:645 --------\n",
      "total_win:378, total_failure: 248, total_equal:20\n",
      "\n",
      "\n",
      "---- round:646 --------\n",
      "total_win:379, total_failure: 248, total_equal:20\n",
      "\n",
      "\n",
      "---- round:647 --------\n",
      "total_win:380, total_failure: 248, total_equal:20\n",
      "\n",
      "\n",
      "---- round:648 --------\n",
      "total_win:380, total_failure: 249, total_equal:20\n",
      "\n",
      "\n",
      "---- round:649 --------\n",
      "total_win:381, total_failure: 249, total_equal:20\n",
      "\n",
      "\n",
      "---- round:650 --------\n",
      "total_win:381, total_failure: 250, total_equal:20\n",
      "\n",
      "\n",
      "---- round:651 --------\n",
      "total_win:382, total_failure: 250, total_equal:20\n",
      "\n",
      "\n",
      "---- round:652 --------\n",
      "total_win:382, total_failure: 251, total_equal:20\n",
      "\n",
      "\n",
      "---- round:653 --------\n",
      "total_win:383, total_failure: 251, total_equal:20\n",
      "\n",
      "\n",
      "---- round:654 --------\n",
      "total_win:384, total_failure: 251, total_equal:20\n",
      "\n",
      "\n",
      "---- round:655 --------\n",
      "total_win:384, total_failure: 252, total_equal:20\n",
      "\n",
      "\n",
      "---- round:656 --------\n",
      "total_win:385, total_failure: 252, total_equal:20\n",
      "\n",
      "\n",
      "---- round:657 --------\n",
      "total_win:385, total_failure: 253, total_equal:20\n",
      "\n",
      "\n",
      "---- round:658 --------\n",
      "total_win:385, total_failure: 254, total_equal:20\n",
      "\n",
      "\n",
      "---- round:659 --------\n",
      "total_win:386, total_failure: 254, total_equal:20\n",
      "\n",
      "\n",
      "---- round:660 --------\n",
      "total_win:387, total_failure: 254, total_equal:20\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- round:661 --------\n",
      "total_win:387, total_failure: 255, total_equal:20\n",
      "\n",
      "\n",
      "---- round:662 --------\n",
      "total_win:388, total_failure: 255, total_equal:20\n",
      "\n",
      "\n",
      "---- round:663 --------\n",
      "total_win:389, total_failure: 255, total_equal:20\n",
      "\n",
      "\n",
      "---- round:664 --------\n",
      "total_win:389, total_failure: 256, total_equal:20\n",
      "\n",
      "\n",
      "---- round:665 --------\n",
      "total_win:390, total_failure: 256, total_equal:20\n",
      "\n",
      "\n",
      "---- round:666 --------\n",
      "total_win:391, total_failure: 256, total_equal:20\n",
      "\n",
      "\n",
      "---- round:667 --------\n",
      "total_win:391, total_failure: 256, total_equal:21\n",
      "\n",
      "\n",
      "---- round:668 --------\n",
      "total_win:392, total_failure: 256, total_equal:21\n",
      "\n",
      "\n",
      "---- round:669 --------\n",
      "total_win:393, total_failure: 256, total_equal:21\n",
      "\n",
      "\n",
      "---- round:670 --------\n",
      "total_win:393, total_failure: 257, total_equal:21\n",
      "\n",
      "\n",
      "---- round:671 --------\n",
      "total_win:394, total_failure: 257, total_equal:21\n",
      "\n",
      "\n",
      "---- round:672 --------\n",
      "total_win:394, total_failure: 258, total_equal:21\n",
      "\n",
      "\n",
      "---- round:673 --------\n",
      "total_win:394, total_failure: 259, total_equal:21\n",
      "\n",
      "\n",
      "---- round:674 --------\n",
      "total_win:395, total_failure: 259, total_equal:21\n",
      "\n",
      "\n",
      "---- round:675 --------\n",
      "total_win:395, total_failure: 260, total_equal:21\n",
      "\n",
      "\n",
      "---- round:676 --------\n",
      "total_win:396, total_failure: 260, total_equal:21\n",
      "\n",
      "\n",
      "---- round:677 --------\n",
      "total_win:397, total_failure: 260, total_equal:21\n",
      "\n",
      "\n",
      "---- round:678 --------\n",
      "total_win:397, total_failure: 261, total_equal:21\n",
      "\n",
      "\n",
      "---- round:679 --------\n",
      "total_win:398, total_failure: 261, total_equal:21\n",
      "\n",
      "\n",
      "---- round:680 --------\n",
      "total_win:398, total_failure: 261, total_equal:22\n",
      "\n",
      "\n",
      "---- round:681 --------\n",
      "total_win:398, total_failure: 262, total_equal:22\n",
      "\n",
      "\n",
      "---- round:682 --------\n",
      "total_win:398, total_failure: 263, total_equal:22\n",
      "\n",
      "\n",
      "---- round:683 --------\n",
      "total_win:399, total_failure: 263, total_equal:22\n",
      "\n",
      "\n",
      "---- round:684 --------\n",
      "total_win:400, total_failure: 263, total_equal:22\n",
      "\n",
      "\n",
      "---- round:685 --------\n",
      "total_win:401, total_failure: 263, total_equal:22\n",
      "\n",
      "\n",
      "---- round:686 --------\n",
      "total_win:402, total_failure: 263, total_equal:22\n",
      "\n",
      "\n",
      "---- round:687 --------\n",
      "total_win:403, total_failure: 263, total_equal:22\n",
      "\n",
      "\n",
      "---- round:688 --------\n",
      "total_win:404, total_failure: 263, total_equal:22\n",
      "\n",
      "\n",
      "---- round:689 --------\n",
      "total_win:405, total_failure: 263, total_equal:22\n",
      "\n",
      "\n",
      "---- round:690 --------\n",
      "total_win:406, total_failure: 263, total_equal:22\n",
      "\n",
      "\n",
      "---- round:691 --------\n",
      "total_win:407, total_failure: 263, total_equal:22\n",
      "\n",
      "\n",
      "---- round:692 --------\n",
      "total_win:408, total_failure: 263, total_equal:22\n",
      "\n",
      "\n",
      "---- round:693 --------\n",
      "total_win:409, total_failure: 263, total_equal:22\n",
      "\n",
      "\n",
      "---- round:694 --------\n",
      "total_win:409, total_failure: 264, total_equal:22\n",
      "\n",
      "\n",
      "---- round:695 --------\n",
      "total_win:410, total_failure: 264, total_equal:22\n",
      "\n",
      "\n",
      "---- round:696 --------\n",
      "total_win:410, total_failure: 265, total_equal:22\n",
      "\n",
      "\n",
      "---- round:697 --------\n",
      "total_win:411, total_failure: 265, total_equal:22\n",
      "\n",
      "\n",
      "---- round:698 --------\n",
      "total_win:412, total_failure: 265, total_equal:22\n",
      "\n",
      "\n",
      "---- round:699 --------\n",
      "total_win:413, total_failure: 265, total_equal:22\n",
      "\n",
      "\n",
      "---- round:700 --------\n",
      "total_win:414, total_failure: 265, total_equal:22\n",
      "\n",
      "\n",
      "---- round:701 --------\n",
      "total_win:415, total_failure: 265, total_equal:22\n",
      "\n",
      "\n",
      "---- round:702 --------\n",
      "total_win:416, total_failure: 265, total_equal:22\n",
      "\n",
      "\n",
      "---- round:703 --------\n",
      "total_win:417, total_failure: 265, total_equal:22\n",
      "\n",
      "\n",
      "---- round:704 --------\n",
      "total_win:418, total_failure: 265, total_equal:22\n",
      "\n",
      "\n",
      "---- round:705 --------\n",
      "total_win:418, total_failure: 266, total_equal:22\n",
      "\n",
      "\n",
      "---- round:706 --------\n",
      "total_win:419, total_failure: 266, total_equal:22\n",
      "\n",
      "\n",
      "---- round:707 --------\n",
      "total_win:420, total_failure: 266, total_equal:22\n",
      "\n",
      "\n",
      "---- round:708 --------\n",
      "total_win:421, total_failure: 266, total_equal:22\n",
      "\n",
      "\n",
      "---- round:709 --------\n",
      "total_win:421, total_failure: 267, total_equal:22\n",
      "\n",
      "\n",
      "---- round:710 --------\n",
      "total_win:422, total_failure: 267, total_equal:22\n",
      "\n",
      "\n",
      "---- round:711 --------\n",
      "total_win:423, total_failure: 267, total_equal:22\n",
      "\n",
      "\n",
      "---- round:712 --------\n",
      "total_win:424, total_failure: 267, total_equal:22\n",
      "\n",
      "\n",
      "---- round:713 --------\n",
      "total_win:425, total_failure: 267, total_equal:22\n",
      "\n",
      "\n",
      "---- round:714 --------\n",
      "total_win:426, total_failure: 267, total_equal:22\n",
      "\n",
      "\n",
      "---- round:715 --------\n",
      "total_win:427, total_failure: 267, total_equal:22\n",
      "\n",
      "\n",
      "---- round:716 --------\n",
      "total_win:427, total_failure: 268, total_equal:22\n",
      "\n",
      "\n",
      "---- round:717 --------\n",
      "total_win:427, total_failure: 268, total_equal:23\n",
      "\n",
      "\n",
      "---- round:718 --------\n",
      "total_win:428, total_failure: 268, total_equal:23\n",
      "\n",
      "\n",
      "---- round:719 --------\n",
      "total_win:428, total_failure: 269, total_equal:23\n",
      "\n",
      "\n",
      "---- round:720 --------\n",
      "total_win:428, total_failure: 270, total_equal:23\n",
      "\n",
      "\n",
      "---- round:721 --------\n",
      "total_win:429, total_failure: 270, total_equal:23\n",
      "\n",
      "\n",
      "---- round:722 --------\n",
      "total_win:430, total_failure: 270, total_equal:23\n",
      "\n",
      "\n",
      "---- round:723 --------\n",
      "total_win:431, total_failure: 270, total_equal:23\n",
      "\n",
      "\n",
      "---- round:724 --------\n",
      "total_win:431, total_failure: 271, total_equal:23\n",
      "\n",
      "\n",
      "---- round:725 --------\n",
      "total_win:432, total_failure: 271, total_equal:23\n",
      "\n",
      "\n",
      "---- round:726 --------\n",
      "total_win:433, total_failure: 271, total_equal:23\n",
      "\n",
      "\n",
      "---- round:727 --------\n",
      "total_win:433, total_failure: 272, total_equal:23\n",
      "\n",
      "\n",
      "---- round:728 --------\n",
      "total_win:434, total_failure: 272, total_equal:23\n",
      "\n",
      "\n",
      "---- round:729 --------\n",
      "total_win:435, total_failure: 272, total_equal:23\n",
      "\n",
      "\n",
      "---- round:730 --------\n",
      "total_win:435, total_failure: 273, total_equal:23\n",
      "\n",
      "\n",
      "---- round:731 --------\n",
      "total_win:436, total_failure: 273, total_equal:23\n",
      "\n",
      "\n",
      "---- round:732 --------\n",
      "total_win:437, total_failure: 273, total_equal:23\n",
      "\n",
      "\n",
      "---- round:733 --------\n",
      "total_win:438, total_failure: 273, total_equal:23\n",
      "\n",
      "\n",
      "---- round:734 --------\n",
      "total_win:439, total_failure: 273, total_equal:23\n",
      "\n",
      "\n",
      "---- round:735 --------\n",
      "total_win:439, total_failure: 274, total_equal:23\n",
      "\n",
      "\n",
      "---- round:736 --------\n",
      "total_win:439, total_failure: 275, total_equal:23\n",
      "\n",
      "\n",
      "---- round:737 --------\n",
      "total_win:440, total_failure: 275, total_equal:23\n",
      "\n",
      "\n",
      "---- round:738 --------\n",
      "total_win:440, total_failure: 276, total_equal:23\n",
      "\n",
      "\n",
      "---- round:739 --------\n",
      "total_win:441, total_failure: 276, total_equal:23\n",
      "\n",
      "\n",
      "---- round:740 --------\n",
      "total_win:442, total_failure: 276, total_equal:23\n",
      "\n",
      "\n",
      "---- round:741 --------\n",
      "total_win:443, total_failure: 276, total_equal:23\n",
      "\n",
      "\n",
      "---- round:742 --------\n",
      "total_win:444, total_failure: 276, total_equal:23\n",
      "\n",
      "\n",
      "---- round:743 --------\n",
      "total_win:444, total_failure: 277, total_equal:23\n",
      "\n",
      "\n",
      "---- round:744 --------\n",
      "total_win:445, total_failure: 277, total_equal:23\n",
      "\n",
      "\n",
      "---- round:745 --------\n",
      "total_win:446, total_failure: 277, total_equal:23\n",
      "\n",
      "\n",
      "---- round:746 --------\n",
      "total_win:447, total_failure: 277, total_equal:23\n",
      "\n",
      "\n",
      "---- round:747 --------\n",
      "total_win:448, total_failure: 277, total_equal:23\n",
      "\n",
      "\n",
      "---- round:748 --------\n",
      "total_win:449, total_failure: 277, total_equal:23\n",
      "\n",
      "\n",
      "---- round:749 --------\n",
      "total_win:449, total_failure: 278, total_equal:23\n",
      "\n",
      "\n",
      "---- round:750 --------\n",
      "total_win:449, total_failure: 279, total_equal:23\n",
      "\n",
      "\n",
      "---- round:751 --------\n",
      "total_win:450, total_failure: 279, total_equal:23\n",
      "\n",
      "\n",
      "---- round:752 --------\n",
      "total_win:450, total_failure: 280, total_equal:23\n",
      "\n",
      "\n",
      "---- round:753 --------\n",
      "total_win:451, total_failure: 280, total_equal:23\n",
      "\n",
      "\n",
      "---- round:754 --------\n",
      "total_win:452, total_failure: 280, total_equal:23\n",
      "\n",
      "\n",
      "---- round:755 --------\n",
      "total_win:453, total_failure: 280, total_equal:23\n",
      "\n",
      "\n",
      "---- round:756 --------\n",
      "total_win:454, total_failure: 280, total_equal:23\n",
      "\n",
      "\n",
      "---- round:757 --------\n",
      "total_win:455, total_failure: 280, total_equal:23\n",
      "\n",
      "\n",
      "---- round:758 --------\n",
      "total_win:455, total_failure: 281, total_equal:23\n",
      "\n",
      "\n",
      "---- round:759 --------\n",
      "total_win:456, total_failure: 281, total_equal:23\n",
      "\n",
      "\n",
      "---- round:760 --------\n",
      "total_win:456, total_failure: 282, total_equal:23\n",
      "\n",
      "\n",
      "---- round:761 --------\n",
      "total_win:457, total_failure: 282, total_equal:23\n",
      "\n",
      "\n",
      "---- round:762 --------\n",
      "total_win:457, total_failure: 283, total_equal:23\n",
      "\n",
      "\n",
      "---- round:763 --------\n",
      "total_win:458, total_failure: 283, total_equal:23\n",
      "\n",
      "\n",
      "---- round:764 --------\n",
      "total_win:459, total_failure: 283, total_equal:23\n",
      "\n",
      "\n",
      "---- round:765 --------\n",
      "total_win:460, total_failure: 283, total_equal:23\n",
      "\n",
      "\n",
      "---- round:766 --------\n",
      "total_win:461, total_failure: 283, total_equal:23\n",
      "\n",
      "\n",
      "---- round:767 --------\n",
      "total_win:461, total_failure: 283, total_equal:24\n",
      "\n",
      "\n",
      "---- round:768 --------\n",
      "total_win:462, total_failure: 283, total_equal:24\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- round:769 --------\n",
      "total_win:462, total_failure: 284, total_equal:24\n",
      "\n",
      "\n",
      "---- round:770 --------\n",
      "total_win:463, total_failure: 284, total_equal:24\n",
      "\n",
      "\n",
      "---- round:771 --------\n",
      "total_win:464, total_failure: 284, total_equal:24\n",
      "\n",
      "\n",
      "---- round:772 --------\n",
      "total_win:464, total_failure: 284, total_equal:25\n",
      "\n",
      "\n",
      "---- round:773 --------\n",
      "total_win:465, total_failure: 284, total_equal:25\n",
      "\n",
      "\n",
      "---- round:774 --------\n",
      "total_win:465, total_failure: 285, total_equal:25\n",
      "\n",
      "\n",
      "---- round:775 --------\n",
      "total_win:466, total_failure: 285, total_equal:25\n",
      "\n",
      "\n",
      "---- round:776 --------\n",
      "total_win:466, total_failure: 286, total_equal:25\n",
      "\n",
      "\n",
      "---- round:777 --------\n",
      "total_win:467, total_failure: 286, total_equal:25\n",
      "\n",
      "\n",
      "---- round:778 --------\n",
      "total_win:468, total_failure: 286, total_equal:25\n",
      "\n",
      "\n",
      "---- round:779 --------\n",
      "total_win:468, total_failure: 287, total_equal:25\n",
      "\n",
      "\n",
      "---- round:780 --------\n",
      "total_win:468, total_failure: 288, total_equal:25\n",
      "\n",
      "\n",
      "---- round:781 --------\n",
      "total_win:469, total_failure: 288, total_equal:25\n",
      "\n",
      "\n",
      "---- round:782 --------\n",
      "total_win:470, total_failure: 288, total_equal:25\n",
      "\n",
      "\n",
      "---- round:783 --------\n",
      "total_win:471, total_failure: 288, total_equal:25\n",
      "\n",
      "\n",
      "---- round:784 --------\n",
      "total_win:472, total_failure: 288, total_equal:25\n",
      "\n",
      "\n",
      "---- round:785 --------\n",
      "total_win:472, total_failure: 289, total_equal:25\n",
      "\n",
      "\n",
      "---- round:786 --------\n",
      "total_win:472, total_failure: 289, total_equal:26\n",
      "\n",
      "\n",
      "---- round:787 --------\n",
      "total_win:472, total_failure: 290, total_equal:26\n",
      "\n",
      "\n",
      "---- round:788 --------\n",
      "total_win:473, total_failure: 290, total_equal:26\n",
      "\n",
      "\n",
      "---- round:789 --------\n",
      "total_win:473, total_failure: 291, total_equal:26\n",
      "\n",
      "\n",
      "---- round:790 --------\n",
      "total_win:474, total_failure: 291, total_equal:26\n",
      "\n",
      "\n",
      "---- round:791 --------\n",
      "total_win:475, total_failure: 291, total_equal:26\n",
      "\n",
      "\n",
      "---- round:792 --------\n",
      "total_win:475, total_failure: 292, total_equal:26\n",
      "\n",
      "\n",
      "---- round:793 --------\n",
      "total_win:476, total_failure: 292, total_equal:26\n",
      "\n",
      "\n",
      "---- round:794 --------\n",
      "total_win:477, total_failure: 292, total_equal:26\n",
      "\n",
      "\n",
      "---- round:795 --------\n",
      "total_win:477, total_failure: 292, total_equal:27\n",
      "\n",
      "\n",
      "---- round:796 --------\n",
      "total_win:478, total_failure: 292, total_equal:27\n",
      "\n",
      "\n",
      "---- round:797 --------\n",
      "total_win:479, total_failure: 292, total_equal:27\n",
      "\n",
      "\n",
      "---- round:798 --------\n",
      "total_win:480, total_failure: 292, total_equal:27\n",
      "\n",
      "\n",
      "---- round:799 --------\n",
      "total_win:480, total_failure: 293, total_equal:27\n",
      "\n",
      "\n",
      "---- round:800 --------\n",
      "total_win:481, total_failure: 293, total_equal:27\n",
      "\n",
      "\n",
      "---- round:801 --------\n",
      "total_win:482, total_failure: 293, total_equal:27\n",
      "\n",
      "\n",
      "---- round:802 --------\n",
      "total_win:482, total_failure: 294, total_equal:27\n",
      "\n",
      "\n",
      "---- round:803 --------\n",
      "total_win:482, total_failure: 295, total_equal:27\n",
      "\n",
      "\n",
      "---- round:804 --------\n",
      "total_win:483, total_failure: 295, total_equal:27\n",
      "\n",
      "\n",
      "---- round:805 --------\n",
      "total_win:484, total_failure: 295, total_equal:27\n",
      "\n",
      "\n",
      "---- round:806 --------\n",
      "total_win:484, total_failure: 296, total_equal:27\n",
      "\n",
      "\n",
      "---- round:807 --------\n",
      "total_win:485, total_failure: 296, total_equal:27\n",
      "\n",
      "\n",
      "---- round:808 --------\n",
      "total_win:485, total_failure: 297, total_equal:27\n",
      "\n",
      "\n",
      "---- round:809 --------\n",
      "total_win:485, total_failure: 298, total_equal:27\n",
      "\n",
      "\n",
      "---- round:810 --------\n",
      "total_win:485, total_failure: 299, total_equal:27\n",
      "\n",
      "\n",
      "---- round:811 --------\n",
      "total_win:485, total_failure: 300, total_equal:27\n",
      "\n",
      "\n",
      "---- round:812 --------\n",
      "total_win:486, total_failure: 300, total_equal:27\n",
      "\n",
      "\n",
      "---- round:813 --------\n",
      "total_win:487, total_failure: 300, total_equal:27\n",
      "\n",
      "\n",
      "---- round:814 --------\n",
      "total_win:488, total_failure: 300, total_equal:27\n",
      "\n",
      "\n",
      "---- round:815 --------\n",
      "total_win:489, total_failure: 300, total_equal:27\n",
      "\n",
      "\n",
      "---- round:816 --------\n",
      "total_win:489, total_failure: 300, total_equal:28\n",
      "\n",
      "\n",
      "---- round:817 --------\n",
      "total_win:490, total_failure: 300, total_equal:28\n",
      "\n",
      "\n",
      "---- round:818 --------\n",
      "total_win:490, total_failure: 301, total_equal:28\n",
      "\n",
      "\n",
      "---- round:819 --------\n",
      "total_win:491, total_failure: 301, total_equal:28\n",
      "\n",
      "\n",
      "---- round:820 --------\n",
      "total_win:491, total_failure: 302, total_equal:28\n",
      "\n",
      "\n",
      "---- round:821 --------\n",
      "total_win:491, total_failure: 303, total_equal:28\n",
      "\n",
      "\n",
      "---- round:822 --------\n",
      "total_win:492, total_failure: 303, total_equal:28\n",
      "\n",
      "\n",
      "---- round:823 --------\n",
      "total_win:493, total_failure: 303, total_equal:28\n",
      "\n",
      "\n",
      "---- round:824 --------\n",
      "total_win:493, total_failure: 303, total_equal:29\n",
      "\n",
      "\n",
      "---- round:825 --------\n",
      "total_win:494, total_failure: 303, total_equal:29\n",
      "\n",
      "\n",
      "---- round:826 --------\n",
      "total_win:495, total_failure: 303, total_equal:29\n",
      "\n",
      "\n",
      "---- round:827 --------\n",
      "total_win:496, total_failure: 303, total_equal:29\n",
      "\n",
      "\n",
      "---- round:828 --------\n",
      "total_win:496, total_failure: 304, total_equal:29\n",
      "\n",
      "\n",
      "---- round:829 --------\n",
      "total_win:497, total_failure: 304, total_equal:29\n",
      "\n",
      "\n",
      "---- round:830 --------\n",
      "total_win:498, total_failure: 304, total_equal:29\n",
      "\n",
      "\n",
      "---- round:831 --------\n",
      "total_win:499, total_failure: 304, total_equal:29\n",
      "\n",
      "\n",
      "---- round:832 --------\n",
      "total_win:499, total_failure: 305, total_equal:29\n",
      "\n",
      "\n",
      "---- round:833 --------\n",
      "total_win:499, total_failure: 306, total_equal:29\n",
      "\n",
      "\n",
      "---- round:834 --------\n",
      "total_win:500, total_failure: 306, total_equal:29\n",
      "\n",
      "\n",
      "---- round:835 --------\n",
      "total_win:501, total_failure: 306, total_equal:29\n",
      "\n",
      "\n",
      "---- round:836 --------\n",
      "total_win:502, total_failure: 306, total_equal:29\n",
      "\n",
      "\n",
      "---- round:837 --------\n",
      "total_win:502, total_failure: 307, total_equal:29\n",
      "\n",
      "\n",
      "---- round:838 --------\n",
      "total_win:502, total_failure: 308, total_equal:29\n",
      "\n",
      "\n",
      "---- round:839 --------\n",
      "total_win:503, total_failure: 308, total_equal:29\n",
      "\n",
      "\n",
      "---- round:840 --------\n",
      "total_win:503, total_failure: 309, total_equal:29\n",
      "\n",
      "\n",
      "---- round:841 --------\n",
      "total_win:503, total_failure: 310, total_equal:29\n",
      "\n",
      "\n",
      "---- round:842 --------\n",
      "total_win:504, total_failure: 310, total_equal:29\n",
      "\n",
      "\n",
      "---- round:843 --------\n",
      "total_win:504, total_failure: 311, total_equal:29\n",
      "\n",
      "\n",
      "---- round:844 --------\n",
      "total_win:505, total_failure: 311, total_equal:29\n",
      "\n",
      "\n",
      "---- round:845 --------\n",
      "total_win:506, total_failure: 311, total_equal:29\n",
      "\n",
      "\n",
      "---- round:846 --------\n",
      "total_win:507, total_failure: 311, total_equal:29\n",
      "\n",
      "\n",
      "---- round:847 --------\n",
      "total_win:508, total_failure: 311, total_equal:29\n",
      "\n",
      "\n",
      "---- round:848 --------\n",
      "total_win:509, total_failure: 311, total_equal:29\n",
      "\n",
      "\n",
      "---- round:849 --------\n",
      "total_win:509, total_failure: 312, total_equal:29\n",
      "\n",
      "\n",
      "---- round:850 --------\n",
      "total_win:510, total_failure: 312, total_equal:29\n",
      "\n",
      "\n",
      "---- round:851 --------\n",
      "total_win:510, total_failure: 313, total_equal:29\n",
      "\n",
      "\n",
      "---- round:852 --------\n",
      "total_win:511, total_failure: 313, total_equal:29\n",
      "\n",
      "\n",
      "---- round:853 --------\n",
      "total_win:512, total_failure: 313, total_equal:29\n",
      "\n",
      "\n",
      "---- round:854 --------\n",
      "total_win:512, total_failure: 314, total_equal:29\n",
      "\n",
      "\n",
      "---- round:855 --------\n",
      "total_win:513, total_failure: 314, total_equal:29\n",
      "\n",
      "\n",
      "---- round:856 --------\n",
      "total_win:513, total_failure: 315, total_equal:29\n",
      "\n",
      "\n",
      "---- round:857 --------\n",
      "total_win:514, total_failure: 315, total_equal:29\n",
      "\n",
      "\n",
      "---- round:858 --------\n",
      "total_win:515, total_failure: 315, total_equal:29\n",
      "\n",
      "\n",
      "---- round:859 --------\n",
      "total_win:515, total_failure: 315, total_equal:30\n",
      "\n",
      "\n",
      "---- round:860 --------\n",
      "total_win:516, total_failure: 315, total_equal:30\n",
      "\n",
      "\n",
      "---- round:861 --------\n",
      "total_win:516, total_failure: 316, total_equal:30\n",
      "\n",
      "\n",
      "---- round:862 --------\n",
      "total_win:517, total_failure: 316, total_equal:30\n",
      "\n",
      "\n",
      "---- round:863 --------\n",
      "total_win:517, total_failure: 317, total_equal:30\n",
      "\n",
      "\n",
      "---- round:864 --------\n",
      "total_win:518, total_failure: 317, total_equal:30\n",
      "\n",
      "\n",
      "---- round:865 --------\n",
      "total_win:519, total_failure: 317, total_equal:30\n",
      "\n",
      "\n",
      "---- round:866 --------\n",
      "total_win:519, total_failure: 318, total_equal:30\n",
      "\n",
      "\n",
      "---- round:867 --------\n",
      "total_win:519, total_failure: 319, total_equal:30\n",
      "\n",
      "\n",
      "---- round:868 --------\n",
      "total_win:520, total_failure: 319, total_equal:30\n",
      "\n",
      "\n",
      "---- round:869 --------\n",
      "total_win:521, total_failure: 319, total_equal:30\n",
      "\n",
      "\n",
      "---- round:870 --------\n",
      "total_win:522, total_failure: 319, total_equal:30\n",
      "\n",
      "\n",
      "---- round:871 --------\n",
      "total_win:522, total_failure: 320, total_equal:30\n",
      "\n",
      "\n",
      "---- round:872 --------\n",
      "total_win:522, total_failure: 321, total_equal:30\n",
      "\n",
      "\n",
      "---- round:873 --------\n",
      "total_win:523, total_failure: 321, total_equal:30\n",
      "\n",
      "\n",
      "---- round:874 --------\n",
      "total_win:523, total_failure: 322, total_equal:30\n",
      "\n",
      "\n",
      "---- round:875 --------\n",
      "total_win:524, total_failure: 322, total_equal:30\n",
      "\n",
      "\n",
      "---- round:876 --------\n",
      "total_win:524, total_failure: 323, total_equal:30\n",
      "\n",
      "\n",
      "---- round:877 --------\n",
      "total_win:525, total_failure: 323, total_equal:30\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- round:878 --------\n",
      "total_win:525, total_failure: 323, total_equal:31\n",
      "\n",
      "\n",
      "---- round:879 --------\n",
      "total_win:526, total_failure: 323, total_equal:31\n",
      "\n",
      "\n",
      "---- round:880 --------\n",
      "total_win:527, total_failure: 323, total_equal:31\n",
      "\n",
      "\n",
      "---- round:881 --------\n",
      "total_win:528, total_failure: 323, total_equal:31\n",
      "\n",
      "\n",
      "---- round:882 --------\n",
      "total_win:529, total_failure: 323, total_equal:31\n",
      "\n",
      "\n",
      "---- round:883 --------\n",
      "total_win:529, total_failure: 324, total_equal:31\n",
      "\n",
      "\n",
      "---- round:884 --------\n",
      "total_win:530, total_failure: 324, total_equal:31\n",
      "\n",
      "\n",
      "---- round:885 --------\n",
      "total_win:530, total_failure: 324, total_equal:32\n",
      "\n",
      "\n",
      "---- round:886 --------\n",
      "total_win:530, total_failure: 325, total_equal:32\n",
      "\n",
      "\n",
      "---- round:887 --------\n",
      "total_win:531, total_failure: 325, total_equal:32\n",
      "\n",
      "\n",
      "---- round:888 --------\n",
      "total_win:532, total_failure: 325, total_equal:32\n",
      "\n",
      "\n",
      "---- round:889 --------\n",
      "total_win:533, total_failure: 325, total_equal:32\n",
      "\n",
      "\n",
      "---- round:890 --------\n",
      "total_win:534, total_failure: 325, total_equal:32\n",
      "\n",
      "\n",
      "---- round:891 --------\n",
      "total_win:534, total_failure: 326, total_equal:32\n",
      "\n",
      "\n",
      "---- round:892 --------\n",
      "total_win:534, total_failure: 327, total_equal:32\n",
      "\n",
      "\n",
      "---- round:893 --------\n",
      "total_win:534, total_failure: 328, total_equal:32\n",
      "\n",
      "\n",
      "---- round:894 --------\n",
      "total_win:534, total_failure: 329, total_equal:32\n",
      "\n",
      "\n",
      "---- round:895 --------\n",
      "total_win:535, total_failure: 329, total_equal:32\n",
      "\n",
      "\n",
      "---- round:896 --------\n",
      "total_win:536, total_failure: 329, total_equal:32\n",
      "\n",
      "\n",
      "---- round:897 --------\n",
      "total_win:537, total_failure: 329, total_equal:32\n",
      "\n",
      "\n",
      "---- round:898 --------\n",
      "total_win:537, total_failure: 330, total_equal:32\n",
      "\n",
      "\n",
      "---- round:899 --------\n",
      "total_win:537, total_failure: 331, total_equal:32\n",
      "\n",
      "\n",
      "---- round:900 --------\n",
      "total_win:538, total_failure: 331, total_equal:32\n",
      "\n",
      "\n",
      "---- round:901 --------\n",
      "total_win:538, total_failure: 332, total_equal:32\n",
      "\n",
      "\n",
      "---- round:902 --------\n",
      "total_win:538, total_failure: 333, total_equal:32\n",
      "\n",
      "\n",
      "---- round:903 --------\n",
      "total_win:538, total_failure: 334, total_equal:32\n",
      "\n",
      "\n",
      "---- round:904 --------\n",
      "total_win:539, total_failure: 334, total_equal:32\n",
      "\n",
      "\n",
      "---- round:905 --------\n",
      "total_win:540, total_failure: 334, total_equal:32\n",
      "\n",
      "\n",
      "---- round:906 --------\n",
      "total_win:541, total_failure: 334, total_equal:32\n",
      "\n",
      "\n",
      "---- round:907 --------\n",
      "total_win:541, total_failure: 335, total_equal:32\n",
      "\n",
      "\n",
      "---- round:908 --------\n",
      "total_win:542, total_failure: 335, total_equal:32\n",
      "\n",
      "\n",
      "---- round:909 --------\n",
      "total_win:543, total_failure: 335, total_equal:32\n",
      "\n",
      "\n",
      "---- round:910 --------\n",
      "total_win:543, total_failure: 336, total_equal:32\n",
      "\n",
      "\n",
      "---- round:911 --------\n",
      "total_win:544, total_failure: 336, total_equal:32\n",
      "\n",
      "\n",
      "---- round:912 --------\n",
      "total_win:545, total_failure: 336, total_equal:32\n",
      "\n",
      "\n",
      "---- round:913 --------\n",
      "total_win:546, total_failure: 336, total_equal:32\n",
      "\n",
      "\n",
      "---- round:914 --------\n",
      "total_win:546, total_failure: 337, total_equal:32\n",
      "\n",
      "\n",
      "---- round:915 --------\n",
      "total_win:547, total_failure: 337, total_equal:32\n",
      "\n",
      "\n",
      "---- round:916 --------\n",
      "total_win:547, total_failure: 338, total_equal:32\n",
      "\n",
      "\n",
      "---- round:917 --------\n",
      "total_win:547, total_failure: 338, total_equal:33\n",
      "\n",
      "\n",
      "---- round:918 --------\n",
      "total_win:548, total_failure: 338, total_equal:33\n",
      "\n",
      "\n",
      "---- round:919 --------\n",
      "total_win:548, total_failure: 339, total_equal:33\n",
      "\n",
      "\n",
      "---- round:920 --------\n",
      "total_win:549, total_failure: 339, total_equal:33\n",
      "\n",
      "\n",
      "---- round:921 --------\n",
      "total_win:549, total_failure: 340, total_equal:33\n",
      "\n",
      "\n",
      "---- round:922 --------\n",
      "total_win:549, total_failure: 341, total_equal:33\n",
      "\n",
      "\n",
      "---- round:923 --------\n",
      "total_win:550, total_failure: 341, total_equal:33\n",
      "\n",
      "\n",
      "---- round:924 --------\n",
      "total_win:550, total_failure: 342, total_equal:33\n",
      "\n",
      "\n",
      "---- round:925 --------\n",
      "total_win:551, total_failure: 342, total_equal:33\n",
      "\n",
      "\n",
      "---- round:926 --------\n",
      "total_win:552, total_failure: 342, total_equal:33\n",
      "\n",
      "\n",
      "---- round:927 --------\n",
      "total_win:552, total_failure: 343, total_equal:33\n",
      "\n",
      "\n",
      "---- round:928 --------\n",
      "total_win:553, total_failure: 343, total_equal:33\n",
      "\n",
      "\n",
      "---- round:929 --------\n",
      "total_win:553, total_failure: 343, total_equal:34\n",
      "\n",
      "\n",
      "---- round:930 --------\n",
      "total_win:554, total_failure: 343, total_equal:34\n",
      "\n",
      "\n",
      "---- round:931 --------\n",
      "total_win:555, total_failure: 343, total_equal:34\n",
      "\n",
      "\n",
      "---- round:932 --------\n",
      "total_win:556, total_failure: 343, total_equal:34\n",
      "\n",
      "\n",
      "---- round:933 --------\n",
      "total_win:557, total_failure: 343, total_equal:34\n",
      "\n",
      "\n",
      "---- round:934 --------\n",
      "total_win:557, total_failure: 344, total_equal:34\n",
      "\n",
      "\n",
      "---- round:935 --------\n",
      "total_win:558, total_failure: 344, total_equal:34\n",
      "\n",
      "\n",
      "---- round:936 --------\n",
      "total_win:558, total_failure: 345, total_equal:34\n",
      "\n",
      "\n",
      "---- round:937 --------\n",
      "total_win:559, total_failure: 345, total_equal:34\n",
      "\n",
      "\n",
      "---- round:938 --------\n",
      "total_win:560, total_failure: 345, total_equal:34\n",
      "\n",
      "\n",
      "---- round:939 --------\n",
      "total_win:560, total_failure: 346, total_equal:34\n",
      "\n",
      "\n",
      "---- round:940 --------\n",
      "total_win:561, total_failure: 346, total_equal:34\n",
      "\n",
      "\n",
      "---- round:941 --------\n",
      "total_win:562, total_failure: 346, total_equal:34\n",
      "\n",
      "\n",
      "---- round:942 --------\n",
      "total_win:563, total_failure: 346, total_equal:34\n",
      "\n",
      "\n",
      "---- round:943 --------\n",
      "total_win:564, total_failure: 346, total_equal:34\n",
      "\n",
      "\n",
      "---- round:944 --------\n",
      "total_win:565, total_failure: 346, total_equal:34\n",
      "\n",
      "\n",
      "---- round:945 --------\n",
      "total_win:566, total_failure: 346, total_equal:34\n",
      "\n",
      "\n",
      "---- round:946 --------\n",
      "total_win:567, total_failure: 346, total_equal:34\n",
      "\n",
      "\n",
      "---- round:947 --------\n",
      "total_win:568, total_failure: 346, total_equal:34\n",
      "\n",
      "\n",
      "---- round:948 --------\n",
      "total_win:568, total_failure: 347, total_equal:34\n",
      "\n",
      "\n",
      "---- round:949 --------\n",
      "total_win:569, total_failure: 347, total_equal:34\n",
      "\n",
      "\n",
      "---- round:950 --------\n",
      "total_win:570, total_failure: 347, total_equal:34\n",
      "\n",
      "\n",
      "---- round:951 --------\n",
      "total_win:570, total_failure: 348, total_equal:34\n",
      "\n",
      "\n",
      "---- round:952 --------\n",
      "total_win:571, total_failure: 348, total_equal:34\n",
      "\n",
      "\n",
      "---- round:953 --------\n",
      "total_win:572, total_failure: 348, total_equal:34\n",
      "\n",
      "\n",
      "---- round:954 --------\n",
      "total_win:572, total_failure: 349, total_equal:34\n",
      "\n",
      "\n",
      "---- round:955 --------\n",
      "total_win:572, total_failure: 350, total_equal:34\n",
      "\n",
      "\n",
      "---- round:956 --------\n",
      "total_win:573, total_failure: 350, total_equal:34\n",
      "\n",
      "\n",
      "---- round:957 --------\n",
      "total_win:574, total_failure: 350, total_equal:34\n",
      "\n",
      "\n",
      "---- round:958 --------\n",
      "total_win:575, total_failure: 350, total_equal:34\n",
      "\n",
      "\n",
      "---- round:959 --------\n",
      "total_win:575, total_failure: 351, total_equal:34\n",
      "\n",
      "\n",
      "---- round:960 --------\n",
      "total_win:575, total_failure: 352, total_equal:34\n",
      "\n",
      "\n",
      "---- round:961 --------\n",
      "total_win:575, total_failure: 353, total_equal:34\n",
      "\n",
      "\n",
      "---- round:962 --------\n",
      "total_win:576, total_failure: 353, total_equal:34\n",
      "\n",
      "\n",
      "---- round:963 --------\n",
      "total_win:576, total_failure: 354, total_equal:34\n",
      "\n",
      "\n",
      "---- round:964 --------\n",
      "total_win:577, total_failure: 354, total_equal:34\n",
      "\n",
      "\n",
      "---- round:965 --------\n",
      "total_win:578, total_failure: 354, total_equal:34\n",
      "\n",
      "\n",
      "---- round:966 --------\n",
      "total_win:579, total_failure: 354, total_equal:34\n",
      "\n",
      "\n",
      "---- round:967 --------\n",
      "total_win:579, total_failure: 355, total_equal:34\n",
      "\n",
      "\n",
      "---- round:968 --------\n",
      "total_win:579, total_failure: 356, total_equal:34\n",
      "\n",
      "\n",
      "---- round:969 --------\n",
      "total_win:580, total_failure: 356, total_equal:34\n",
      "\n",
      "\n",
      "---- round:970 --------\n",
      "total_win:581, total_failure: 356, total_equal:34\n",
      "\n",
      "\n",
      "---- round:971 --------\n",
      "total_win:582, total_failure: 356, total_equal:34\n",
      "\n",
      "\n",
      "---- round:972 --------\n",
      "total_win:583, total_failure: 356, total_equal:34\n",
      "\n",
      "\n",
      "---- round:973 --------\n",
      "total_win:584, total_failure: 356, total_equal:34\n",
      "\n",
      "\n",
      "---- round:974 --------\n",
      "total_win:584, total_failure: 357, total_equal:34\n",
      "\n",
      "\n",
      "---- round:975 --------\n",
      "total_win:585, total_failure: 357, total_equal:34\n",
      "\n",
      "\n",
      "---- round:976 --------\n",
      "total_win:586, total_failure: 357, total_equal:34\n",
      "\n",
      "\n",
      "---- round:977 --------\n",
      "total_win:587, total_failure: 357, total_equal:34\n",
      "\n",
      "\n",
      "---- round:978 --------\n",
      "total_win:588, total_failure: 357, total_equal:34\n",
      "\n",
      "\n",
      "---- round:979 --------\n",
      "total_win:589, total_failure: 357, total_equal:34\n",
      "\n",
      "\n",
      "---- round:980 --------\n",
      "total_win:590, total_failure: 357, total_equal:34\n",
      "\n",
      "\n",
      "---- round:981 --------\n",
      "total_win:590, total_failure: 358, total_equal:34\n",
      "\n",
      "\n",
      "---- round:982 --------\n",
      "total_win:590, total_failure: 358, total_equal:35\n",
      "\n",
      "\n",
      "---- round:983 --------\n",
      "total_win:590, total_failure: 359, total_equal:35\n",
      "\n",
      "\n",
      "---- round:984 --------\n",
      "total_win:591, total_failure: 359, total_equal:35\n",
      "\n",
      "\n",
      "---- round:985 --------\n",
      "total_win:591, total_failure: 360, total_equal:35\n",
      "\n",
      "\n",
      "---- round:986 --------\n",
      "total_win:591, total_failure: 361, total_equal:35\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "---- round:987 --------\n",
      "total_win:591, total_failure: 362, total_equal:35\n",
      "\n",
      "\n",
      "---- round:988 --------\n",
      "total_win:592, total_failure: 362, total_equal:35\n",
      "\n",
      "\n",
      "---- round:989 --------\n",
      "total_win:592, total_failure: 362, total_equal:36\n",
      "\n",
      "\n",
      "---- round:990 --------\n",
      "total_win:593, total_failure: 362, total_equal:36\n",
      "\n",
      "\n",
      "---- round:991 --------\n",
      "total_win:594, total_failure: 362, total_equal:36\n",
      "\n",
      "\n",
      "---- round:992 --------\n",
      "total_win:595, total_failure: 362, total_equal:36\n",
      "\n",
      "\n",
      "---- round:993 --------\n",
      "total_win:596, total_failure: 362, total_equal:36\n",
      "\n",
      "\n",
      "---- round:994 --------\n",
      "total_win:596, total_failure: 363, total_equal:36\n",
      "\n",
      "\n",
      "---- round:995 --------\n",
      "total_win:597, total_failure: 363, total_equal:36\n",
      "\n",
      "\n",
      "---- round:996 --------\n",
      "total_win:598, total_failure: 363, total_equal:36\n",
      "\n",
      "\n",
      "---- round:997 --------\n",
      "total_win:598, total_failure: 364, total_equal:36\n",
      "\n",
      "\n",
      "---- round:998 --------\n",
      "total_win:598, total_failure: 365, total_equal:36\n",
      "\n",
      "\n",
      "---- round:999 --------\n",
      "total_win:599, total_failure: 365, total_equal:36\n",
      "\n",
      "train time: 173.30751538276672\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "from gym_reversi import ReversiEnv\n",
    "\n",
    "PolicyModel = PPO\n",
    "\n",
    "opponent_model = \"random\"\n",
    "# opponent_model = PolicyModel.load(\"models/Reversi_ppo/model\")\n",
    "\n",
    "env = ReversiEnv(opponent=\"random\", board_size=8, player_color='white', is_train=False,\n",
    "                 greedy_rate=0, verbose=0)\n",
    "\n",
    "# model = PolicyModel.load(\"models/Reversi_ppo/model\")\n",
    "# model = PolicyModel.load('models/model_240w')\n",
    "# model = torch.load('models/model_240w.pth')\n",
    "# model = PolicyModel.load(\"models/ppo_8x8_cnn/model_1500w\")\n",
    "\n",
    "policy_model.load_state_dict(torch.load(\"models/ppo_8x8_cnn/model_1480w_state_dict.pt\"))\n",
    "model = policy_model\n",
    "\n",
    "max_round = 1000\n",
    "\n",
    "total_round = 0\n",
    "total_win = 0\n",
    "total_failure = 0\n",
    "total_equal = 0\n",
    "\n",
    "\n",
    "t0=time.time()\n",
    "obs, info = env.reset()\n",
    "while total_round < max_round:\n",
    "    action, _states = model.predict(obs, deterministic=True)\n",
    "    action = int(action)\n",
    "    obs, rewards, dones, truncated, info = env.step(action)\n",
    "\n",
    "#     print(f\"---- round:{total_round} --------\")\n",
    "#     print(f\"action: {action}\")\n",
    "#     env.render(\"human\")\n",
    "\n",
    "    if dones:\n",
    "        print(f\"\\n---- round:{total_round} --------\")\n",
    "#         env.render(\"human\")\n",
    "        obs, info = env.reset()\n",
    "        total_round += 1\n",
    "        if rewards > 0:\n",
    "            total_win+=1\n",
    "        elif rewards < 0:\n",
    "            total_failure += 1\n",
    "        else:\n",
    "            total_equal += 1\n",
    "\n",
    "        print(f\"total_win:{total_win}, total_failure: {total_failure}, total_equal:{total_equal}\\n\")\n",
    "\n",
    "# print(f\"total_win:{total_win}, total_failure: {total_failure}\")\n",
    "print(f\"train time: {time.time()-t0}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b3fcf3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load model from self.model_path: models/Reversi_ppo_8x8/model error\n",
      "Using cuda device\n",
      "Logging to models/Reversi_ppo_8x8/PPO_1\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1.03     |\n",
      "|    ep_rew_mean     | -1       |\n",
      "| time/              |          |\n",
      "|    fps             | 107      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 4        |\n",
      "|    total_timesteps | 512      |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.05         |\n",
      "|    ep_rew_mean          | -1           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 149          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 6            |\n",
      "|    total_timesteps      | 1024         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0073447656 |\n",
      "|    clip_fraction        | 0.333        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.15        |\n",
      "|    explained_variance   | -769         |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.1         |\n",
      "|    n_updates            | 4            |\n",
      "|    policy_gradient_loss | -0.0305      |\n",
      "|    value_loss           | 0.142        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.08        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 173         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 1536        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.007036981 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | -17.5       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0688     |\n",
      "|    n_updates            | 8           |\n",
      "|    policy_gradient_loss | -0.0206     |\n",
      "|    value_loss           | 0.000552    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.09        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 190         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006736666 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | -86         |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0866     |\n",
      "|    n_updates            | 12          |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 0.00022     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.1         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 204         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 2560        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010517114 |\n",
      "|    clip_fraction        | 0.326       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -4.09       |\n",
      "|    explained_variance   | -49.8       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0756     |\n",
      "|    n_updates            | 16          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    value_loss           | 0.000651    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1.12         |\n",
      "|    ep_rew_mean          | -1           |\n",
      "| time/                   |              |\n",
      "|    fps                  | 214          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 3072         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0076154075 |\n",
      "|    clip_fraction        | 0.371        |\n",
      "|    clip_range           | 0.1          |\n",
      "|    entropy_loss         | -4.06        |\n",
      "|    explained_variance   | -18.8        |\n",
      "|    learning_rate        | 0.00025      |\n",
      "|    loss                 | -0.0977      |\n",
      "|    n_updates            | 20           |\n",
      "|    policy_gradient_loss | -0.0265      |\n",
      "|    value_loss           | 0.000326     |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.14        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 221         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 3584        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021294396 |\n",
      "|    clip_fraction        | 0.549       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -4.02       |\n",
      "|    explained_variance   | -14.2       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0914     |\n",
      "|    n_updates            | 24          |\n",
      "|    policy_gradient_loss | -0.0358     |\n",
      "|    value_loss           | 0.000164    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.29        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 228         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023197766 |\n",
      "|    clip_fraction        | 0.539       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -3.89       |\n",
      "|    explained_variance   | -49.9       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0988     |\n",
      "|    n_updates            | 28          |\n",
      "|    policy_gradient_loss | -0.0343     |\n",
      "|    value_loss           | 0.000791    |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"reversi_model_train.py\", line 225, in <module>\n",
      "    run_train(sys.argv[1:])\n",
      "  File \"reversi_model_train.py\", line 220, in run_train\n",
      "    print(f\"end time: {time2str(time.time())}\")\n",
      "NameError: name 'time2str' is not defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.32        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 234         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 4608        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014122702 |\n",
      "|    clip_fraction        | 0.53        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -3.8        |\n",
      "|    explained_variance   | -27.1       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0721     |\n",
      "|    n_updates            | 32          |\n",
      "|    policy_gradient_loss | -0.027      |\n",
      "|    value_loss           | 0.000412    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.39        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 238         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012754567 |\n",
      "|    clip_fraction        | 0.541       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -3.7        |\n",
      "|    explained_variance   | -8.26       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0708     |\n",
      "|    n_updates            | 36          |\n",
      "|    policy_gradient_loss | -0.0329     |\n",
      "|    value_loss           | 0.000302    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.49        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 242         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 5632        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012073407 |\n",
      "|    clip_fraction        | 0.535       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -3.62       |\n",
      "|    explained_variance   | -7.39       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0734     |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0344     |\n",
      "|    value_loss           | 0.000434    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.53        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 245         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012966257 |\n",
      "|    clip_fraction        | 0.475       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -3.55       |\n",
      "|    explained_variance   | -12.2       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0766     |\n",
      "|    n_updates            | 44          |\n",
      "|    policy_gradient_loss | -0.0302     |\n",
      "|    value_loss           | 0.000808    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.67        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 248         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 6656        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013435766 |\n",
      "|    clip_fraction        | 0.472       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -3.45       |\n",
      "|    explained_variance   | -17.6       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0578     |\n",
      "|    n_updates            | 48          |\n",
      "|    policy_gradient_loss | -0.0293     |\n",
      "|    value_loss           | 0.000401    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.62        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 250         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014273578 |\n",
      "|    clip_fraction        | 0.477       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -3.34       |\n",
      "|    explained_variance   | -8.57       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0713     |\n",
      "|    n_updates            | 52          |\n",
      "|    policy_gradient_loss | -0.0279     |\n",
      "|    value_loss           | 0.000379    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.63        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 252         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 7680        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009905947 |\n",
      "|    clip_fraction        | 0.323       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -3.3        |\n",
      "|    explained_variance   | -19.4       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0972     |\n",
      "|    n_updates            | 56          |\n",
      "|    policy_gradient_loss | -0.025      |\n",
      "|    value_loss           | 0.000366    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.77        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 255         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011325691 |\n",
      "|    clip_fraction        | 0.448       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -3.23       |\n",
      "|    explained_variance   | -11.5       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0678     |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    value_loss           | 0.000451    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.7         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 256         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 8704        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010256808 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -3.2        |\n",
      "|    explained_variance   | -9.42       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0765     |\n",
      "|    n_updates            | 64          |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    value_loss           | 0.000675    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.83        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 258         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027851718 |\n",
      "|    clip_fraction        | 0.542       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -3.06       |\n",
      "|    explained_variance   | -5.06       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0664     |\n",
      "|    n_updates            | 68          |\n",
      "|    policy_gradient_loss | -0.0381     |\n",
      "|    value_loss           | 0.000186    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1.98        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 260         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 9728        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014484894 |\n",
      "|    clip_fraction        | 0.386       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.93       |\n",
      "|    explained_variance   | -5.76       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0557     |\n",
      "|    n_updates            | 72          |\n",
      "|    policy_gradient_loss | -0.0247     |\n",
      "|    value_loss           | 0.000507    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.1         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 261         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008986317 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.92       |\n",
      "|    explained_variance   | -14.7       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0612     |\n",
      "|    n_updates            | 76          |\n",
      "|    policy_gradient_loss | -0.0241     |\n",
      "|    value_loss           | 0.000528    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.04       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 263        |\n",
      "|    iterations           | 21         |\n",
      "|    time_elapsed         | 40         |\n",
      "|    total_timesteps      | 10752      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00951506 |\n",
      "|    clip_fraction        | 0.317      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -2.78      |\n",
      "|    explained_variance   | -3.6       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0488    |\n",
      "|    n_updates            | 80         |\n",
      "|    policy_gradient_loss | -0.0197    |\n",
      "|    value_loss           | 0.000408   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.04        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 264         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010902087 |\n",
      "|    clip_fraction        | 0.337       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.76       |\n",
      "|    explained_variance   | -9.77       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0803     |\n",
      "|    n_updates            | 84          |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    value_loss           | 0.000399    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.1        |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 265        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 44         |\n",
      "|    total_timesteps      | 11776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01257821 |\n",
      "|    clip_fraction        | 0.374      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -2.66      |\n",
      "|    explained_variance   | -9.6       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.061     |\n",
      "|    n_updates            | 88         |\n",
      "|    policy_gradient_loss | -0.0248    |\n",
      "|    value_loss           | 0.00196    |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.2        |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 266        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00704157 |\n",
      "|    clip_fraction        | 0.335      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -2.67      |\n",
      "|    explained_variance   | -20.4      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.043     |\n",
      "|    n_updates            | 92         |\n",
      "|    policy_gradient_loss | -0.0187    |\n",
      "|    value_loss           | 0.000737   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.26        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014053014 |\n",
      "|    clip_fraction        | 0.371       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.62       |\n",
      "|    explained_variance   | -4.06       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0738     |\n",
      "|    n_updates            | 96          |\n",
      "|    policy_gradient_loss | -0.0251     |\n",
      "|    value_loss           | 0.00029     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.2         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 268         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012740225 |\n",
      "|    clip_fraction        | 0.377       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.58       |\n",
      "|    explained_variance   | -2.75       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0407     |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0207     |\n",
      "|    value_loss           | 0.000312    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.21        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 269         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 13824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012026594 |\n",
      "|    clip_fraction        | 0.364       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.56       |\n",
      "|    explained_variance   | -12.8       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0681     |\n",
      "|    n_updates            | 104         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 0.000657    |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 2.23      |\n",
      "|    ep_rew_mean          | -1        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 270       |\n",
      "|    iterations           | 28        |\n",
      "|    time_elapsed         | 53        |\n",
      "|    total_timesteps      | 14336     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0105237 |\n",
      "|    clip_fraction        | 0.378     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -2.53     |\n",
      "|    explained_variance   | -4.18     |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.0494   |\n",
      "|    n_updates            | 108       |\n",
      "|    policy_gradient_loss | -0.0224   |\n",
      "|    value_loss           | 0.000392  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.34        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 271         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 14848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012286808 |\n",
      "|    clip_fraction        | 0.379       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.49       |\n",
      "|    explained_variance   | -3.96       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0554     |\n",
      "|    n_updates            | 112         |\n",
      "|    policy_gradient_loss | -0.0217     |\n",
      "|    value_loss           | 0.000496    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.43        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009772992 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.44       |\n",
      "|    explained_variance   | -5.49       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0712     |\n",
      "|    n_updates            | 116         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    value_loss           | 0.000378    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 272         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 15872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011111824 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.36       |\n",
      "|    explained_variance   | -4.56       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0518     |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    value_loss           | 0.00051     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.47        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 273         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009870542 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.31       |\n",
      "|    explained_variance   | -9.11       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0713     |\n",
      "|    n_updates            | 124         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 0.000506    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.43        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 16896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013210797 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.33       |\n",
      "|    explained_variance   | -2.81       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0397     |\n",
      "|    n_updates            | 128         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 0.000244    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.49        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 274         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010187581 |\n",
      "|    clip_fraction        | 0.39        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.32       |\n",
      "|    explained_variance   | -4.65       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0693     |\n",
      "|    n_updates            | 132         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 0.000945    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.39        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 17920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011110387 |\n",
      "|    clip_fraction        | 0.37        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.32       |\n",
      "|    explained_variance   | -4.87       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0638     |\n",
      "|    n_updates            | 136         |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    value_loss           | 0.000336    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.57        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 275         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011893211 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.29       |\n",
      "|    explained_variance   | -2.32       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.083      |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0189     |\n",
      "|    value_loss           | 0.000239    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.63        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 276         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 18944       |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016008945 |\n",
      "|    clip_fraction        | 0.403       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | -1.93       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0448     |\n",
      "|    n_updates            | 144         |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    value_loss           | 0.000332    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.56        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011021307 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.27       |\n",
      "|    explained_variance   | -6.96       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0599     |\n",
      "|    n_updates            | 148         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    value_loss           | 0.000732    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.59        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 277         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 19968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017065762 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.23       |\n",
      "|    explained_variance   | -1.33       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0593     |\n",
      "|    n_updates            | 152         |\n",
      "|    policy_gradient_loss | -0.0242     |\n",
      "|    value_loss           | 0.00269     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.59        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 278         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012844294 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.24       |\n",
      "|    explained_variance   | -6.97       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.049      |\n",
      "|    n_updates            | 156         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 0.000803    |\n",
      "-----------------------------------------\n",
      "train time: 74.24348425865173\n",
      "Logging to models/Reversi_ppo_8x8/PPO_2\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 2.67     |\n",
      "|    ep_rew_mean     | -1       |\n",
      "| time/              |          |\n",
      "|    fps             | 409      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 512      |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.72        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 331         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 1024        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014150092 |\n",
      "|    clip_fraction        | 0.368       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.19       |\n",
      "|    explained_variance   | -2.67       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0624     |\n",
      "|    n_updates            | 164         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    value_loss           | 0.000319    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.7         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 310         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 1536        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016221175 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.15       |\n",
      "|    explained_variance   | -2.13       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0626     |\n",
      "|    n_updates            | 168         |\n",
      "|    policy_gradient_loss | -0.0177     |\n",
      "|    value_loss           | 0.000517    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.83       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 300        |\n",
      "|    iterations           | 4          |\n",
      "|    time_elapsed         | 6          |\n",
      "|    total_timesteps      | 2048       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01399245 |\n",
      "|    clip_fraction        | 0.321      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -2.09      |\n",
      "|    explained_variance   | -4.08      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0486    |\n",
      "|    n_updates            | 172        |\n",
      "|    policy_gradient_loss | -0.0203    |\n",
      "|    value_loss           | 0.000355   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.78        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 2560        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010953377 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.09       |\n",
      "|    explained_variance   | -0.671      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0485     |\n",
      "|    n_updates            | 176         |\n",
      "|    policy_gradient_loss | -0.0185     |\n",
      "|    value_loss           | 0.00028     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.86        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014851952 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.99       |\n",
      "|    explained_variance   | -3          |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0575     |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 0.000579    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.9         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 12          |\n",
      "|    total_timesteps      | 3584        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013038715 |\n",
      "|    clip_fraction        | 0.343       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.02       |\n",
      "|    explained_variance   | -2.91       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0522     |\n",
      "|    n_updates            | 184         |\n",
      "|    policy_gradient_loss | -0.0228     |\n",
      "|    value_loss           | 0.000907    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.81        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013552675 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | -2.37       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0608     |\n",
      "|    n_updates            | 188         |\n",
      "|    policy_gradient_loss | -0.0218     |\n",
      "|    value_loss           | 0.000284    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.04        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 4608        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015546909 |\n",
      "|    clip_fraction        | 0.29        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.04       |\n",
      "|    explained_variance   | -2.27       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0563     |\n",
      "|    n_updates            | 192         |\n",
      "|    policy_gradient_loss | -0.0215     |\n",
      "|    value_loss           | 0.000281    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.9         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017759988 |\n",
      "|    clip_fraction        | 0.365       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2          |\n",
      "|    explained_variance   | -1.96       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0546     |\n",
      "|    n_updates            | 196         |\n",
      "|    policy_gradient_loss | -0.02       |\n",
      "|    value_loss           | 0.000258    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.92        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 5632        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018616296 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.96       |\n",
      "|    explained_variance   | -1.22       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0427     |\n",
      "|    n_updates            | 200         |\n",
      "|    policy_gradient_loss | -0.0262     |\n",
      "|    value_loss           | 0.000369    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.11        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019845208 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.98       |\n",
      "|    explained_variance   | -2.86       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0605     |\n",
      "|    n_updates            | 204         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 0.000527    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.86        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 6656        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013224801 |\n",
      "|    clip_fraction        | 0.299       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -2.01       |\n",
      "|    explained_variance   | -2.05       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0639     |\n",
      "|    n_updates            | 208         |\n",
      "|    policy_gradient_loss | -0.0168     |\n",
      "|    value_loss           | 0.000473    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.07        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013290366 |\n",
      "|    clip_fraction        | 0.374       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.93       |\n",
      "|    explained_variance   | -2.52       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0601     |\n",
      "|    n_updates            | 212         |\n",
      "|    policy_gradient_loss | -0.0161     |\n",
      "|    value_loss           | 0.000471    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 2.84        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 27          |\n",
      "|    total_timesteps      | 7680        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013611486 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.97       |\n",
      "|    explained_variance   | -2.21       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.059      |\n",
      "|    n_updates            | 216         |\n",
      "|    policy_gradient_loss | -0.0194     |\n",
      "|    value_loss           | 0.000291    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 2.89       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 16         |\n",
      "|    time_elapsed         | 28         |\n",
      "|    total_timesteps      | 8192       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01669307 |\n",
      "|    clip_fraction        | 0.326      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.92      |\n",
      "|    explained_variance   | -0.96      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0607    |\n",
      "|    n_updates            | 220        |\n",
      "|    policy_gradient_loss | -0.0183    |\n",
      "|    value_loss           | 0.000187   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.1         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 8704        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015906092 |\n",
      "|    clip_fraction        | 0.325       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -1.39       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0269     |\n",
      "|    n_updates            | 224         |\n",
      "|    policy_gradient_loss | -0.0219     |\n",
      "|    value_loss           | 0.000202    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.14        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013418251 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.81       |\n",
      "|    explained_variance   | -1.81       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0497     |\n",
      "|    n_updates            | 228         |\n",
      "|    policy_gradient_loss | -0.021      |\n",
      "|    value_loss           | 0.000269    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.22       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 19         |\n",
      "|    time_elapsed         | 34         |\n",
      "|    total_timesteps      | 9728       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02506246 |\n",
      "|    clip_fraction        | 0.315      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.82      |\n",
      "|    explained_variance   | -1.81      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0408    |\n",
      "|    n_updates            | 232        |\n",
      "|    policy_gradient_loss | -0.0187    |\n",
      "|    value_loss           | 0.000274   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.21        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.010853377 |\n",
      "|    clip_fraction        | 0.363       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.82       |\n",
      "|    explained_variance   | -1.85       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0569     |\n",
      "|    n_updates            | 236         |\n",
      "|    policy_gradient_loss | -0.017      |\n",
      "|    value_loss           | 0.000232    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.09        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 10752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016872037 |\n",
      "|    clip_fraction        | 0.33        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -1.56       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0447     |\n",
      "|    n_updates            | 240         |\n",
      "|    policy_gradient_loss | -0.0211     |\n",
      "|    value_loss           | 0.000294    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.26        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016664222 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.84       |\n",
      "|    explained_variance   | -2.06       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0378     |\n",
      "|    n_updates            | 244         |\n",
      "|    policy_gradient_loss | -0.0209     |\n",
      "|    value_loss           | 0.00161     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.24        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 11776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013322363 |\n",
      "|    clip_fraction        | 0.351       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.76       |\n",
      "|    explained_variance   | -5.49       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0566     |\n",
      "|    n_updates            | 248         |\n",
      "|    policy_gradient_loss | -0.0182     |\n",
      "|    value_loss           | 0.000627    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.16       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 281        |\n",
      "|    iterations           | 24         |\n",
      "|    time_elapsed         | 43         |\n",
      "|    total_timesteps      | 12288      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01624358 |\n",
      "|    clip_fraction        | 0.375      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.72      |\n",
      "|    explained_variance   | -1.62      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0598    |\n",
      "|    n_updates            | 252        |\n",
      "|    policy_gradient_loss | -0.0205    |\n",
      "|    value_loss           | 0.000321   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.38        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015835052 |\n",
      "|    clip_fraction        | 0.404       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.72       |\n",
      "|    explained_variance   | -2.81       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0478     |\n",
      "|    n_updates            | 256         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    value_loss           | 0.000421    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.37        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024786972 |\n",
      "|    clip_fraction        | 0.348       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.71       |\n",
      "|    explained_variance   | -1.87       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0555     |\n",
      "|    n_updates            | 260         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 0.000262    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.26        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 13824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.012505651 |\n",
      "|    clip_fraction        | 0.344       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | -1.02       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0654     |\n",
      "|    n_updates            | 264         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 0.000254    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.21        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014528184 |\n",
      "|    clip_fraction        | 0.328       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.67       |\n",
      "|    explained_variance   | -0.447      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.054      |\n",
      "|    n_updates            | 268         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 0.000348    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.27        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 14848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014443451 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.66       |\n",
      "|    explained_variance   | -2.75       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0579     |\n",
      "|    n_updates            | 272         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    value_loss           | 0.00027     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.35        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019388754 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | -0.535      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0533     |\n",
      "|    n_updates            | 276         |\n",
      "|    policy_gradient_loss | -0.023      |\n",
      "|    value_loss           | 0.000226    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.43        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 15872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017330173 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.68       |\n",
      "|    explained_variance   | -2.49       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0461     |\n",
      "|    n_updates            | 280         |\n",
      "|    policy_gradient_loss | -0.019      |\n",
      "|    value_loss           | 0.000315    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.55        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017576644 |\n",
      "|    clip_fraction        | 0.366       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | -2.67       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0328     |\n",
      "|    n_updates            | 284         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 0.000423    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.56        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 16896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017717846 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.58       |\n",
      "|    explained_variance   | -2.9        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0561     |\n",
      "|    n_updates            | 288         |\n",
      "|    policy_gradient_loss | -0.0197     |\n",
      "|    value_loss           | 0.000532    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.5         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020091759 |\n",
      "|    clip_fraction        | 0.356       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -2.19       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0368     |\n",
      "|    n_updates            | 292         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.00062     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.26        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 17920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014091339 |\n",
      "|    clip_fraction        | 0.311       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.57       |\n",
      "|    explained_variance   | -3.14       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0533     |\n",
      "|    n_updates            | 296         |\n",
      "|    policy_gradient_loss | -0.0191     |\n",
      "|    value_loss           | 0.000651    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.23        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015488928 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | -2.32       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0232      |\n",
      "|    n_updates            | 300         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.000271    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.45        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 18944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015902843 |\n",
      "|    clip_fraction        | 0.34        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.65       |\n",
      "|    explained_variance   | -0.873      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0545     |\n",
      "|    n_updates            | 304         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.00026     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.36        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013516587 |\n",
      "|    clip_fraction        | 0.394       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | -1.01       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0504     |\n",
      "|    n_updates            | 308         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.000432    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.6         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 19968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023918647 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.42       |\n",
      "|    explained_variance   | -0.325      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0644     |\n",
      "|    n_updates            | 312         |\n",
      "|    policy_gradient_loss | -0.0192     |\n",
      "|    value_loss           | 0.000631    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.51        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013470653 |\n",
      "|    clip_fraction        | 0.336       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.55       |\n",
      "|    explained_variance   | -0.732      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0217     |\n",
      "|    n_updates            | 316         |\n",
      "|    policy_gradient_loss | -0.0193     |\n",
      "|    value_loss           | 0.000663    |\n",
      "-----------------------------------------\n",
      "train time: 73.61483454704285\n",
      "Logging to models/Reversi_ppo_8x8/PPO_3\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 3.43     |\n",
      "|    ep_rew_mean     | -1       |\n",
      "| time/              |          |\n",
      "|    fps             | 406      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 512      |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.4         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 3           |\n",
      "|    total_timesteps      | 1024        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019658323 |\n",
      "|    clip_fraction        | 0.349       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.61       |\n",
      "|    explained_variance   | -1.61       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0483     |\n",
      "|    n_updates            | 324         |\n",
      "|    policy_gradient_loss | -0.0234     |\n",
      "|    value_loss           | 0.000292    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.33        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 304         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 5           |\n",
      "|    total_timesteps      | 1536        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019490812 |\n",
      "|    clip_fraction        | 0.332       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.59       |\n",
      "|    explained_variance   | -0.897      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0581     |\n",
      "|    n_updates            | 328         |\n",
      "|    policy_gradient_loss | -0.0225     |\n",
      "|    value_loss           | 0.000378    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.65        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022723304 |\n",
      "|    clip_fraction        | 0.322       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.48       |\n",
      "|    explained_variance   | -2.21       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0538     |\n",
      "|    n_updates            | 332         |\n",
      "|    policy_gradient_loss | -0.022      |\n",
      "|    value_loss           | 0.000368    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.69        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 2560        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021730794 |\n",
      "|    clip_fraction        | 0.397       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.51       |\n",
      "|    explained_variance   | -1.49       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0501     |\n",
      "|    n_updates            | 336         |\n",
      "|    policy_gradient_loss | -0.0232     |\n",
      "|    value_loss           | 0.000365    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.68        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025238708 |\n",
      "|    clip_fraction        | 0.321       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.49       |\n",
      "|    explained_variance   | -0.978      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0189     |\n",
      "|    n_updates            | 340         |\n",
      "|    policy_gradient_loss | -0.0226     |\n",
      "|    value_loss           | 0.000254    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.68       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 3584       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01848685 |\n",
      "|    clip_fraction        | 0.359      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.48      |\n",
      "|    explained_variance   | -0.804     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0373    |\n",
      "|    n_updates            | 344        |\n",
      "|    policy_gradient_loss | -0.0189    |\n",
      "|    value_loss           | 0.000284   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.77        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014972188 |\n",
      "|    clip_fraction        | 0.329       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -1.32       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0608     |\n",
      "|    n_updates            | 348         |\n",
      "|    policy_gradient_loss | -0.0204     |\n",
      "|    value_loss           | 0.000292    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.81        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 16          |\n",
      "|    total_timesteps      | 4608        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019485151 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.43       |\n",
      "|    explained_variance   | -0.381      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0403     |\n",
      "|    n_updates            | 352         |\n",
      "|    policy_gradient_loss | -0.0138     |\n",
      "|    value_loss           | 0.000314    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.96        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021960009 |\n",
      "|    clip_fraction        | 0.338       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.4        |\n",
      "|    explained_variance   | -1.64       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0312     |\n",
      "|    n_updates            | 356         |\n",
      "|    policy_gradient_loss | -0.0174     |\n",
      "|    value_loss           | 0.000402    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.82        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 19          |\n",
      "|    total_timesteps      | 5632        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019504694 |\n",
      "|    clip_fraction        | 0.341       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | -0.874      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.051      |\n",
      "|    n_updates            | 360         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.000393    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.27       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 12         |\n",
      "|    time_elapsed         | 21         |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02248199 |\n",
      "|    clip_fraction        | 0.37       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.31      |\n",
      "|    explained_variance   | -0.523     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0717    |\n",
      "|    n_updates            | 364        |\n",
      "|    policy_gradient_loss | -0.0154    |\n",
      "|    value_loss           | 0.000294   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.24        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 23          |\n",
      "|    total_timesteps      | 6656        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015889835 |\n",
      "|    clip_fraction        | 0.317       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.36       |\n",
      "|    explained_variance   | -0.2        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 368         |\n",
      "|    policy_gradient_loss | -0.0143     |\n",
      "|    value_loss           | 0.000552    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.98        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 25          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018497363 |\n",
      "|    clip_fraction        | 0.304       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.35       |\n",
      "|    explained_variance   | -1.7        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0427     |\n",
      "|    n_updates            | 372         |\n",
      "|    policy_gradient_loss | -0.0227     |\n",
      "|    value_loss           | 0.000357    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 3.98       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 27         |\n",
      "|    total_timesteps      | 7680       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02428676 |\n",
      "|    clip_fraction        | 0.357      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -1.3       |\n",
      "|    explained_variance   | -0.594     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0331    |\n",
      "|    n_updates            | 376        |\n",
      "|    policy_gradient_loss | -0.0146    |\n",
      "|    value_loss           | 0.00034    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.98        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 29          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020491045 |\n",
      "|    clip_fraction        | 0.382       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | -0.794      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0444     |\n",
      "|    n_updates            | 380         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.000278    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.02        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 8704        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017920021 |\n",
      "|    clip_fraction        | 0.369       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.26       |\n",
      "|    explained_variance   | -0.901      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0482     |\n",
      "|    n_updates            | 384         |\n",
      "|    policy_gradient_loss | -0.0134     |\n",
      "|    value_loss           | 0.000409    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.35        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023188764 |\n",
      "|    clip_fraction        | 0.436       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.24       |\n",
      "|    explained_variance   | -0.925      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0292     |\n",
      "|    n_updates            | 388         |\n",
      "|    policy_gradient_loss | -0.0105     |\n",
      "|    value_loss           | 0.000855    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.23        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 9728        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024640327 |\n",
      "|    clip_fraction        | 0.293       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.23       |\n",
      "|    explained_variance   | -0.749      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.041      |\n",
      "|    n_updates            | 392         |\n",
      "|    policy_gradient_loss | -0.0152     |\n",
      "|    value_loss           | 0.000479    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.25        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017694151 |\n",
      "|    clip_fraction        | 0.345       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.15       |\n",
      "|    explained_variance   | -0.239      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0363     |\n",
      "|    n_updates            | 396         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.000287    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.11        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 38          |\n",
      "|    total_timesteps      | 10752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015325073 |\n",
      "|    clip_fraction        | 0.26        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.17       |\n",
      "|    explained_variance   | -0.672      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0152     |\n",
      "|    n_updates            | 400         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.000417    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 3.98        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 40          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025460254 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -1.67       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0328     |\n",
      "|    n_updates            | 404         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.000598    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.02        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 281         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 11776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016387656 |\n",
      "|    clip_fraction        | 0.306       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.1        |\n",
      "|    explained_variance   | -2.24       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0313     |\n",
      "|    n_updates            | 408         |\n",
      "|    policy_gradient_loss | -0.0141     |\n",
      "|    value_loss           | 0.000644    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.55        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023310466 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.06       |\n",
      "|    explained_variance   | -0.938      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0426     |\n",
      "|    n_updates            | 412         |\n",
      "|    policy_gradient_loss | -0.016      |\n",
      "|    value_loss           | 0.000374    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.47        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 45          |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020929905 |\n",
      "|    clip_fraction        | 0.315       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.07       |\n",
      "|    explained_variance   | -1.42       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0409     |\n",
      "|    n_updates            | 416         |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    value_loss           | 0.000384    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.38        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018993177 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | -0.606      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0667     |\n",
      "|    n_updates            | 420         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.000295    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.38        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 280         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 49          |\n",
      "|    total_timesteps      | 13824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026365649 |\n",
      "|    clip_fraction        | 0.339       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.925      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0347     |\n",
      "|    n_updates            | 424         |\n",
      "|    policy_gradient_loss | -0.018      |\n",
      "|    value_loss           | 0.00049     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.19        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022115339 |\n",
      "|    clip_fraction        | 0.32        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | -2.42       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0427     |\n",
      "|    n_updates            | 428         |\n",
      "|    policy_gradient_loss | -0.0179     |\n",
      "|    value_loss           | 0.00107     |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4.38      |\n",
      "|    ep_rew_mean          | -1        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 279       |\n",
      "|    iterations           | 29        |\n",
      "|    time_elapsed         | 53        |\n",
      "|    total_timesteps      | 14848     |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0183082 |\n",
      "|    clip_fraction        | 0.266     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -1.06     |\n",
      "|    explained_variance   | -1.1      |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.0134   |\n",
      "|    n_updates            | 432       |\n",
      "|    policy_gradient_loss | -0.0135   |\n",
      "|    value_loss           | 0.000285  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.56        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020046797 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | -0.559      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0345     |\n",
      "|    n_updates            | 436         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.00023     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.69        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 15872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030108638 |\n",
      "|    clip_fraction        | 0.313       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -0.0635     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0332     |\n",
      "|    n_updates            | 440         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 0.000298    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.45        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 58          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020233985 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.03       |\n",
      "|    explained_variance   | -0.0303     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0424     |\n",
      "|    n_updates            | 444         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.000328    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.46        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 60          |\n",
      "|    total_timesteps      | 16896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.013822593 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.971      |\n",
      "|    explained_variance   | -0.813      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0353     |\n",
      "|    n_updates            | 448         |\n",
      "|    policy_gradient_loss | -0.0158     |\n",
      "|    value_loss           | 0.000292    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.48       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 279        |\n",
      "|    iterations           | 34         |\n",
      "|    time_elapsed         | 62         |\n",
      "|    total_timesteps      | 17408      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01789312 |\n",
      "|    clip_fraction        | 0.265      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.905     |\n",
      "|    explained_variance   | -0.106     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0177    |\n",
      "|    n_updates            | 452        |\n",
      "|    policy_gradient_loss | -0.00979   |\n",
      "|    value_loss           | 0.000354   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.64        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 64          |\n",
      "|    total_timesteps      | 17920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019893352 |\n",
      "|    clip_fraction        | 0.275       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.947      |\n",
      "|    explained_variance   | -0.209      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0447     |\n",
      "|    n_updates            | 456         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.000242    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.42        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 36          |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016969476 |\n",
      "|    clip_fraction        | 0.243       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.969      |\n",
      "|    explained_variance   | -0.479      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0329     |\n",
      "|    n_updates            | 460         |\n",
      "|    policy_gradient_loss | -0.0151     |\n",
      "|    value_loss           | 0.000301    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.32        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 18944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025955297 |\n",
      "|    clip_fraction        | 0.292       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.952      |\n",
      "|    explained_variance   | -0.564      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00784    |\n",
      "|    n_updates            | 464         |\n",
      "|    policy_gradient_loss | -0.0157     |\n",
      "|    value_loss           | 0.00103     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.48        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 69          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026013324 |\n",
      "|    clip_fraction        | 0.316       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.965      |\n",
      "|    explained_variance   | -0.517      |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0489     |\n",
      "|    n_updates            | 468         |\n",
      "|    policy_gradient_loss | -0.0131     |\n",
      "|    value_loss           | 0.00075     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.38        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 19968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020007072 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | -0.572      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0403     |\n",
      "|    n_updates            | 472         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.000292    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.55        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 279         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 73          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025985833 |\n",
      "|    clip_fraction        | 0.324       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.08       |\n",
      "|    explained_variance   | -0.19       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0565     |\n",
      "|    n_updates            | 476         |\n",
      "|    policy_gradient_loss | -0.00813    |\n",
      "|    value_loss           | 0.000412    |\n",
      "-----------------------------------------\n",
      "train time: 73.94000959396362\n",
      "Logging to models/Reversi_ppo_8x8/PPO_4\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.44     |\n",
      "|    ep_rew_mean     | -1       |\n",
      "| time/              |          |\n",
      "|    fps             | 430      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 512      |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.43       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 337        |\n",
      "|    iterations           | 2          |\n",
      "|    time_elapsed         | 3          |\n",
      "|    total_timesteps      | 1024       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02047062 |\n",
      "|    clip_fraction        | 0.271      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.97      |\n",
      "|    explained_variance   | -0.154     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0333    |\n",
      "|    n_updates            | 484        |\n",
      "|    policy_gradient_loss | -0.0164    |\n",
      "|    value_loss           | 0.000182   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.54        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 316         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 1536        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020645997 |\n",
      "|    clip_fraction        | 0.285       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.955      |\n",
      "|    explained_variance   | -0.0794     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0461     |\n",
      "|    n_updates            | 488         |\n",
      "|    policy_gradient_loss | -0.0172     |\n",
      "|    value_loss           | 0.000231    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.56        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 307         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019477598 |\n",
      "|    clip_fraction        | 0.297       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.04       |\n",
      "|    explained_variance   | -1.78       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.11        |\n",
      "|    n_updates            | 492         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.000339    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.69        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 2560        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018412272 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.01       |\n",
      "|    explained_variance   | -0.401      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0361     |\n",
      "|    n_updates            | 496         |\n",
      "|    policy_gradient_loss | -0.0147     |\n",
      "|    value_loss           | 0.000265    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.71        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017730156 |\n",
      "|    clip_fraction        | 0.301       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.932      |\n",
      "|    explained_variance   | -0.324      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 500         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.000325    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.74       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 294        |\n",
      "|    iterations           | 7          |\n",
      "|    time_elapsed         | 12         |\n",
      "|    total_timesteps      | 3584       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02030718 |\n",
      "|    clip_fraction        | 0.323      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.923     |\n",
      "|    explained_variance   | -0.00984   |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0243    |\n",
      "|    n_updates            | 504        |\n",
      "|    policy_gradient_loss | -0.0145    |\n",
      "|    value_loss           | 0.000346   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.53        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 292         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 14          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015394696 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -1.02       |\n",
      "|    explained_variance   | -0.431      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0288     |\n",
      "|    n_updates            | 508         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.000427    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.75       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 9          |\n",
      "|    time_elapsed         | 15         |\n",
      "|    total_timesteps      | 4608       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02026099 |\n",
      "|    clip_fraction        | 0.342      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.973     |\n",
      "|    explained_variance   | -0.244     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0514    |\n",
      "|    n_updates            | 512        |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    value_loss           | 0.000389   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.9         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017012957 |\n",
      "|    clip_fraction        | 0.242       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.913      |\n",
      "|    explained_variance   | -0.268      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0445     |\n",
      "|    n_updates            | 516         |\n",
      "|    policy_gradient_loss | -0.00966    |\n",
      "|    value_loss           | 0.000359    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.79       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 289        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 19         |\n",
      "|    total_timesteps      | 5632       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02134452 |\n",
      "|    clip_fraction        | 0.309      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.988     |\n",
      "|    explained_variance   | 0.0898     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0315    |\n",
      "|    n_updates            | 520        |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    value_loss           | 0.000261   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.67        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035454884 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.876      |\n",
      "|    explained_variance   | -0.0382     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0501     |\n",
      "|    n_updates            | 524         |\n",
      "|    policy_gradient_loss | -0.0165     |\n",
      "|    value_loss           | 0.00031     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.94       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 23         |\n",
      "|    total_timesteps      | 6656       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02592365 |\n",
      "|    clip_fraction        | 0.273      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.84      |\n",
      "|    explained_variance   | -0.524     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0467    |\n",
      "|    n_updates            | 528        |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    value_loss           | 0.000333   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.88        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018094867 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.896      |\n",
      "|    explained_variance   | -1.89       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0376     |\n",
      "|    n_updates            | 532         |\n",
      "|    policy_gradient_loss | -0.0156     |\n",
      "|    value_loss           | 0.000435    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.68       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 287        |\n",
      "|    iterations           | 15         |\n",
      "|    time_elapsed         | 26         |\n",
      "|    total_timesteps      | 7680       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02166932 |\n",
      "|    clip_fraction        | 0.249      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.874     |\n",
      "|    explained_variance   | -0.979     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.00747    |\n",
      "|    n_updates            | 536        |\n",
      "|    policy_gradient_loss | -0.0166    |\n",
      "|    value_loss           | 0.000506   |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| rollout/                |           |\n",
      "|    ep_len_mean          | 4.81      |\n",
      "|    ep_rew_mean          | -1        |\n",
      "| time/                   |           |\n",
      "|    fps                  | 284       |\n",
      "|    iterations           | 16        |\n",
      "|    time_elapsed         | 28        |\n",
      "|    total_timesteps      | 8192      |\n",
      "| train/                  |           |\n",
      "|    approx_kl            | 0.0204598 |\n",
      "|    clip_fraction        | 0.287     |\n",
      "|    clip_range           | 0.1       |\n",
      "|    entropy_loss         | -0.842    |\n",
      "|    explained_variance   | -0.686    |\n",
      "|    learning_rate        | 0.00025   |\n",
      "|    loss                 | -0.027    |\n",
      "|    n_updates            | 540       |\n",
      "|    policy_gradient_loss | -0.0154   |\n",
      "|    value_loss           | 0.000321  |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.86        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 30          |\n",
      "|    total_timesteps      | 8704        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028778318 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.869      |\n",
      "|    explained_variance   | -0.0456     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0377     |\n",
      "|    n_updates            | 544         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.000225    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5          |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 18         |\n",
      "|    time_elapsed         | 32         |\n",
      "|    total_timesteps      | 9216       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02262456 |\n",
      "|    clip_fraction        | 0.267      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.868     |\n",
      "|    explained_variance   | 0.0703     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0445    |\n",
      "|    n_updates            | 548        |\n",
      "|    policy_gradient_loss | -0.0123    |\n",
      "|    value_loss           | 0.000219   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 34          |\n",
      "|    total_timesteps      | 9728        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017460452 |\n",
      "|    clip_fraction        | 0.229       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.859      |\n",
      "|    explained_variance   | -0.732      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0393     |\n",
      "|    n_updates            | 552         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.000338    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.03        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 36          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030239046 |\n",
      "|    clip_fraction        | 0.271       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.885      |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0395     |\n",
      "|    n_updates            | 556         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.000292    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.98        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 10752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030873831 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.855      |\n",
      "|    explained_variance   | -0.648      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0387     |\n",
      "|    n_updates            | 560         |\n",
      "|    policy_gradient_loss | -0.00928    |\n",
      "|    value_loss           | 0.000417    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.8         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021244012 |\n",
      "|    clip_fraction        | 0.251       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.882      |\n",
      "|    explained_variance   | -0.116      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.039      |\n",
      "|    n_updates            | 564         |\n",
      "|    policy_gradient_loss | -0.0135     |\n",
      "|    value_loss           | 0.000219    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.8        |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 23         |\n",
      "|    time_elapsed         | 41         |\n",
      "|    total_timesteps      | 11776      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02676183 |\n",
      "|    clip_fraction        | 0.272      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.888     |\n",
      "|    explained_variance   | 0.24       |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0402    |\n",
      "|    n_updates            | 568        |\n",
      "|    policy_gradient_loss | -0.013     |\n",
      "|    value_loss           | 0.000338   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.73        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 43          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021230634 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.866      |\n",
      "|    explained_variance   | -0.262      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00592    |\n",
      "|    n_updates            | 572         |\n",
      "|    policy_gradient_loss | -0.0126     |\n",
      "|    value_loss           | 0.000229    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.83       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 25         |\n",
      "|    time_elapsed         | 45         |\n",
      "|    total_timesteps      | 12800      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02321222 |\n",
      "|    clip_fraction        | 0.226      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.81      |\n",
      "|    explained_variance   | 0.0589     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0301    |\n",
      "|    n_updates            | 576        |\n",
      "|    policy_gradient_loss | -0.0117    |\n",
      "|    value_loss           | 0.00027    |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.87        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 26          |\n",
      "|    time_elapsed         | 47          |\n",
      "|    total_timesteps      | 13312       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018833553 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.879      |\n",
      "|    explained_variance   | -0.339      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0377     |\n",
      "|    n_updates            | 580         |\n",
      "|    policy_gradient_loss | -0.0122     |\n",
      "|    value_loss           | 0.000299    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 4.8        |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 283        |\n",
      "|    iterations           | 27         |\n",
      "|    time_elapsed         | 48         |\n",
      "|    total_timesteps      | 13824      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02095925 |\n",
      "|    clip_fraction        | 0.24       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.848     |\n",
      "|    explained_variance   | 0.239      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0452    |\n",
      "|    n_updates            | 584        |\n",
      "|    policy_gradient_loss | -0.00941   |\n",
      "|    value_loss           | 0.000319   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.87        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022261947 |\n",
      "|    clip_fraction        | 0.261       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.831      |\n",
      "|    explained_variance   | -0.179      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.02       |\n",
      "|    n_updates            | 588         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.000554    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.97        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 52          |\n",
      "|    total_timesteps      | 14848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.028215567 |\n",
      "|    clip_fraction        | 0.274       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.86       |\n",
      "|    explained_variance   | -1.48       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00551    |\n",
      "|    n_updates            | 592         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.000615    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.97        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 30          |\n",
      "|    time_elapsed         | 54          |\n",
      "|    total_timesteps      | 15360       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018495701 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.834      |\n",
      "|    explained_variance   | -0.275      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0354     |\n",
      "|    n_updates            | 596         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.000811    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.9         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 31          |\n",
      "|    time_elapsed         | 56          |\n",
      "|    total_timesteps      | 15872       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030433543 |\n",
      "|    clip_fraction        | 0.281       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.835      |\n",
      "|    explained_variance   | -1.41       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0207     |\n",
      "|    n_updates            | 600         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.000419    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.83        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.041258104 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.815      |\n",
      "|    explained_variance   | -0.623      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0288     |\n",
      "|    n_updates            | 604         |\n",
      "|    policy_gradient_loss | -0.00313    |\n",
      "|    value_loss           | 0.000374    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.74        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 283         |\n",
      "|    iterations           | 33          |\n",
      "|    time_elapsed         | 59          |\n",
      "|    total_timesteps      | 16896       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024039252 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.841      |\n",
      "|    explained_variance   | -2.85       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0394     |\n",
      "|    n_updates            | 608         |\n",
      "|    policy_gradient_loss | -0.0111     |\n",
      "|    value_loss           | 0.000467    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.79        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033064563 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.88       |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    explained_variance   | -0.278      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0276     |\n",
      "|    n_updates            | 612         |\n",
      "|    policy_gradient_loss | -0.00273    |\n",
      "|    value_loss           | 0.000403    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.01        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 63          |\n",
      "|    total_timesteps      | 17920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032047465 |\n",
      "|    clip_fraction        | 0.268       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.869      |\n",
      "|    explained_variance   | 0.0643      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0536     |\n",
      "|    n_updates            | 616         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 0.000301    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.06       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 282        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 65         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.04812053 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.84      |\n",
      "|    explained_variance   | 0.0234     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0162    |\n",
      "|    n_updates            | 620        |\n",
      "|    policy_gradient_loss | -0.0144    |\n",
      "|    value_loss           | 0.000349   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.01        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 67          |\n",
      "|    total_timesteps      | 18944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021283317 |\n",
      "|    clip_fraction        | 0.249       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.834      |\n",
      "|    explained_variance   | 0.0517      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0287     |\n",
      "|    n_updates            | 624         |\n",
      "|    policy_gradient_loss | -0.00941    |\n",
      "|    value_loss           | 0.000307    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.09        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021588054 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.829      |\n",
      "|    explained_variance   | 0.0655      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.0142      |\n",
      "|    n_updates            | 628         |\n",
      "|    policy_gradient_loss | -0.0155     |\n",
      "|    value_loss           | 0.000208    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.15        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 19968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020251686 |\n",
      "|    clip_fraction        | 0.237       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.797      |\n",
      "|    explained_variance   | 0.107       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0424     |\n",
      "|    n_updates            | 632         |\n",
      "|    policy_gradient_loss | -0.015      |\n",
      "|    value_loss           | 0.000186    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.08        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 282         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 72          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.029139243 |\n",
      "|    clip_fraction        | 0.254       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | 0.0759      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0406     |\n",
      "|    n_updates            | 636         |\n",
      "|    policy_gradient_loss | -0.0145     |\n",
      "|    value_loss           | 0.000256    |\n",
      "-----------------------------------------\n",
      "train time: 73.33347964286804\n",
      "Logging to models/Reversi_ppo_8x8/PPO_5\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 4.94     |\n",
      "|    ep_rew_mean     | -1       |\n",
      "| time/              |          |\n",
      "|    fps             | 426      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 1        |\n",
      "|    total_timesteps | 512      |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.17        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 342         |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 2           |\n",
      "|    total_timesteps      | 1024        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026909009 |\n",
      "|    clip_fraction        | 0.257       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | 0.0184      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0114     |\n",
      "|    n_updates            | 644         |\n",
      "|    policy_gradient_loss | -0.00781    |\n",
      "|    value_loss           | 0.000333    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.19        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 321         |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 4           |\n",
      "|    total_timesteps      | 1536        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.035018347 |\n",
      "|    clip_fraction        | 0.255       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.871      |\n",
      "|    explained_variance   | -2.37       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | 0.008       |\n",
      "|    n_updates            | 648         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.00044     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.95        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 311         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 6           |\n",
      "|    total_timesteps      | 2048        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.017558837 |\n",
      "|    clip_fraction        | 0.247       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.851      |\n",
      "|    explained_variance   | 0.148       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00498    |\n",
      "|    n_updates            | 652         |\n",
      "|    policy_gradient_loss | -0.0129     |\n",
      "|    value_loss           | 0.000233    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.13        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 305         |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 8           |\n",
      "|    total_timesteps      | 2560        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.040764906 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.802      |\n",
      "|    explained_variance   | 0.04        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.057      |\n",
      "|    n_updates            | 656         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.000263    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.9         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 301         |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 10          |\n",
      "|    total_timesteps      | 3072        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026766283 |\n",
      "|    clip_fraction        | 0.238       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.749      |\n",
      "|    explained_variance   | 0.0291      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0443     |\n",
      "|    n_updates            | 660         |\n",
      "|    policy_gradient_loss | -0.00932    |\n",
      "|    value_loss           | 0.000224    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.24        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 298         |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 3584        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024752323 |\n",
      "|    clip_fraction        | 0.256       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.8        |\n",
      "|    explained_variance   | 0.266       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.042      |\n",
      "|    n_updates            | 664         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.000261    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.43        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 296         |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 13          |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022163156 |\n",
      "|    clip_fraction        | 0.253       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.849      |\n",
      "|    explained_variance   | -0.215      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0297     |\n",
      "|    n_updates            | 668         |\n",
      "|    policy_gradient_loss | -0.0123     |\n",
      "|    value_loss           | 0.000452    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.24        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 294         |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 15          |\n",
      "|    total_timesteps      | 4608        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025981186 |\n",
      "|    clip_fraction        | 0.231       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.842      |\n",
      "|    explained_variance   | -0.231      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0397     |\n",
      "|    n_updates            | 672         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.000506    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.27        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 293         |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 17          |\n",
      "|    total_timesteps      | 5120        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032795485 |\n",
      "|    clip_fraction        | 0.277       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.814      |\n",
      "|    explained_variance   | -0.25       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0199     |\n",
      "|    n_updates            | 676         |\n",
      "|    policy_gradient_loss | -0.0167     |\n",
      "|    value_loss           | 0.000312    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.23       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 292        |\n",
      "|    iterations           | 11         |\n",
      "|    time_elapsed         | 19         |\n",
      "|    total_timesteps      | 5632       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01968103 |\n",
      "|    clip_fraction        | 0.202      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.754     |\n",
      "|    explained_variance   | 0.0565     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0421    |\n",
      "|    n_updates            | 680        |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    value_loss           | 0.000238   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.99        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 291         |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 21          |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023236103 |\n",
      "|    clip_fraction        | 0.232       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.722      |\n",
      "|    explained_variance   | -0.0936     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0219     |\n",
      "|    n_updates            | 684         |\n",
      "|    policy_gradient_loss | -0.0144     |\n",
      "|    value_loss           | 0.000269    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.09       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 290        |\n",
      "|    iterations           | 13         |\n",
      "|    time_elapsed         | 22         |\n",
      "|    total_timesteps      | 6656       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.06294495 |\n",
      "|    clip_fraction        | 0.268      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.699     |\n",
      "|    explained_variance   | 0.0291     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | 0.000745   |\n",
      "|    n_updates            | 688        |\n",
      "|    policy_gradient_loss | -0.00704   |\n",
      "|    value_loss           | 0.000225   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.16        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 24          |\n",
      "|    total_timesteps      | 7168        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024916735 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.742      |\n",
      "|    explained_variance   | -0.0693     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0369     |\n",
      "|    n_updates            | 692         |\n",
      "|    policy_gradient_loss | -0.00856    |\n",
      "|    value_loss           | 0.000216    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.11        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 289         |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 26          |\n",
      "|    total_timesteps      | 7680        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027790874 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.789      |\n",
      "|    explained_variance   | 0.166       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0378     |\n",
      "|    n_updates            | 696         |\n",
      "|    policy_gradient_loss | -0.00589    |\n",
      "|    value_loss           | 0.000307    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.12        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 288         |\n",
      "|    iterations           | 16          |\n",
      "|    time_elapsed         | 28          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022120195 |\n",
      "|    clip_fraction        | 0.244       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.717      |\n",
      "|    explained_variance   | 0.114       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0342     |\n",
      "|    n_updates            | 700         |\n",
      "|    policy_gradient_loss | -0.0154     |\n",
      "|    value_loss           | 0.000144    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.45       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 288        |\n",
      "|    iterations           | 17         |\n",
      "|    time_elapsed         | 30         |\n",
      "|    total_timesteps      | 8704       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02141815 |\n",
      "|    clip_fraction        | 0.247      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.686     |\n",
      "|    explained_variance   | 0.251      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0222    |\n",
      "|    n_updates            | 704        |\n",
      "|    policy_gradient_loss | -0.01      |\n",
      "|    value_loss           | 0.000242   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.3         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 32          |\n",
      "|    total_timesteps      | 9216        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021370143 |\n",
      "|    clip_fraction        | 0.214       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.71       |\n",
      "|    explained_variance   | -0.052      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0386     |\n",
      "|    n_updates            | 708         |\n",
      "|    policy_gradient_loss | -0.0098     |\n",
      "|    value_loss           | 0.000533    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.99        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 33          |\n",
      "|    total_timesteps      | 9728        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016541988 |\n",
      "|    clip_fraction        | 0.245       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.719      |\n",
      "|    explained_variance   | -0.0392     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0352     |\n",
      "|    n_updates            | 712         |\n",
      "|    policy_gradient_loss | -0.0109     |\n",
      "|    value_loss           | 0.000229    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.21        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 35          |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023791399 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.687      |\n",
      "|    explained_variance   | -0.000138   |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0322     |\n",
      "|    n_updates            | 716         |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    value_loss           | 0.000186    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.12        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 21          |\n",
      "|    time_elapsed         | 37          |\n",
      "|    total_timesteps      | 10752       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.032978904 |\n",
      "|    clip_fraction        | 0.248       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.69       |\n",
      "|    explained_variance   | 0.325       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0349     |\n",
      "|    n_updates            | 720         |\n",
      "|    policy_gradient_loss | -0.0149     |\n",
      "|    value_loss           | 0.000326    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.12        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 22          |\n",
      "|    time_elapsed         | 39          |\n",
      "|    total_timesteps      | 11264       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.046490632 |\n",
      "|    clip_fraction        | 0.282       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.739      |\n",
      "|    explained_variance   | -0.318      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0293     |\n",
      "|    n_updates            | 724         |\n",
      "|    policy_gradient_loss | -0.0132     |\n",
      "|    value_loss           | 0.00027     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.13        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 287         |\n",
      "|    iterations           | 23          |\n",
      "|    time_elapsed         | 41          |\n",
      "|    total_timesteps      | 11776       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.045026824 |\n",
      "|    clip_fraction        | 0.273       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.736      |\n",
      "|    explained_variance   | 0.275       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0284     |\n",
      "|    n_updates            | 728         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 0.000216    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.25        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 24          |\n",
      "|    time_elapsed         | 42          |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016162388 |\n",
      "|    clip_fraction        | 0.23        |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.744      |\n",
      "|    explained_variance   | 0.432       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0374     |\n",
      "|    n_updates            | 732         |\n",
      "|    policy_gradient_loss | -0.0146     |\n",
      "|    value_loss           | 0.000148    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.98        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 25          |\n",
      "|    time_elapsed         | 44          |\n",
      "|    total_timesteps      | 12800       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019522872 |\n",
      "|    clip_fraction        | 0.235       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.719      |\n",
      "|    explained_variance   | 0.0827      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0431     |\n",
      "|    n_updates            | 736         |\n",
      "|    policy_gradient_loss | -0.0142     |\n",
      "|    value_loss           | 0.000238    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.24       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 286        |\n",
      "|    iterations           | 26         |\n",
      "|    time_elapsed         | 46         |\n",
      "|    total_timesteps      | 13312      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01953221 |\n",
      "|    clip_fraction        | 0.221      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.701     |\n",
      "|    explained_variance   | -0.665     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0338    |\n",
      "|    n_updates            | 740        |\n",
      "|    policy_gradient_loss | -0.00878   |\n",
      "|    value_loss           | 0.000246   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.2         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 286         |\n",
      "|    iterations           | 27          |\n",
      "|    time_elapsed         | 48          |\n",
      "|    total_timesteps      | 13824       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.024821952 |\n",
      "|    clip_fraction        | 0.262       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.718      |\n",
      "|    explained_variance   | 0.198       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.047      |\n",
      "|    n_updates            | 744         |\n",
      "|    policy_gradient_loss | -0.0173     |\n",
      "|    value_loss           | 0.000334    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.12        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 28          |\n",
      "|    time_elapsed         | 50          |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020947233 |\n",
      "|    clip_fraction        | 0.223       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.707      |\n",
      "|    explained_variance   | -0.0412     |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0188     |\n",
      "|    n_updates            | 748         |\n",
      "|    policy_gradient_loss | -0.0133     |\n",
      "|    value_loss           | 0.00027     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.39        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 29          |\n",
      "|    time_elapsed         | 51          |\n",
      "|    total_timesteps      | 14848       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025380181 |\n",
      "|    clip_fraction        | 0.234       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.727      |\n",
      "|    explained_variance   | 0.194       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0512     |\n",
      "|    n_updates            | 752         |\n",
      "|    policy_gradient_loss | -0.011      |\n",
      "|    value_loss           | 0.00023     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.21       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 30         |\n",
      "|    time_elapsed         | 53         |\n",
      "|    total_timesteps      | 15360      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.01973904 |\n",
      "|    clip_fraction        | 0.235      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.731     |\n",
      "|    explained_variance   | 0.182      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0327    |\n",
      "|    n_updates            | 756        |\n",
      "|    policy_gradient_loss | -0.0162    |\n",
      "|    value_loss           | 0.000306   |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.16       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 31         |\n",
      "|    time_elapsed         | 55         |\n",
      "|    total_timesteps      | 15872      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02924206 |\n",
      "|    clip_fraction        | 0.285      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.706     |\n",
      "|    explained_variance   | 0.0061     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.031     |\n",
      "|    n_updates            | 760        |\n",
      "|    policy_gradient_loss | -0.0142    |\n",
      "|    value_loss           | 0.000375   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.16        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 32          |\n",
      "|    time_elapsed         | 57          |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026707897 |\n",
      "|    clip_fraction        | 0.283       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.711      |\n",
      "|    explained_variance   | -0.293      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00774    |\n",
      "|    n_updates            | 764         |\n",
      "|    policy_gradient_loss | -0.0127     |\n",
      "|    value_loss           | 0.00038     |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.31       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 285        |\n",
      "|    iterations           | 33         |\n",
      "|    time_elapsed         | 59         |\n",
      "|    total_timesteps      | 16896      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.08196925 |\n",
      "|    clip_fraction        | 0.336      |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.674     |\n",
      "|    explained_variance   | -0.112     |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0455    |\n",
      "|    n_updates            | 768        |\n",
      "|    policy_gradient_loss | -0.0119    |\n",
      "|    value_loss           | 0.000297   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 4.99        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 285         |\n",
      "|    iterations           | 34          |\n",
      "|    time_elapsed         | 61          |\n",
      "|    total_timesteps      | 17408       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.021776687 |\n",
      "|    clip_fraction        | 0.227       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.662      |\n",
      "|    explained_variance   | 0.0242      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.00693    |\n",
      "|    n_updates            | 772         |\n",
      "|    policy_gradient_loss | -0.0112     |\n",
      "|    value_loss           | 0.00022     |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.19        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 35          |\n",
      "|    time_elapsed         | 62          |\n",
      "|    total_timesteps      | 17920       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.042319864 |\n",
      "|    clip_fraction        | 0.287       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.65       |\n",
      "|    explained_variance   | 0.24        |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0388     |\n",
      "|    n_updates            | 776         |\n",
      "|    policy_gradient_loss | -0.00892    |\n",
      "|    value_loss           | 0.000249    |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 5.48       |\n",
      "|    ep_rew_mean          | -1         |\n",
      "| time/                   |            |\n",
      "|    fps                  | 284        |\n",
      "|    iterations           | 36         |\n",
      "|    time_elapsed         | 64         |\n",
      "|    total_timesteps      | 18432      |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.02341375 |\n",
      "|    clip_fraction        | 0.25       |\n",
      "|    clip_range           | 0.1        |\n",
      "|    entropy_loss         | -0.728     |\n",
      "|    explained_variance   | 0.308      |\n",
      "|    learning_rate        | 0.00025    |\n",
      "|    loss                 | -0.0391    |\n",
      "|    n_updates            | 780        |\n",
      "|    policy_gradient_loss | -0.0137    |\n",
      "|    value_loss           | 0.000295   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.4         |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 37          |\n",
      "|    time_elapsed         | 66          |\n",
      "|    total_timesteps      | 18944       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018462656 |\n",
      "|    clip_fraction        | 0.219       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.643      |\n",
      "|    explained_variance   | -0.25       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0314     |\n",
      "|    n_updates            | 784         |\n",
      "|    policy_gradient_loss | -0.0113     |\n",
      "|    value_loss           | 0.000263    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.47        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 38          |\n",
      "|    time_elapsed         | 68          |\n",
      "|    total_timesteps      | 19456       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.026465222 |\n",
      "|    clip_fraction        | 0.258       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.64       |\n",
      "|    explained_variance   | 0.176       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0409     |\n",
      "|    n_updates            | 788         |\n",
      "|    policy_gradient_loss | -0.012      |\n",
      "|    value_loss           | 0.000263    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.47        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 39          |\n",
      "|    time_elapsed         | 70          |\n",
      "|    total_timesteps      | 19968       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.018245187 |\n",
      "|    clip_fraction        | 0.224       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.648      |\n",
      "|    explained_variance   | -0.186      |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.046      |\n",
      "|    n_updates            | 792         |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    value_loss           | 0.000241    |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 5.39        |\n",
      "|    ep_rew_mean          | -1          |\n",
      "| time/                   |             |\n",
      "|    fps                  | 284         |\n",
      "|    iterations           | 40          |\n",
      "|    time_elapsed         | 71          |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.033236545 |\n",
      "|    clip_fraction        | 0.296       |\n",
      "|    clip_range           | 0.1         |\n",
      "|    entropy_loss         | -0.692      |\n",
      "|    explained_variance   | 0.237       |\n",
      "|    learning_rate        | 0.00025     |\n",
      "|    loss                 | -0.0428     |\n",
      "|    n_updates            | 796         |\n",
      "|    policy_gradient_loss | -0.014      |\n",
      "|    value_loss           | 0.000285    |\n",
      "-----------------------------------------\n",
      "train time: 72.65169906616211\n"
     ]
    }
   ],
   "source": [
    "!python reversi_model_train.py --board_size 8 --total_timesteps 100000 --cp_timesteps 20000 --n_envs 8 --opponent_model_path random --start_index 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84461556",
   "metadata": {},
   "source": [
    "### 模型加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed063b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "21bb1a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from gym_reversi import ReversiEnv\n",
    "\n",
    "def get_possible_actions(board, player_color):\n",
    "    actions = []\n",
    "    d = board.shape[-1]\n",
    "    opponent_color = 1 - player_color\n",
    "    for pos_x in range(d):\n",
    "        for pos_y in range(d):\n",
    "            if board[0, pos_x, pos_y] or board[1, pos_x, pos_y]:\n",
    "                continue\n",
    "            for dx in [-1, 0, 1]:\n",
    "                for dy in [-1, 0, 1]:\n",
    "                    if dx == 0 and dy == 0:\n",
    "                        continue\n",
    "                    nx = pos_x + dx\n",
    "                    ny = pos_y + dy\n",
    "                    n = 0\n",
    "                    if nx not in range(d) or ny not in range(d):\n",
    "                        continue\n",
    "                    while board[opponent_color, nx, ny] == 1:\n",
    "                        tmp_nx = nx + dx\n",
    "                        tmp_ny = ny + dy\n",
    "                        if tmp_nx not in range(d) or tmp_ny not in range(d):\n",
    "                            break\n",
    "                        n += 1\n",
    "                        nx += dx\n",
    "                        ny += dy\n",
    "                    if n > 0 and board[player_color, nx, ny] == 1:\n",
    "                        action = pos_x * d + pos_y\n",
    "                        if action not in actions:\n",
    "                            actions.append(action)\n",
    "    return actions\n",
    "\n",
    "def set_possible_actions_place(board, possible_actions, channel_index=2):\n",
    "    board[channel_index, :, :] = 0\n",
    "    # possible_actions = ReversiEnv.get_possible_actions(board, player_color)\n",
    "    possible_actions_coords = [ReversiEnv.action_to_coordinate(board, _action) for _action in possible_actions]\n",
    "    for pos_x, pos_y in possible_actions_coords:\n",
    "        board[channel_index, pos_x, pos_y] = 1\n",
    "    return board\n",
    "\n",
    "def get_test_observation(board_size=4, player_color=0):\n",
    "    # init board setting\n",
    "    N_CHANNELS = 4\n",
    "    # channels： 0: 黑棋位置， 1: 白棋位置， 2: 当前可合法落子位置，3：player 颜色\n",
    "    observation = np.zeros((N_CHANNELS, board_size, board_size), dtype=int)\n",
    "\n",
    "    observation[3, :, :] = player_color\n",
    "\n",
    "    centerL = int(board_size / 2 - 1)\n",
    "    centerR = int(board_size / 2)\n",
    "    # self.observation[2, :, :] = 1\n",
    "    # self.observation[2, (centerL) : (centerR + 1), (centerL) : (centerR + 1)] = 0\n",
    "    observation[0, centerR, centerL] = 1\n",
    "    observation[0, centerL, centerR] = 1\n",
    "    observation[1, centerL, centerL] = 1\n",
    "    observation[1, centerR, centerR] = 1\n",
    "    possible_actions = get_possible_actions(observation, player_color)\n",
    "\n",
    "    # 设置主玩家合法位置\n",
    "    set_possible_actions_place(observation, possible_actions)\n",
    "\n",
    "    return observation\n",
    "\n",
    "\n",
    "def action_to_coordinate(board, action):\n",
    "    return action // board.shape[-1], action % board.shape[-1]\n",
    "\n",
    "\n",
    "def valid_action_mask(board_size=8, possible_actions=[]):\n",
    "    valid_actions = np.zeros((board_size**2, ), dtype=np.uint8)\n",
    "    for idx in possible_actions:\n",
    "        valid_actions[idx] = 1\n",
    "    return valid_actions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8337b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3165f67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "from sb3_contrib.ppo_mask import MaskablePPO\n",
    "\n",
    "# PolicyModel = PPO\n",
    "PolicyModel = MaskablePPO\n",
    "\n",
    "model_path = \"models/ppo_8x8_backbone/model_40w\"\n",
    "# model_path = \"models/model_460w\"\n",
    "state_dict_path = model_path + '_state_dict.pt'\n",
    "\n",
    "sb3_model = PolicyModel.load(model_path)\n",
    "\n",
    "torch.save(sb3_model.policy.state_dict(), state_dict_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "caf16963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskableActorCriticPolicy(\n",
       "  (features_extractor): CustomCNN(\n",
       "    (net): MyResNet(\n",
       "      (resnet_block): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=512, out_features=64, bias=True)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=8192, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): CustomCNN(\n",
       "    (net): MyResNet(\n",
       "      (resnet_block): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=512, out_features=64, bias=True)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=8192, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): CustomCNN(\n",
       "    (net): MyResNet(\n",
       "      (resnet_block): Sequential(\n",
       "        (0): BasicBlock(\n",
       "          (conv1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): BasicBlock(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (2): BasicBlock(\n",
       "          (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (conv1): Conv2d(4, 4, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(4, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=512, out_features=64, bias=True)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=8192, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb3_model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc055898",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['features_extractor.net.resnet_block.0.conv1.weight', 'features_extractor.net.resnet_block.0.bn1.weight', 'features_extractor.net.resnet_block.0.bn1.bias', 'features_extractor.net.resnet_block.0.bn1.running_mean', 'features_extractor.net.resnet_block.0.bn1.running_var', 'features_extractor.net.resnet_block.0.bn1.num_batches_tracked', 'features_extractor.net.resnet_block.0.conv2.weight', 'features_extractor.net.resnet_block.0.bn2.weight', 'features_extractor.net.resnet_block.0.bn2.bias', 'features_extractor.net.resnet_block.0.bn2.running_mean', 'features_extractor.net.resnet_block.0.bn2.running_var', 'features_extractor.net.resnet_block.0.bn2.num_batches_tracked', 'features_extractor.net.resnet_block.0.downsample.0.weight', 'features_extractor.net.resnet_block.0.downsample.1.weight', 'features_extractor.net.resnet_block.0.downsample.1.bias', 'features_extractor.net.resnet_block.0.downsample.1.running_mean', 'features_extractor.net.resnet_block.0.downsample.1.running_var', 'features_extractor.net.resnet_block.0.downsample.1.num_batches_tracked', 'features_extractor.net.resnet_block.1.conv1.weight', 'features_extractor.net.resnet_block.1.bn1.weight', 'features_extractor.net.resnet_block.1.bn1.bias', 'features_extractor.net.resnet_block.1.bn1.running_mean', 'features_extractor.net.resnet_block.1.bn1.running_var', 'features_extractor.net.resnet_block.1.bn1.num_batches_tracked', 'features_extractor.net.resnet_block.1.conv2.weight', 'features_extractor.net.resnet_block.1.bn2.weight', 'features_extractor.net.resnet_block.1.bn2.bias', 'features_extractor.net.resnet_block.1.bn2.running_mean', 'features_extractor.net.resnet_block.1.bn2.running_var', 'features_extractor.net.resnet_block.1.bn2.num_batches_tracked', 'features_extractor.net.resnet_block.1.downsample.0.weight', 'features_extractor.net.resnet_block.1.downsample.1.weight', 'features_extractor.net.resnet_block.1.downsample.1.bias', 'features_extractor.net.resnet_block.1.downsample.1.running_mean', 'features_extractor.net.resnet_block.1.downsample.1.running_var', 'features_extractor.net.resnet_block.1.downsample.1.num_batches_tracked', 'features_extractor.net.resnet_block.2.conv1.weight', 'features_extractor.net.resnet_block.2.bn1.weight', 'features_extractor.net.resnet_block.2.bn1.bias', 'features_extractor.net.resnet_block.2.bn1.running_mean', 'features_extractor.net.resnet_block.2.bn1.running_var', 'features_extractor.net.resnet_block.2.bn1.num_batches_tracked', 'features_extractor.net.resnet_block.2.conv2.weight', 'features_extractor.net.resnet_block.2.bn2.weight', 'features_extractor.net.resnet_block.2.bn2.bias', 'features_extractor.net.resnet_block.2.bn2.running_mean', 'features_extractor.net.resnet_block.2.bn2.running_var', 'features_extractor.net.resnet_block.2.bn2.num_batches_tracked', 'features_extractor.net.conv1.weight', 'features_extractor.net.bn1.weight', 'features_extractor.net.bn1.bias', 'features_extractor.net.bn1.running_mean', 'features_extractor.net.bn1.running_var', 'features_extractor.net.bn1.num_batches_tracked', 'features_extractor.net.fc.weight', 'features_extractor.net.fc.bias', 'features_extractor.linear.0.weight', 'features_extractor.linear.0.bias', 'pi_features_extractor.net.resnet_block.0.conv1.weight', 'pi_features_extractor.net.resnet_block.0.bn1.weight', 'pi_features_extractor.net.resnet_block.0.bn1.bias', 'pi_features_extractor.net.resnet_block.0.bn1.running_mean', 'pi_features_extractor.net.resnet_block.0.bn1.running_var', 'pi_features_extractor.net.resnet_block.0.bn1.num_batches_tracked', 'pi_features_extractor.net.resnet_block.0.conv2.weight', 'pi_features_extractor.net.resnet_block.0.bn2.weight', 'pi_features_extractor.net.resnet_block.0.bn2.bias', 'pi_features_extractor.net.resnet_block.0.bn2.running_mean', 'pi_features_extractor.net.resnet_block.0.bn2.running_var', 'pi_features_extractor.net.resnet_block.0.bn2.num_batches_tracked', 'pi_features_extractor.net.resnet_block.0.downsample.0.weight', 'pi_features_extractor.net.resnet_block.0.downsample.1.weight', 'pi_features_extractor.net.resnet_block.0.downsample.1.bias', 'pi_features_extractor.net.resnet_block.0.downsample.1.running_mean', 'pi_features_extractor.net.resnet_block.0.downsample.1.running_var', 'pi_features_extractor.net.resnet_block.0.downsample.1.num_batches_tracked', 'pi_features_extractor.net.resnet_block.1.conv1.weight', 'pi_features_extractor.net.resnet_block.1.bn1.weight', 'pi_features_extractor.net.resnet_block.1.bn1.bias', 'pi_features_extractor.net.resnet_block.1.bn1.running_mean', 'pi_features_extractor.net.resnet_block.1.bn1.running_var', 'pi_features_extractor.net.resnet_block.1.bn1.num_batches_tracked', 'pi_features_extractor.net.resnet_block.1.conv2.weight', 'pi_features_extractor.net.resnet_block.1.bn2.weight', 'pi_features_extractor.net.resnet_block.1.bn2.bias', 'pi_features_extractor.net.resnet_block.1.bn2.running_mean', 'pi_features_extractor.net.resnet_block.1.bn2.running_var', 'pi_features_extractor.net.resnet_block.1.bn2.num_batches_tracked', 'pi_features_extractor.net.resnet_block.1.downsample.0.weight', 'pi_features_extractor.net.resnet_block.1.downsample.1.weight', 'pi_features_extractor.net.resnet_block.1.downsample.1.bias', 'pi_features_extractor.net.resnet_block.1.downsample.1.running_mean', 'pi_features_extractor.net.resnet_block.1.downsample.1.running_var', 'pi_features_extractor.net.resnet_block.1.downsample.1.num_batches_tracked', 'pi_features_extractor.net.resnet_block.2.conv1.weight', 'pi_features_extractor.net.resnet_block.2.bn1.weight', 'pi_features_extractor.net.resnet_block.2.bn1.bias', 'pi_features_extractor.net.resnet_block.2.bn1.running_mean', 'pi_features_extractor.net.resnet_block.2.bn1.running_var', 'pi_features_extractor.net.resnet_block.2.bn1.num_batches_tracked', 'pi_features_extractor.net.resnet_block.2.conv2.weight', 'pi_features_extractor.net.resnet_block.2.bn2.weight', 'pi_features_extractor.net.resnet_block.2.bn2.bias', 'pi_features_extractor.net.resnet_block.2.bn2.running_mean', 'pi_features_extractor.net.resnet_block.2.bn2.running_var', 'pi_features_extractor.net.resnet_block.2.bn2.num_batches_tracked', 'pi_features_extractor.net.conv1.weight', 'pi_features_extractor.net.bn1.weight', 'pi_features_extractor.net.bn1.bias', 'pi_features_extractor.net.bn1.running_mean', 'pi_features_extractor.net.bn1.running_var', 'pi_features_extractor.net.bn1.num_batches_tracked', 'pi_features_extractor.net.fc.weight', 'pi_features_extractor.net.fc.bias', 'pi_features_extractor.linear.0.weight', 'pi_features_extractor.linear.0.bias', 'vf_features_extractor.net.resnet_block.0.conv1.weight', 'vf_features_extractor.net.resnet_block.0.bn1.weight', 'vf_features_extractor.net.resnet_block.0.bn1.bias', 'vf_features_extractor.net.resnet_block.0.bn1.running_mean', 'vf_features_extractor.net.resnet_block.0.bn1.running_var', 'vf_features_extractor.net.resnet_block.0.bn1.num_batches_tracked', 'vf_features_extractor.net.resnet_block.0.conv2.weight', 'vf_features_extractor.net.resnet_block.0.bn2.weight', 'vf_features_extractor.net.resnet_block.0.bn2.bias', 'vf_features_extractor.net.resnet_block.0.bn2.running_mean', 'vf_features_extractor.net.resnet_block.0.bn2.running_var', 'vf_features_extractor.net.resnet_block.0.bn2.num_batches_tracked', 'vf_features_extractor.net.resnet_block.0.downsample.0.weight', 'vf_features_extractor.net.resnet_block.0.downsample.1.weight', 'vf_features_extractor.net.resnet_block.0.downsample.1.bias', 'vf_features_extractor.net.resnet_block.0.downsample.1.running_mean', 'vf_features_extractor.net.resnet_block.0.downsample.1.running_var', 'vf_features_extractor.net.resnet_block.0.downsample.1.num_batches_tracked', 'vf_features_extractor.net.resnet_block.1.conv1.weight', 'vf_features_extractor.net.resnet_block.1.bn1.weight', 'vf_features_extractor.net.resnet_block.1.bn1.bias', 'vf_features_extractor.net.resnet_block.1.bn1.running_mean', 'vf_features_extractor.net.resnet_block.1.bn1.running_var', 'vf_features_extractor.net.resnet_block.1.bn1.num_batches_tracked', 'vf_features_extractor.net.resnet_block.1.conv2.weight', 'vf_features_extractor.net.resnet_block.1.bn2.weight', 'vf_features_extractor.net.resnet_block.1.bn2.bias', 'vf_features_extractor.net.resnet_block.1.bn2.running_mean', 'vf_features_extractor.net.resnet_block.1.bn2.running_var', 'vf_features_extractor.net.resnet_block.1.bn2.num_batches_tracked', 'vf_features_extractor.net.resnet_block.1.downsample.0.weight', 'vf_features_extractor.net.resnet_block.1.downsample.1.weight', 'vf_features_extractor.net.resnet_block.1.downsample.1.bias', 'vf_features_extractor.net.resnet_block.1.downsample.1.running_mean', 'vf_features_extractor.net.resnet_block.1.downsample.1.running_var', 'vf_features_extractor.net.resnet_block.1.downsample.1.num_batches_tracked', 'vf_features_extractor.net.resnet_block.2.conv1.weight', 'vf_features_extractor.net.resnet_block.2.bn1.weight', 'vf_features_extractor.net.resnet_block.2.bn1.bias', 'vf_features_extractor.net.resnet_block.2.bn1.running_mean', 'vf_features_extractor.net.resnet_block.2.bn1.running_var', 'vf_features_extractor.net.resnet_block.2.bn1.num_batches_tracked', 'vf_features_extractor.net.resnet_block.2.conv2.weight', 'vf_features_extractor.net.resnet_block.2.bn2.weight', 'vf_features_extractor.net.resnet_block.2.bn2.bias', 'vf_features_extractor.net.resnet_block.2.bn2.running_mean', 'vf_features_extractor.net.resnet_block.2.bn2.running_var', 'vf_features_extractor.net.resnet_block.2.bn2.num_batches_tracked', 'vf_features_extractor.net.conv1.weight', 'vf_features_extractor.net.bn1.weight', 'vf_features_extractor.net.bn1.bias', 'vf_features_extractor.net.bn1.running_mean', 'vf_features_extractor.net.bn1.running_var', 'vf_features_extractor.net.bn1.num_batches_tracked', 'vf_features_extractor.net.fc.weight', 'vf_features_extractor.net.fc.bias', 'vf_features_extractor.linear.0.weight', 'vf_features_extractor.linear.0.bias', 'mlp_extractor.policy_net.0.weight', 'mlp_extractor.policy_net.0.bias', 'mlp_extractor.policy_net.2.weight', 'mlp_extractor.policy_net.2.bias', 'mlp_extractor.value_net.0.weight', 'mlp_extractor.value_net.0.bias', 'mlp_extractor.value_net.2.weight', 'mlp_extractor.value_net.2.bias', 'action_net.weight', 'action_net.bias', 'value_net.weight', 'value_net.bias'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb3_model.policy.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8b0b56a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=256, out_features=16, bias=True)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy.action_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a862d219",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fc33ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from model_deploy.policies import CustomCNN, ActorCriticPolicy\n",
    "from model_deploy.custom_feature_extractor import CustomCNN\n",
    "from model_deploy.policies import MaskableActorCriticPolicy\n",
    "\n",
    "def build_model(state_dict_path, features_extractor_kwargs, observation_space=(4,8,8)):\n",
    "\n",
    "    # features_extractor_kwargs=dict(features_dim=1024,\n",
    "    #                                net_arch=[64, 128, 256],\n",
    "    #                                # net_arch=[64, 128, 128],\n",
    "    #                                # net_arch=[32, 64, 128],\n",
    "    #                                kernel_size=3,\n",
    "    #                                stride=1,\n",
    "    #                                padding='same',\n",
    "    #                                is_batch_norm=False),\n",
    "\n",
    "    action_space = [observation_space[1]*observation_space[2]]\n",
    "\n",
    "    policy_model = MaskableActorCriticPolicy(\n",
    "                    observation_space = observation_space,\n",
    "                    action_space = action_space,\n",
    "                    net_arch=[256, 256],\n",
    "                    features_extractor_class = CustomCNN,\n",
    "                    features_extractor_kwargs = features_extractor_kwargs,\n",
    "                    normalize_images= False,\n",
    "    )\n",
    "\n",
    "    return policy_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5af5c08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9321ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5da6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# ppo_model = PPO.load(\"models/Reversi_ppo_4x4/model_100w\")\n",
    "\n",
    "# ## 保存模型\n",
    "# torch.save(ppo_model.policy, 'models/Reversi_ppo_4x4/model_100w.pth')\n",
    "\n",
    "# ## 读取模型\n",
    "# pth_model = torch.load('models/Reversi_ppo_4x4/model_100w.pth')\n",
    "\n",
    "observation = get_test_observation(board_size=8, player_color=0)\n",
    "# observation\n",
    "\n",
    "possible_actions = get_possible_actions(observation, player_color=0)\n",
    "\n",
    "action_mask = valid_action_mask(board_size=8, possible_actions=possible_actions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3ecd92e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[19, 26, 37, 44]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "possible_actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97fe7375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "      dtype=uint8)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f57fffd",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "predict() got an unexpected keyword argument 'action_mask'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-e52f0bcf3963>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_states\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msb3_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maction_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# action_to_coordinate(observation, action)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: predict() got an unexpected keyword argument 'action_mask'"
     ]
    }
   ],
   "source": [
    "action, _states = sb3_model.predict(observation, deterministic=True, action_mask=action_mask)\n",
    "action\n",
    "# action_to_coordinate(observation, action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78141b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(26, dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b3d8b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MaskableActorCriticPolicy(\n",
       "  (features_extractor): CustomCNN(\n",
       "    (net): MyCnnNet(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "        (6): Flatten(start_dim=1, end_dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=8192, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): CustomCNN(\n",
       "    (net): MyCnnNet(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "        (6): Flatten(start_dim=1, end_dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=8192, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): CustomCNN(\n",
       "    (net): MyCnnNet(\n",
       "      (conv_block): Sequential(\n",
       "        (0): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): ReLU()\n",
       "        (2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (3): ReLU()\n",
       "        (4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (5): ReLU()\n",
       "        (6): Flatten(start_dim=1, end_dim=-1)\n",
       "      )\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=8192, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700cbbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70e67ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "# from model_deploy.policies import CustomCNN, ActorCriticPolicy\n",
    "from model_deploy.custom_feature_extractor import CustomCNN\n",
    "from model_deploy.policies import MaskableActorCriticPolicy\n",
    "\n",
    "\n",
    "backbone='cnn'\n",
    "backbone='res_net'\n",
    "\n",
    "features_extractor_kwargs=dict(features_dim=256,\n",
    "                               backbone=backbone,\n",
    "#                                net_arch=[64, 128, 256],\n",
    "                               net_arch=[64, 128, 128],\n",
    "#                                net_arch=[32, 64, 128],\n",
    "#                                net_arch=[32, 64, 64],\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding=1,\n",
    "                               is_batch_norm=False\n",
    "                               )\n",
    "\n",
    "observation_space=(4, 8, 8)\n",
    "action_space = [observation_space[1]*observation_space[2]]\n",
    "\n",
    "policy_model = MaskableActorCriticPolicy(\n",
    "        observation_space=observation_space, \n",
    "        action_space=action_space, \n",
    "        net_arch=[256, 256],\n",
    "        features_extractor_class = CustomCNN,\n",
    "        features_extractor_kwargs = features_extractor_kwargs,\n",
    "        share_features_extractor = True,\n",
    "    normalize_images=False\n",
    "\n",
    ")\n",
    "\n",
    "# model_path = \"models/ppo_8x8_cnn/model\"\n",
    "model_path = \"models/ppo_8x8_backbone/model_40w\"\n",
    "# model_path = \"models/model_460w\"\n",
    "\n",
    "# model_path = \"models/model\"\n",
    "state_dict_path = model_path + '_state_dict.pt'\n",
    "\n",
    "policy_model.load_state_dict(torch.load(state_dict_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9804e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_masks = \n",
    "action, _states = policy_model.predict(observation, deterministic=True, action_masks)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6b1bfd86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action.reshape(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "596f5f9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c0c9d465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from stable_baselines3 import PPO\n",
    "PolicyModel = PPO\n",
    "\n",
    "model_path = \"models/ppo_8x8_cnn/model_1480w\"\n",
    "# model_path = \"models/model_460w\"\n",
    "state_dict_path = model_path + '_state_dict.pt'\n",
    "\n",
    "sb3_model = PolicyModel.load(model_path)\n",
    "\n",
    "torch.save(sb3_model.policy.state_dict(), state_dict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7bfd560a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44]], dtype=int64)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model_path = \"models/ppo_8x8_cnn/model\"\n",
    "model_path = \"models/ppo_8x8_cnn/model_1480w\"\n",
    "# model_path = \"models/model_460w\"\n",
    "\n",
    "# model_path = \"models/model\"\n",
    "state_dict_path = model_path + '_state_dict.pt'\n",
    "\n",
    "# features_extractor_kwargs=dict(features_dim=1024,\n",
    "#                                net_arch=[64, 128, 256],\n",
    "#                                # net_arch=[64, 128, 128],\n",
    "#                                # net_arch=[32, 64, 128],\n",
    "#                                kernel_size=3,\n",
    "#                                stride=1,\n",
    "#                                padding='same',\n",
    "#                                is_batch_norm=False),\n",
    "\n",
    "features_extractor_kwargs=dict(features_dim=256,\n",
    "#                                net_arch=[64, 128, 256],\n",
    "#                                net_arch=[64, 128, 128],\n",
    "                               net_arch=[32, 64, 64],\n",
    "                               kernel_size=3,\n",
    "                               stride=1,\n",
    "                               padding='same',\n",
    "                               is_batch_norm=False)\n",
    "\n",
    "policy_model = build_model(state_dict_path, features_extractor_kwargs, observation_space=(4,8,8))\n",
    "\n",
    "policy_model.load_state_dict(torch.load(state_dict_path))\n",
    "action, _states = policy_model.predict(observation, deterministic=True)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "20a3b267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[37]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action, _states = policy_model.predict(observation, deterministic=True)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff313dfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): CustomCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): CustomCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): CustomCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb3_model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6eeb6529",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): CustomCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (pi_features_extractor): CustomCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (vf_features_extractor): CustomCNN(\n",
       "    (cnn): Sequential(\n",
       "      (0): Conv2d(4, 32, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (1): ReLU()\n",
       "      (2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (3): ReLU()\n",
       "      (4): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
       "      (5): ReLU()\n",
       "      (6): Flatten(start_dim=1, end_dim=-1)\n",
       "    )\n",
       "    (linear): Sequential(\n",
       "      (0): Linear(in_features=4096, out_features=256, bias=True)\n",
       "      (1): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=256, out_features=256, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=256, out_features=64, bias=True)\n",
       "  (value_net): Linear(in_features=256, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5b9f2b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('features_extractor.cnn.0.weight',\n",
       "              tensor([[[[ 5.8862e-02,  3.7363e-01, -1.3097e-01],\n",
       "                        [-1.3117e-01, -1.4281e-01,  1.0642e-02],\n",
       "                        [-3.2974e-01,  5.1945e-02, -1.7016e-01]],\n",
       "              \n",
       "                       [[-1.6550e-01,  2.2424e-01,  6.2481e-01],\n",
       "                        [ 1.1638e-01,  6.0274e-02,  2.3141e-01],\n",
       "                        [-1.1957e-01, -3.1702e-01,  2.2510e-01]],\n",
       "              \n",
       "                       [[-1.1080e-01,  3.4992e-01, -2.3739e-01],\n",
       "                        [-8.8834e-02,  2.8504e-01,  1.4751e-01],\n",
       "                        [ 1.0280e-01, -2.0961e-01, -1.3982e-01]],\n",
       "              \n",
       "                       [[-3.6928e-01,  2.0983e-01, -2.5590e-01],\n",
       "                        [ 1.8024e-02,  4.0449e-01, -2.9480e-01],\n",
       "                        [-1.0230e-01, -4.0876e-02,  4.6758e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3953e-02, -1.4663e-01,  3.7173e-01],\n",
       "                        [ 2.7627e-01,  1.3760e-01,  1.6290e-01],\n",
       "                        [-2.6357e-02, -1.3164e-01, -2.5004e-01]],\n",
       "              \n",
       "                       [[ 1.5716e-01, -6.5916e-01, -3.7163e-01],\n",
       "                        [-1.4906e-01, -3.3604e-01, -9.9113e-02],\n",
       "                        [ 1.2724e-01,  1.5649e-01, -6.1665e-02]],\n",
       "              \n",
       "                       [[-2.0052e-02,  1.7148e-01, -3.4569e-01],\n",
       "                        [ 4.4725e-01, -1.2255e-02,  4.0592e-01],\n",
       "                        [-1.6992e-01, -1.4607e-01, -3.2384e-01]],\n",
       "              \n",
       "                       [[-1.7028e-02, -8.5108e-02, -2.3798e-01],\n",
       "                        [ 2.8127e-01,  1.8218e-02,  2.9830e-01],\n",
       "                        [-1.0245e-01, -3.9497e-02,  2.7497e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8271e-02, -7.2140e-01,  3.2392e-02],\n",
       "                        [ 2.9607e-01, -1.0893e-01, -3.0054e-01],\n",
       "                        [-2.4524e-01, -3.4102e-01,  6.4828e-02]],\n",
       "              \n",
       "                       [[-1.5833e-01,  2.8716e-01, -2.8541e-01],\n",
       "                        [-8.1920e-02,  5.3344e-01, -8.9772e-02],\n",
       "                        [-2.3166e-01,  2.8033e-01, -2.1412e-01]],\n",
       "              \n",
       "                       [[-9.1274e-02,  5.6942e-02, -1.8451e-01],\n",
       "                        [-1.0216e-01,  7.0682e-02,  5.3959e-02],\n",
       "                        [ 3.2387e-01, -2.0344e-01, -4.7135e-02]],\n",
       "              \n",
       "                       [[ 1.5830e-02,  4.4492e-02,  1.4217e-01],\n",
       "                        [-1.3069e-02, -1.6149e-01, -1.3701e-02],\n",
       "                        [-1.9981e-01,  2.9199e-01,  3.8395e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2955e-01, -1.0186e-01,  7.6801e-02],\n",
       "                        [-8.6575e-02, -8.0612e-03, -1.5902e-01],\n",
       "                        [-2.8949e-04, -2.3332e-01,  2.2612e-01]],\n",
       "              \n",
       "                       [[ 3.0940e-02, -2.1828e-01,  4.1376e-01],\n",
       "                        [ 1.4290e-02, -3.3372e-02,  1.5831e-01],\n",
       "                        [ 2.5643e-02, -9.1558e-02,  3.4163e-01]],\n",
       "              \n",
       "                       [[ 8.4127e-02,  3.7897e-02, -1.5717e-01],\n",
       "                        [ 6.7579e-02,  3.5411e-01,  3.2907e-02],\n",
       "                        [-6.1220e-02,  4.9653e-01,  1.0497e-01]],\n",
       "              \n",
       "                       [[ 1.0379e-01, -2.9524e-01,  2.6511e-02],\n",
       "                        [-3.9713e-02, -5.0619e-01, -3.7104e-02],\n",
       "                        [-4.2020e-01,  5.8012e-01,  6.2754e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.3067e-01, -1.3824e-02, -2.5355e-01],\n",
       "                        [ 3.1014e-01,  1.0804e-02,  1.3980e-01],\n",
       "                        [-1.2415e-01,  4.2892e-02,  1.1416e-01]],\n",
       "              \n",
       "                       [[-2.8074e-01,  7.6132e-02,  3.3707e-01],\n",
       "                        [ 4.0284e-02, -2.8315e-01,  6.4632e-02],\n",
       "                        [ 1.1876e-01, -1.0156e-01, -7.2963e-02]],\n",
       "              \n",
       "                       [[ 3.2671e-01, -1.1268e-01,  2.0574e-02],\n",
       "                        [ 1.2063e-01,  2.8370e-02, -2.6460e-01],\n",
       "                        [-5.2230e-02,  3.3347e-02, -1.6008e-01]],\n",
       "              \n",
       "                       [[ 3.0438e-01, -2.1996e-01, -3.7970e-01],\n",
       "                        [-4.8888e-01, -1.0636e-01,  2.4557e-01],\n",
       "                        [ 4.3349e-02,  1.3737e-02,  5.5982e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5865e-01, -1.3829e-01, -3.8599e-02],\n",
       "                        [ 2.3240e-01, -2.6784e-01, -2.6056e-01],\n",
       "                        [ 3.3347e-01,  1.6459e-01, -9.9123e-02]],\n",
       "              \n",
       "                       [[-1.3240e-02, -2.4913e-01,  4.1011e-01],\n",
       "                        [-3.2280e-01,  4.6701e-01, -4.4934e-02],\n",
       "                        [-5.1787e-01, -2.1056e-01,  1.4919e-01]],\n",
       "              \n",
       "                       [[ 1.6178e-01, -9.8057e-02,  6.0526e-02],\n",
       "                        [-1.1812e-01,  1.3447e-01,  2.1761e-01],\n",
       "                        [-4.6781e-01, -6.2003e-02, -1.7766e-01]],\n",
       "              \n",
       "                       [[-1.6266e-01,  2.7354e-03, -2.3151e-01],\n",
       "                        [ 2.1946e-01, -4.2909e-01, -6.8603e-02],\n",
       "                        [ 4.2664e-01, -1.6004e-01, -6.8614e-02]]]])),\n",
       "             ('features_extractor.cnn.0.bias',\n",
       "              tensor([-0.0566, -0.0666,  0.0050,  0.0101, -0.0325, -0.1201, -0.0267, -0.0672,\n",
       "                      -0.0574, -0.0115,  0.0515, -0.0224, -0.0393, -0.0064, -0.0498,  0.0367,\n",
       "                       0.0978,  0.1039,  0.0021, -0.0343, -0.0318, -0.0280,  0.0324, -0.0059,\n",
       "                       0.0608,  0.0087, -0.0349,  0.0326,  0.0145, -0.0126, -0.0186,  0.0100])),\n",
       "             ('features_extractor.cnn.2.weight',\n",
       "              tensor([[[[ 0.0337,  0.0183,  0.1811],\n",
       "                        [-0.0092,  0.0704,  0.0781],\n",
       "                        [ 0.0079,  0.0235,  0.2508]],\n",
       "              \n",
       "                       [[-0.0559, -0.0903, -0.1553],\n",
       "                        [ 0.0236,  0.0402,  0.0951],\n",
       "                        [ 0.1265, -0.1126, -0.1120]],\n",
       "              \n",
       "                       [[-0.0063, -0.0839,  0.0146],\n",
       "                        [ 0.0568,  0.0494,  0.0495],\n",
       "                        [-0.1111, -0.1969, -0.1347]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1430,  0.0147, -0.0547],\n",
       "                        [ 0.0025, -0.1023,  0.1860],\n",
       "                        [ 0.0145, -0.0365, -0.0542]],\n",
       "              \n",
       "                       [[-0.0599, -0.0654, -0.0008],\n",
       "                        [ 0.0207,  0.1879,  0.0056],\n",
       "                        [-0.0875, -0.0323,  0.0365]],\n",
       "              \n",
       "                       [[ 0.2021,  0.0356,  0.0555],\n",
       "                        [ 0.1441, -0.0895,  0.0371],\n",
       "                        [-0.1306, -0.1064, -0.0320]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0295,  0.1417,  0.0898],\n",
       "                        [-0.0841, -0.0365,  0.0656],\n",
       "                        [-0.1357,  0.1170,  0.1063]],\n",
       "              \n",
       "                       [[ 0.1105, -0.0365,  0.0223],\n",
       "                        [-0.0618,  0.0518, -0.0784],\n",
       "                        [ 0.1527,  0.1740, -0.0630]],\n",
       "              \n",
       "                       [[ 0.1227, -0.1392, -0.0040],\n",
       "                        [ 0.0392, -0.0950,  0.1206],\n",
       "                        [-0.0319,  0.0154,  0.0485]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1858,  0.0093, -0.0078],\n",
       "                        [ 0.0195, -0.0297, -0.1388],\n",
       "                        [-0.0933, -0.0209,  0.0919]],\n",
       "              \n",
       "                       [[ 0.0456, -0.0209, -0.0961],\n",
       "                        [ 0.0440, -0.0379, -0.0509],\n",
       "                        [ 0.0703, -0.0644,  0.0500]],\n",
       "              \n",
       "                       [[ 0.1575,  0.1472, -0.1588],\n",
       "                        [ 0.0704, -0.0619,  0.0216],\n",
       "                        [-0.0397,  0.0828,  0.0385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0037,  0.0176, -0.2178],\n",
       "                        [-0.0295, -0.1379,  0.0542],\n",
       "                        [ 0.0287,  0.0869, -0.0711]],\n",
       "              \n",
       "                       [[ 0.0246,  0.0180, -0.0136],\n",
       "                        [ 0.0585, -0.0908,  0.0373],\n",
       "                        [-0.1708,  0.0041, -0.1778]],\n",
       "              \n",
       "                       [[ 0.0947,  0.0598,  0.0550],\n",
       "                        [-0.0396,  0.1413, -0.1427],\n",
       "                        [-0.1346, -0.0290, -0.0006]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0819, -0.0565, -0.0107],\n",
       "                        [ 0.0251,  0.0080, -0.1340],\n",
       "                        [-0.0806, -0.0358,  0.0328]],\n",
       "              \n",
       "                       [[-0.0176, -0.0219,  0.0098],\n",
       "                        [ 0.0743,  0.0146, -0.0068],\n",
       "                        [ 0.0307, -0.0660, -0.1691]],\n",
       "              \n",
       "                       [[-0.0751,  0.0300, -0.0542],\n",
       "                        [-0.1141,  0.0117, -0.0460],\n",
       "                        [ 0.1561,  0.0939,  0.1133]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0220, -0.0986,  0.0897],\n",
       "                        [ 0.0680, -0.1171,  0.0113],\n",
       "                        [-0.0018,  0.0855,  0.0803]],\n",
       "              \n",
       "                       [[ 0.0904,  0.0183, -0.1006],\n",
       "                        [-0.1004, -0.0417, -0.1845],\n",
       "                        [-0.1535,  0.0890, -0.0894]],\n",
       "              \n",
       "                       [[ 0.1373,  0.0621, -0.0894],\n",
       "                        [ 0.2271,  0.1095, -0.0319],\n",
       "                        [ 0.0152, -0.0245,  0.1569]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0120, -0.0119,  0.0167],\n",
       "                        [-0.0655,  0.0904,  0.0507],\n",
       "                        [-0.0890,  0.2800, -0.0387]],\n",
       "              \n",
       "                       [[-0.0526, -0.1061,  0.1017],\n",
       "                        [ 0.0505,  0.0431, -0.0106],\n",
       "                        [ 0.1109, -0.1559,  0.0986]],\n",
       "              \n",
       "                       [[ 0.1002,  0.1639,  0.0977],\n",
       "                        [-0.0913, -0.0571,  0.0487],\n",
       "                        [-0.1078,  0.1614, -0.0788]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1416,  0.0937,  0.0798],\n",
       "                        [ 0.0718,  0.0977, -0.0887],\n",
       "                        [-0.0445,  0.0350, -0.0309]],\n",
       "              \n",
       "                       [[ 0.1969, -0.0258, -0.0243],\n",
       "                        [ 0.2591,  0.0262,  0.0080],\n",
       "                        [-0.0006,  0.0793, -0.2098]],\n",
       "              \n",
       "                       [[ 0.0529, -0.0417,  0.0800],\n",
       "                        [-0.0687, -0.0148,  0.2967],\n",
       "                        [-0.1469, -0.2498, -0.0229]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1094,  0.0152, -0.0539],\n",
       "                        [-0.0680, -0.0788,  0.0701],\n",
       "                        [ 0.0526, -0.1560, -0.2047]],\n",
       "              \n",
       "                       [[ 0.0327, -0.0424, -0.0037],\n",
       "                        [-0.0473, -0.0575,  0.1007],\n",
       "                        [ 0.0497, -0.1394, -0.0099]],\n",
       "              \n",
       "                       [[-0.0807, -0.1619, -0.0035],\n",
       "                        [ 0.0386, -0.0241,  0.0321],\n",
       "                        [-0.1117,  0.0962, -0.1791]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0174, -0.0043, -0.0614],\n",
       "                        [-0.0582,  0.0048, -0.1357],\n",
       "                        [ 0.0407, -0.0188, -0.1285]],\n",
       "              \n",
       "                       [[ 0.1117, -0.0041, -0.1399],\n",
       "                        [ 0.0533, -0.1416, -0.1361],\n",
       "                        [-0.0427,  0.0032, -0.0008]],\n",
       "              \n",
       "                       [[ 0.0627,  0.0510,  0.0315],\n",
       "                        [ 0.1574,  0.1953, -0.1351],\n",
       "                        [ 0.0472, -0.0914,  0.0192]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2125, -0.0262, -0.0840],\n",
       "                        [-0.0027, -0.0503,  0.0810],\n",
       "                        [ 0.0658, -0.0355, -0.0023]],\n",
       "              \n",
       "                       [[-0.0149,  0.0386, -0.0299],\n",
       "                        [-0.0956, -0.1379, -0.0337],\n",
       "                        [ 0.0054,  0.1598, -0.0692]],\n",
       "              \n",
       "                       [[ 0.0698, -0.1232, -0.0237],\n",
       "                        [ 0.0924, -0.0492,  0.0697],\n",
       "                        [-0.0753, -0.0362,  0.0646]]]])),\n",
       "             ('features_extractor.cnn.2.bias',\n",
       "              tensor([-0.0390, -0.0034, -0.0113, -0.0361,  0.0085,  0.0049, -0.0228,  0.0194,\n",
       "                      -0.0314, -0.0193, -0.0153, -0.0270, -0.0255,  0.0063, -0.0083,  0.0100,\n",
       "                       0.0165, -0.0047, -0.0294, -0.0083,  0.0202, -0.0153,  0.0065, -0.0314,\n",
       "                       0.0038,  0.0038, -0.0122, -0.0127, -0.0490,  0.0145, -0.0177,  0.0108,\n",
       "                       0.0031, -0.0147, -0.0546, -0.0104,  0.0075, -0.0224, -0.0226, -0.0075,\n",
       "                      -0.0132, -0.0033, -0.0336, -0.0368,  0.0054, -0.0007, -0.0043, -0.0222,\n",
       "                      -0.0103, -0.0611, -0.0028, -0.0120, -0.0236, -0.0233, -0.0365,  0.0186,\n",
       "                      -0.0335,  0.0064, -0.0251, -0.0194, -0.0224, -0.0334, -0.0377, -0.0148])),\n",
       "             ('features_extractor.cnn.4.weight',\n",
       "              tensor([[[[-0.1014,  0.0709,  0.1082],\n",
       "                        [-0.0704,  0.0229, -0.0548],\n",
       "                        [ 0.0604,  0.0755, -0.1099]],\n",
       "              \n",
       "                       [[ 0.0352, -0.2052, -0.0431],\n",
       "                        [ 0.0014, -0.1739, -0.0260],\n",
       "                        [-0.0592,  0.1083,  0.0191]],\n",
       "              \n",
       "                       [[-0.1012,  0.0074,  0.1031],\n",
       "                        [-0.0348, -0.0550, -0.0482],\n",
       "                        [ 0.0439,  0.0012, -0.0179]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0070,  0.0207,  0.0602],\n",
       "                        [ 0.0391, -0.0656,  0.0200],\n",
       "                        [ 0.0378,  0.0211, -0.1084]],\n",
       "              \n",
       "                       [[-0.0429,  0.0146, -0.0985],\n",
       "                        [ 0.0302, -0.0878,  0.1199],\n",
       "                        [-0.1365,  0.1271, -0.0090]],\n",
       "              \n",
       "                       [[-0.1360,  0.1147, -0.0451],\n",
       "                        [-0.0211,  0.0499,  0.0696],\n",
       "                        [ 0.0633, -0.1438,  0.0214]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0525, -0.1044, -0.0197],\n",
       "                        [ 0.0397, -0.0160, -0.0297],\n",
       "                        [-0.0340,  0.0754,  0.0151]],\n",
       "              \n",
       "                       [[-0.0837,  0.0467,  0.0243],\n",
       "                        [ 0.0600,  0.0197, -0.0111],\n",
       "                        [-0.0211,  0.0185,  0.0020]],\n",
       "              \n",
       "                       [[ 0.0702,  0.0136,  0.0851],\n",
       "                        [-0.0559, -0.0383,  0.0509],\n",
       "                        [ 0.0301,  0.0863, -0.0579]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0008,  0.1314, -0.0715],\n",
       "                        [-0.0519, -0.0206,  0.0187],\n",
       "                        [-0.0610, -0.1474,  0.0442]],\n",
       "              \n",
       "                       [[-0.0570, -0.0038, -0.0652],\n",
       "                        [-0.1259,  0.0309, -0.1133],\n",
       "                        [ 0.0531,  0.0175, -0.0488]],\n",
       "              \n",
       "                       [[-0.0420, -0.1407,  0.0187],\n",
       "                        [ 0.0362,  0.0119,  0.1130],\n",
       "                        [ 0.1020, -0.0303,  0.0771]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0843,  0.0506, -0.0102],\n",
       "                        [-0.0309,  0.0596,  0.1865],\n",
       "                        [ 0.0695, -0.1693, -0.1030]],\n",
       "              \n",
       "                       [[ 0.0419,  0.0717,  0.1250],\n",
       "                        [-0.0795,  0.0079,  0.1064],\n",
       "                        [-0.0167, -0.0967, -0.1259]],\n",
       "              \n",
       "                       [[ 0.0243,  0.0092,  0.0335],\n",
       "                        [ 0.0913, -0.0200,  0.1210],\n",
       "                        [ 0.0838, -0.0482,  0.0845]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0013, -0.0548, -0.1030],\n",
       "                        [ 0.1146,  0.1135, -0.0269],\n",
       "                        [ 0.0268,  0.0550, -0.0531]],\n",
       "              \n",
       "                       [[ 0.0765, -0.0841,  0.0607],\n",
       "                        [ 0.0406,  0.0043, -0.0290],\n",
       "                        [-0.0238,  0.0344, -0.0343]],\n",
       "              \n",
       "                       [[-0.0306, -0.0158,  0.0538],\n",
       "                        [-0.0041,  0.0514,  0.0606],\n",
       "                        [ 0.0687, -0.0608,  0.0098]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0852, -0.0107, -0.0530],\n",
       "                        [ 0.0538, -0.0349, -0.0862],\n",
       "                        [ 0.0586,  0.0060, -0.1364]],\n",
       "              \n",
       "                       [[ 0.0105, -0.0361, -0.0264],\n",
       "                        [ 0.1033, -0.0619, -0.0171],\n",
       "                        [-0.0026,  0.0930, -0.0463]],\n",
       "              \n",
       "                       [[-0.0930, -0.0707,  0.0251],\n",
       "                        [ 0.0259, -0.0004,  0.2019],\n",
       "                        [-0.0139, -0.0725, -0.1661]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0039,  0.0044,  0.0718],\n",
       "                        [ 0.1228, -0.0095,  0.0568],\n",
       "                        [-0.0977, -0.0113,  0.0441]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0876,  0.0224],\n",
       "                        [ 0.0183, -0.0459, -0.0793],\n",
       "                        [-0.0716, -0.0030, -0.0981]],\n",
       "              \n",
       "                       [[-0.0205,  0.0779, -0.1334],\n",
       "                        [-0.1343,  0.0562,  0.0465],\n",
       "                        [ 0.0765, -0.0930, -0.0822]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0020, -0.1609, -0.0816],\n",
       "                        [-0.0171, -0.0815, -0.0878],\n",
       "                        [-0.0384,  0.0751,  0.0293]],\n",
       "              \n",
       "                       [[ 0.0061, -0.0220, -0.0833],\n",
       "                        [ 0.0124, -0.0083,  0.0255],\n",
       "                        [ 0.0746, -0.0895,  0.0211]],\n",
       "              \n",
       "                       [[-0.1771, -0.1180,  0.0226],\n",
       "                        [ 0.0984, -0.0210, -0.0414],\n",
       "                        [ 0.1382,  0.0387,  0.0620]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0797,  0.0699,  0.0314],\n",
       "                        [-0.0514, -0.1527, -0.0059],\n",
       "                        [-0.0050, -0.0193,  0.0991]],\n",
       "              \n",
       "                       [[-0.1514,  0.0452, -0.0108],\n",
       "                        [-0.0435, -0.1535, -0.0243],\n",
       "                        [ 0.0623, -0.0156, -0.0899]],\n",
       "              \n",
       "                       [[ 0.0136,  0.0049,  0.1030],\n",
       "                        [-0.0593, -0.0197, -0.0076],\n",
       "                        [-0.0189, -0.0357, -0.0282]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0250, -0.0896,  0.1386],\n",
       "                        [-0.0635, -0.0235,  0.0971],\n",
       "                        [-0.0404,  0.0862, -0.0077]],\n",
       "              \n",
       "                       [[-0.0196,  0.0070, -0.0055],\n",
       "                        [-0.0389, -0.1478, -0.0312],\n",
       "                        [ 0.0856,  0.0393, -0.0485]],\n",
       "              \n",
       "                       [[-0.0351,  0.0242, -0.0526],\n",
       "                        [-0.0668, -0.0827,  0.0873],\n",
       "                        [ 0.0886, -0.0227, -0.1589]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1103, -0.0872,  0.0069],\n",
       "                        [-0.0348,  0.0992,  0.0197],\n",
       "                        [-0.0116,  0.0288,  0.0328]],\n",
       "              \n",
       "                       [[-0.0918,  0.0735,  0.0194],\n",
       "                        [-0.1080,  0.0114, -0.0639],\n",
       "                        [-0.0689,  0.0118,  0.0921]],\n",
       "              \n",
       "                       [[ 0.0896, -0.0524,  0.0459],\n",
       "                        [-0.0676, -0.0987,  0.0727],\n",
       "                        [ 0.0799, -0.2089,  0.0608]]]])),\n",
       "             ('features_extractor.cnn.4.bias',\n",
       "              tensor([-0.0527, -0.0421, -0.0194, -0.0534, -0.0266, -0.0121, -0.0038, -0.0021,\n",
       "                      -0.0285, -0.0684, -0.0531, -0.0151, -0.0482, -0.0270, -0.0442, -0.0434,\n",
       "                      -0.0313, -0.0371, -0.0373, -0.0229, -0.0440, -0.0215, -0.0519, -0.0588,\n",
       "                      -0.0308, -0.0252, -0.0491, -0.0177, -0.0092, -0.0191, -0.0484, -0.0235,\n",
       "                      -0.0379, -0.0287, -0.0316, -0.0126, -0.0297, -0.0215, -0.0215, -0.0448,\n",
       "                      -0.0187, -0.0510, -0.0096, -0.0514, -0.0251, -0.0464, -0.0250, -0.0309,\n",
       "                      -0.0291, -0.0448, -0.0306, -0.0332, -0.0095, -0.0130, -0.0548, -0.0416,\n",
       "                      -0.0410, -0.0265, -0.0136, -0.0418,  0.0009, -0.0626, -0.0153, -0.0527])),\n",
       "             ('features_extractor.linear.0.weight',\n",
       "              tensor([[-0.0270, -0.0135, -0.0357,  ..., -0.0760, -0.0304,  0.0015],\n",
       "                      [-0.0007, -0.0621,  0.0162,  ..., -0.0310,  0.0050, -0.0013],\n",
       "                      [-0.0178,  0.0220,  0.0382,  ...,  0.0995, -0.0172,  0.0078],\n",
       "                      ...,\n",
       "                      [-0.0200, -0.0426, -0.1067,  ..., -0.0226, -0.0147, -0.0272],\n",
       "                      [-0.0199,  0.1090, -0.0471,  ...,  0.0651,  0.0328, -0.0295],\n",
       "                      [ 0.0558, -0.0437,  0.0408,  ...,  0.0242,  0.0245,  0.0446]])),\n",
       "             ('features_extractor.linear.0.bias',\n",
       "              tensor([-5.6608e-03,  6.0292e-03, -9.1965e-03, -1.8568e-02, -1.1593e-02,\n",
       "                       9.6789e-03, -1.5750e-02, -2.1523e-02, -1.4694e-02,  1.8843e-03,\n",
       "                      -1.0284e-02, -1.3603e-02, -1.9655e-02,  2.5110e-03, -2.3079e-02,\n",
       "                      -2.5503e-03,  2.5569e-02, -1.5688e-02, -2.0103e-02,  5.9138e-03,\n",
       "                      -2.3874e-03,  1.0382e-02, -1.2352e-03, -6.3961e-03, -3.2044e-03,\n",
       "                       2.0733e-02, -7.9140e-03,  2.1906e-03, -3.3774e-04, -1.2366e-02,\n",
       "                      -8.4314e-03,  6.4223e-03, -1.3893e-02, -1.9243e-02, -9.8721e-03,\n",
       "                      -1.3911e-02, -1.6314e-02,  3.9481e-03,  6.8481e-03, -7.2767e-04,\n",
       "                      -3.5789e-03,  1.7647e-02,  5.1980e-03, -1.5433e-02,  2.0342e-03,\n",
       "                      -3.8536e-03,  4.9479e-03,  1.1522e-02,  3.1461e-03, -2.1221e-02,\n",
       "                      -1.8123e-02,  2.9962e-03, -2.4504e-02, -1.3904e-02, -1.9924e-02,\n",
       "                      -6.5181e-03, -1.1136e-02, -8.0146e-03,  1.1183e-03,  5.8428e-03,\n",
       "                      -6.7766e-03, -1.8218e-02,  2.0625e-02, -4.1976e-03,  9.8920e-03,\n",
       "                       2.7103e-03,  5.1831e-03, -1.0430e-02,  4.0037e-05, -2.4779e-02,\n",
       "                      -2.1182e-02, -4.8570e-04, -1.4988e-02,  4.2176e-04,  1.6978e-02,\n",
       "                      -1.7201e-02, -9.6121e-03, -1.7206e-02, -3.7706e-03, -8.1554e-03,\n",
       "                      -8.9120e-03, -4.4588e-03, -2.7373e-02,  2.3373e-03, -4.0309e-03,\n",
       "                       5.0599e-03, -3.3017e-02, -1.5682e-02, -3.8791e-03, -1.3667e-02,\n",
       "                      -1.1874e-02, -1.3697e-02, -4.7328e-03, -8.9924e-03, -1.7318e-02,\n",
       "                      -7.3571e-03, -5.0703e-03,  1.3889e-02, -1.2070e-02, -1.8983e-02,\n",
       "                      -3.0111e-03, -7.7595e-03,  1.6896e-02, -1.3754e-02,  6.6683e-03,\n",
       "                      -4.5552e-03, -3.7477e-04, -1.2147e-02, -3.4943e-03, -1.3093e-02,\n",
       "                       5.1952e-03,  1.8795e-02,  3.8898e-03, -2.4092e-02,  2.5640e-05,\n",
       "                      -1.4565e-02, -1.4779e-02, -1.6007e-02, -4.0413e-03, -2.6391e-02,\n",
       "                      -9.2754e-03, -6.6702e-03, -1.9132e-02, -1.9438e-02, -1.8338e-02,\n",
       "                      -3.7500e-03,  7.5928e-03, -1.0519e-02, -1.1963e-03,  5.0987e-03,\n",
       "                      -5.1751e-03, -1.9795e-03, -1.2211e-02, -1.1549e-02, -1.8722e-02,\n",
       "                      -5.7123e-03, -3.2459e-02, -7.2956e-03, -2.8802e-02,  3.6083e-03,\n",
       "                       4.6870e-05, -7.6378e-03, -8.7449e-03, -1.4517e-03, -4.2058e-03,\n",
       "                      -1.1429e-02, -1.9129e-02, -8.3722e-03, -1.4606e-02,  1.8631e-03,\n",
       "                      -1.6571e-02,  6.3678e-03, -2.3493e-02, -1.0677e-02, -9.0645e-03,\n",
       "                      -1.2493e-02, -1.7621e-02,  7.2907e-04, -1.5983e-02,  1.2657e-02,\n",
       "                      -1.4844e-02, -3.4709e-02,  3.4632e-03,  5.9516e-03, -1.3603e-02,\n",
       "                      -7.0841e-04, -1.5203e-02, -5.4989e-03, -6.8727e-03, -6.8712e-03,\n",
       "                      -6.7857e-03, -1.2739e-02, -9.4579e-04, -5.7958e-03, -2.0469e-02,\n",
       "                      -4.8724e-03, -1.1285e-02, -1.0248e-02,  1.5599e-02, -1.2677e-02,\n",
       "                      -1.2914e-02,  7.9928e-03, -1.6114e-02, -1.2004e-02, -9.0505e-03,\n",
       "                      -1.7559e-02,  1.1923e-02,  7.7604e-03, -4.7151e-04, -8.8959e-03,\n",
       "                       6.0266e-04, -1.1305e-02, -1.7632e-02, -9.8618e-04, -3.2808e-04,\n",
       "                      -9.2304e-03, -5.8386e-03, -1.2238e-02, -1.0198e-02, -1.9077e-03,\n",
       "                      -1.6158e-02, -1.6521e-02,  4.7318e-03,  1.0410e-02, -2.2033e-02,\n",
       "                       1.1737e-03, -1.2583e-02, -1.3367e-02,  1.6993e-03, -1.0574e-02,\n",
       "                      -3.0460e-03, -8.5488e-03, -1.0641e-02, -2.5659e-02, -1.0535e-02,\n",
       "                      -1.0917e-02, -1.0462e-02, -4.1459e-03, -1.4119e-02, -1.1132e-02,\n",
       "                      -1.0320e-02, -1.4184e-02, -1.0302e-02, -8.1392e-04, -2.7057e-03,\n",
       "                      -4.2100e-03,  1.9071e-02, -1.4972e-02,  3.7827e-03, -8.7062e-03,\n",
       "                       6.6713e-03, -9.7732e-03,  7.0135e-03,  6.3468e-03, -8.1618e-03,\n",
       "                       1.1720e-02, -1.4238e-02, -1.1268e-02,  1.4706e-02,  4.6204e-03,\n",
       "                      -9.1095e-04,  2.2036e-02, -1.6451e-02, -1.4447e-02, -1.8699e-02,\n",
       "                       9.3533e-03, -5.2393e-03,  1.2488e-02, -7.6009e-03, -9.2387e-04,\n",
       "                      -1.9480e-03, -1.4901e-02, -1.6314e-02,  5.9689e-03, -5.6877e-03,\n",
       "                       9.1546e-03])),\n",
       "             ('pi_features_extractor.cnn.0.weight',\n",
       "              tensor([[[[ 5.8862e-02,  3.7363e-01, -1.3097e-01],\n",
       "                        [-1.3117e-01, -1.4281e-01,  1.0642e-02],\n",
       "                        [-3.2974e-01,  5.1945e-02, -1.7016e-01]],\n",
       "              \n",
       "                       [[-1.6550e-01,  2.2424e-01,  6.2481e-01],\n",
       "                        [ 1.1638e-01,  6.0274e-02,  2.3141e-01],\n",
       "                        [-1.1957e-01, -3.1702e-01,  2.2510e-01]],\n",
       "              \n",
       "                       [[-1.1080e-01,  3.4992e-01, -2.3739e-01],\n",
       "                        [-8.8834e-02,  2.8504e-01,  1.4751e-01],\n",
       "                        [ 1.0280e-01, -2.0961e-01, -1.3982e-01]],\n",
       "              \n",
       "                       [[-3.6928e-01,  2.0983e-01, -2.5590e-01],\n",
       "                        [ 1.8024e-02,  4.0449e-01, -2.9480e-01],\n",
       "                        [-1.0230e-01, -4.0876e-02,  4.6758e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3953e-02, -1.4663e-01,  3.7173e-01],\n",
       "                        [ 2.7627e-01,  1.3760e-01,  1.6290e-01],\n",
       "                        [-2.6357e-02, -1.3164e-01, -2.5004e-01]],\n",
       "              \n",
       "                       [[ 1.5716e-01, -6.5916e-01, -3.7163e-01],\n",
       "                        [-1.4906e-01, -3.3604e-01, -9.9113e-02],\n",
       "                        [ 1.2724e-01,  1.5649e-01, -6.1665e-02]],\n",
       "              \n",
       "                       [[-2.0052e-02,  1.7148e-01, -3.4569e-01],\n",
       "                        [ 4.4725e-01, -1.2255e-02,  4.0592e-01],\n",
       "                        [-1.6992e-01, -1.4607e-01, -3.2384e-01]],\n",
       "              \n",
       "                       [[-1.7028e-02, -8.5108e-02, -2.3798e-01],\n",
       "                        [ 2.8127e-01,  1.8218e-02,  2.9830e-01],\n",
       "                        [-1.0245e-01, -3.9497e-02,  2.7497e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8271e-02, -7.2140e-01,  3.2392e-02],\n",
       "                        [ 2.9607e-01, -1.0893e-01, -3.0054e-01],\n",
       "                        [-2.4524e-01, -3.4102e-01,  6.4828e-02]],\n",
       "              \n",
       "                       [[-1.5833e-01,  2.8716e-01, -2.8541e-01],\n",
       "                        [-8.1920e-02,  5.3344e-01, -8.9772e-02],\n",
       "                        [-2.3166e-01,  2.8033e-01, -2.1412e-01]],\n",
       "              \n",
       "                       [[-9.1274e-02,  5.6942e-02, -1.8451e-01],\n",
       "                        [-1.0216e-01,  7.0682e-02,  5.3959e-02],\n",
       "                        [ 3.2387e-01, -2.0344e-01, -4.7135e-02]],\n",
       "              \n",
       "                       [[ 1.5830e-02,  4.4492e-02,  1.4217e-01],\n",
       "                        [-1.3069e-02, -1.6149e-01, -1.3701e-02],\n",
       "                        [-1.9981e-01,  2.9199e-01,  3.8395e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2955e-01, -1.0186e-01,  7.6801e-02],\n",
       "                        [-8.6575e-02, -8.0612e-03, -1.5902e-01],\n",
       "                        [-2.8949e-04, -2.3332e-01,  2.2612e-01]],\n",
       "              \n",
       "                       [[ 3.0940e-02, -2.1828e-01,  4.1376e-01],\n",
       "                        [ 1.4290e-02, -3.3372e-02,  1.5831e-01],\n",
       "                        [ 2.5643e-02, -9.1558e-02,  3.4163e-01]],\n",
       "              \n",
       "                       [[ 8.4127e-02,  3.7897e-02, -1.5717e-01],\n",
       "                        [ 6.7579e-02,  3.5411e-01,  3.2907e-02],\n",
       "                        [-6.1220e-02,  4.9653e-01,  1.0497e-01]],\n",
       "              \n",
       "                       [[ 1.0379e-01, -2.9524e-01,  2.6511e-02],\n",
       "                        [-3.9713e-02, -5.0619e-01, -3.7104e-02],\n",
       "                        [-4.2020e-01,  5.8012e-01,  6.2754e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.3067e-01, -1.3824e-02, -2.5355e-01],\n",
       "                        [ 3.1014e-01,  1.0804e-02,  1.3980e-01],\n",
       "                        [-1.2415e-01,  4.2892e-02,  1.1416e-01]],\n",
       "              \n",
       "                       [[-2.8074e-01,  7.6132e-02,  3.3707e-01],\n",
       "                        [ 4.0284e-02, -2.8315e-01,  6.4632e-02],\n",
       "                        [ 1.1876e-01, -1.0156e-01, -7.2963e-02]],\n",
       "              \n",
       "                       [[ 3.2671e-01, -1.1268e-01,  2.0574e-02],\n",
       "                        [ 1.2063e-01,  2.8370e-02, -2.6460e-01],\n",
       "                        [-5.2230e-02,  3.3347e-02, -1.6008e-01]],\n",
       "              \n",
       "                       [[ 3.0438e-01, -2.1996e-01, -3.7970e-01],\n",
       "                        [-4.8888e-01, -1.0636e-01,  2.4557e-01],\n",
       "                        [ 4.3349e-02,  1.3737e-02,  5.5982e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5865e-01, -1.3829e-01, -3.8599e-02],\n",
       "                        [ 2.3240e-01, -2.6784e-01, -2.6056e-01],\n",
       "                        [ 3.3347e-01,  1.6459e-01, -9.9123e-02]],\n",
       "              \n",
       "                       [[-1.3240e-02, -2.4913e-01,  4.1011e-01],\n",
       "                        [-3.2280e-01,  4.6701e-01, -4.4934e-02],\n",
       "                        [-5.1787e-01, -2.1056e-01,  1.4919e-01]],\n",
       "              \n",
       "                       [[ 1.6178e-01, -9.8057e-02,  6.0526e-02],\n",
       "                        [-1.1812e-01,  1.3447e-01,  2.1761e-01],\n",
       "                        [-4.6781e-01, -6.2003e-02, -1.7766e-01]],\n",
       "              \n",
       "                       [[-1.6266e-01,  2.7354e-03, -2.3151e-01],\n",
       "                        [ 2.1946e-01, -4.2909e-01, -6.8603e-02],\n",
       "                        [ 4.2664e-01, -1.6004e-01, -6.8614e-02]]]])),\n",
       "             ('pi_features_extractor.cnn.0.bias',\n",
       "              tensor([-0.0566, -0.0666,  0.0050,  0.0101, -0.0325, -0.1201, -0.0267, -0.0672,\n",
       "                      -0.0574, -0.0115,  0.0515, -0.0224, -0.0393, -0.0064, -0.0498,  0.0367,\n",
       "                       0.0978,  0.1039,  0.0021, -0.0343, -0.0318, -0.0280,  0.0324, -0.0059,\n",
       "                       0.0608,  0.0087, -0.0349,  0.0326,  0.0145, -0.0126, -0.0186,  0.0100])),\n",
       "             ('pi_features_extractor.cnn.2.weight',\n",
       "              tensor([[[[ 0.0337,  0.0183,  0.1811],\n",
       "                        [-0.0092,  0.0704,  0.0781],\n",
       "                        [ 0.0079,  0.0235,  0.2508]],\n",
       "              \n",
       "                       [[-0.0559, -0.0903, -0.1553],\n",
       "                        [ 0.0236,  0.0402,  0.0951],\n",
       "                        [ 0.1265, -0.1126, -0.1120]],\n",
       "              \n",
       "                       [[-0.0063, -0.0839,  0.0146],\n",
       "                        [ 0.0568,  0.0494,  0.0495],\n",
       "                        [-0.1111, -0.1969, -0.1347]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1430,  0.0147, -0.0547],\n",
       "                        [ 0.0025, -0.1023,  0.1860],\n",
       "                        [ 0.0145, -0.0365, -0.0542]],\n",
       "              \n",
       "                       [[-0.0599, -0.0654, -0.0008],\n",
       "                        [ 0.0207,  0.1879,  0.0056],\n",
       "                        [-0.0875, -0.0323,  0.0365]],\n",
       "              \n",
       "                       [[ 0.2021,  0.0356,  0.0555],\n",
       "                        [ 0.1441, -0.0895,  0.0371],\n",
       "                        [-0.1306, -0.1064, -0.0320]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0295,  0.1417,  0.0898],\n",
       "                        [-0.0841, -0.0365,  0.0656],\n",
       "                        [-0.1357,  0.1170,  0.1063]],\n",
       "              \n",
       "                       [[ 0.1105, -0.0365,  0.0223],\n",
       "                        [-0.0618,  0.0518, -0.0784],\n",
       "                        [ 0.1527,  0.1740, -0.0630]],\n",
       "              \n",
       "                       [[ 0.1227, -0.1392, -0.0040],\n",
       "                        [ 0.0392, -0.0950,  0.1206],\n",
       "                        [-0.0319,  0.0154,  0.0485]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1858,  0.0093, -0.0078],\n",
       "                        [ 0.0195, -0.0297, -0.1388],\n",
       "                        [-0.0933, -0.0209,  0.0919]],\n",
       "              \n",
       "                       [[ 0.0456, -0.0209, -0.0961],\n",
       "                        [ 0.0440, -0.0379, -0.0509],\n",
       "                        [ 0.0703, -0.0644,  0.0500]],\n",
       "              \n",
       "                       [[ 0.1575,  0.1472, -0.1588],\n",
       "                        [ 0.0704, -0.0619,  0.0216],\n",
       "                        [-0.0397,  0.0828,  0.0385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0037,  0.0176, -0.2178],\n",
       "                        [-0.0295, -0.1379,  0.0542],\n",
       "                        [ 0.0287,  0.0869, -0.0711]],\n",
       "              \n",
       "                       [[ 0.0246,  0.0180, -0.0136],\n",
       "                        [ 0.0585, -0.0908,  0.0373],\n",
       "                        [-0.1708,  0.0041, -0.1778]],\n",
       "              \n",
       "                       [[ 0.0947,  0.0598,  0.0550],\n",
       "                        [-0.0396,  0.1413, -0.1427],\n",
       "                        [-0.1346, -0.0290, -0.0006]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0819, -0.0565, -0.0107],\n",
       "                        [ 0.0251,  0.0080, -0.1340],\n",
       "                        [-0.0806, -0.0358,  0.0328]],\n",
       "              \n",
       "                       [[-0.0176, -0.0219,  0.0098],\n",
       "                        [ 0.0743,  0.0146, -0.0068],\n",
       "                        [ 0.0307, -0.0660, -0.1691]],\n",
       "              \n",
       "                       [[-0.0751,  0.0300, -0.0542],\n",
       "                        [-0.1141,  0.0117, -0.0460],\n",
       "                        [ 0.1561,  0.0939,  0.1133]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0220, -0.0986,  0.0897],\n",
       "                        [ 0.0680, -0.1171,  0.0113],\n",
       "                        [-0.0018,  0.0855,  0.0803]],\n",
       "              \n",
       "                       [[ 0.0904,  0.0183, -0.1006],\n",
       "                        [-0.1004, -0.0417, -0.1845],\n",
       "                        [-0.1535,  0.0890, -0.0894]],\n",
       "              \n",
       "                       [[ 0.1373,  0.0621, -0.0894],\n",
       "                        [ 0.2271,  0.1095, -0.0319],\n",
       "                        [ 0.0152, -0.0245,  0.1569]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0120, -0.0119,  0.0167],\n",
       "                        [-0.0655,  0.0904,  0.0507],\n",
       "                        [-0.0890,  0.2800, -0.0387]],\n",
       "              \n",
       "                       [[-0.0526, -0.1061,  0.1017],\n",
       "                        [ 0.0505,  0.0431, -0.0106],\n",
       "                        [ 0.1109, -0.1559,  0.0986]],\n",
       "              \n",
       "                       [[ 0.1002,  0.1639,  0.0977],\n",
       "                        [-0.0913, -0.0571,  0.0487],\n",
       "                        [-0.1078,  0.1614, -0.0788]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1416,  0.0937,  0.0798],\n",
       "                        [ 0.0718,  0.0977, -0.0887],\n",
       "                        [-0.0445,  0.0350, -0.0309]],\n",
       "              \n",
       "                       [[ 0.1969, -0.0258, -0.0243],\n",
       "                        [ 0.2591,  0.0262,  0.0080],\n",
       "                        [-0.0006,  0.0793, -0.2098]],\n",
       "              \n",
       "                       [[ 0.0529, -0.0417,  0.0800],\n",
       "                        [-0.0687, -0.0148,  0.2967],\n",
       "                        [-0.1469, -0.2498, -0.0229]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1094,  0.0152, -0.0539],\n",
       "                        [-0.0680, -0.0788,  0.0701],\n",
       "                        [ 0.0526, -0.1560, -0.2047]],\n",
       "              \n",
       "                       [[ 0.0327, -0.0424, -0.0037],\n",
       "                        [-0.0473, -0.0575,  0.1007],\n",
       "                        [ 0.0497, -0.1394, -0.0099]],\n",
       "              \n",
       "                       [[-0.0807, -0.1619, -0.0035],\n",
       "                        [ 0.0386, -0.0241,  0.0321],\n",
       "                        [-0.1117,  0.0962, -0.1791]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0174, -0.0043, -0.0614],\n",
       "                        [-0.0582,  0.0048, -0.1357],\n",
       "                        [ 0.0407, -0.0188, -0.1285]],\n",
       "              \n",
       "                       [[ 0.1117, -0.0041, -0.1399],\n",
       "                        [ 0.0533, -0.1416, -0.1361],\n",
       "                        [-0.0427,  0.0032, -0.0008]],\n",
       "              \n",
       "                       [[ 0.0627,  0.0510,  0.0315],\n",
       "                        [ 0.1574,  0.1953, -0.1351],\n",
       "                        [ 0.0472, -0.0914,  0.0192]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2125, -0.0262, -0.0840],\n",
       "                        [-0.0027, -0.0503,  0.0810],\n",
       "                        [ 0.0658, -0.0355, -0.0023]],\n",
       "              \n",
       "                       [[-0.0149,  0.0386, -0.0299],\n",
       "                        [-0.0956, -0.1379, -0.0337],\n",
       "                        [ 0.0054,  0.1598, -0.0692]],\n",
       "              \n",
       "                       [[ 0.0698, -0.1232, -0.0237],\n",
       "                        [ 0.0924, -0.0492,  0.0697],\n",
       "                        [-0.0753, -0.0362,  0.0646]]]])),\n",
       "             ('pi_features_extractor.cnn.2.bias',\n",
       "              tensor([-0.0390, -0.0034, -0.0113, -0.0361,  0.0085,  0.0049, -0.0228,  0.0194,\n",
       "                      -0.0314, -0.0193, -0.0153, -0.0270, -0.0255,  0.0063, -0.0083,  0.0100,\n",
       "                       0.0165, -0.0047, -0.0294, -0.0083,  0.0202, -0.0153,  0.0065, -0.0314,\n",
       "                       0.0038,  0.0038, -0.0122, -0.0127, -0.0490,  0.0145, -0.0177,  0.0108,\n",
       "                       0.0031, -0.0147, -0.0546, -0.0104,  0.0075, -0.0224, -0.0226, -0.0075,\n",
       "                      -0.0132, -0.0033, -0.0336, -0.0368,  0.0054, -0.0007, -0.0043, -0.0222,\n",
       "                      -0.0103, -0.0611, -0.0028, -0.0120, -0.0236, -0.0233, -0.0365,  0.0186,\n",
       "                      -0.0335,  0.0064, -0.0251, -0.0194, -0.0224, -0.0334, -0.0377, -0.0148])),\n",
       "             ('pi_features_extractor.cnn.4.weight',\n",
       "              tensor([[[[-0.1014,  0.0709,  0.1082],\n",
       "                        [-0.0704,  0.0229, -0.0548],\n",
       "                        [ 0.0604,  0.0755, -0.1099]],\n",
       "              \n",
       "                       [[ 0.0352, -0.2052, -0.0431],\n",
       "                        [ 0.0014, -0.1739, -0.0260],\n",
       "                        [-0.0592,  0.1083,  0.0191]],\n",
       "              \n",
       "                       [[-0.1012,  0.0074,  0.1031],\n",
       "                        [-0.0348, -0.0550, -0.0482],\n",
       "                        [ 0.0439,  0.0012, -0.0179]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0070,  0.0207,  0.0602],\n",
       "                        [ 0.0391, -0.0656,  0.0200],\n",
       "                        [ 0.0378,  0.0211, -0.1084]],\n",
       "              \n",
       "                       [[-0.0429,  0.0146, -0.0985],\n",
       "                        [ 0.0302, -0.0878,  0.1199],\n",
       "                        [-0.1365,  0.1271, -0.0090]],\n",
       "              \n",
       "                       [[-0.1360,  0.1147, -0.0451],\n",
       "                        [-0.0211,  0.0499,  0.0696],\n",
       "                        [ 0.0633, -0.1438,  0.0214]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0525, -0.1044, -0.0197],\n",
       "                        [ 0.0397, -0.0160, -0.0297],\n",
       "                        [-0.0340,  0.0754,  0.0151]],\n",
       "              \n",
       "                       [[-0.0837,  0.0467,  0.0243],\n",
       "                        [ 0.0600,  0.0197, -0.0111],\n",
       "                        [-0.0211,  0.0185,  0.0020]],\n",
       "              \n",
       "                       [[ 0.0702,  0.0136,  0.0851],\n",
       "                        [-0.0559, -0.0383,  0.0509],\n",
       "                        [ 0.0301,  0.0863, -0.0579]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0008,  0.1314, -0.0715],\n",
       "                        [-0.0519, -0.0206,  0.0187],\n",
       "                        [-0.0610, -0.1474,  0.0442]],\n",
       "              \n",
       "                       [[-0.0570, -0.0038, -0.0652],\n",
       "                        [-0.1259,  0.0309, -0.1133],\n",
       "                        [ 0.0531,  0.0175, -0.0488]],\n",
       "              \n",
       "                       [[-0.0420, -0.1407,  0.0187],\n",
       "                        [ 0.0362,  0.0119,  0.1130],\n",
       "                        [ 0.1020, -0.0303,  0.0771]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0843,  0.0506, -0.0102],\n",
       "                        [-0.0309,  0.0596,  0.1865],\n",
       "                        [ 0.0695, -0.1693, -0.1030]],\n",
       "              \n",
       "                       [[ 0.0419,  0.0717,  0.1250],\n",
       "                        [-0.0795,  0.0079,  0.1064],\n",
       "                        [-0.0167, -0.0967, -0.1259]],\n",
       "              \n",
       "                       [[ 0.0243,  0.0092,  0.0335],\n",
       "                        [ 0.0913, -0.0200,  0.1210],\n",
       "                        [ 0.0838, -0.0482,  0.0845]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0013, -0.0548, -0.1030],\n",
       "                        [ 0.1146,  0.1135, -0.0269],\n",
       "                        [ 0.0268,  0.0550, -0.0531]],\n",
       "              \n",
       "                       [[ 0.0765, -0.0841,  0.0607],\n",
       "                        [ 0.0406,  0.0043, -0.0290],\n",
       "                        [-0.0238,  0.0344, -0.0343]],\n",
       "              \n",
       "                       [[-0.0306, -0.0158,  0.0538],\n",
       "                        [-0.0041,  0.0514,  0.0606],\n",
       "                        [ 0.0687, -0.0608,  0.0098]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0852, -0.0107, -0.0530],\n",
       "                        [ 0.0538, -0.0349, -0.0862],\n",
       "                        [ 0.0586,  0.0060, -0.1364]],\n",
       "              \n",
       "                       [[ 0.0105, -0.0361, -0.0264],\n",
       "                        [ 0.1033, -0.0619, -0.0171],\n",
       "                        [-0.0026,  0.0930, -0.0463]],\n",
       "              \n",
       "                       [[-0.0930, -0.0707,  0.0251],\n",
       "                        [ 0.0259, -0.0004,  0.2019],\n",
       "                        [-0.0139, -0.0725, -0.1661]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0039,  0.0044,  0.0718],\n",
       "                        [ 0.1228, -0.0095,  0.0568],\n",
       "                        [-0.0977, -0.0113,  0.0441]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0876,  0.0224],\n",
       "                        [ 0.0183, -0.0459, -0.0793],\n",
       "                        [-0.0716, -0.0030, -0.0981]],\n",
       "              \n",
       "                       [[-0.0205,  0.0779, -0.1334],\n",
       "                        [-0.1343,  0.0562,  0.0465],\n",
       "                        [ 0.0765, -0.0930, -0.0822]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0020, -0.1609, -0.0816],\n",
       "                        [-0.0171, -0.0815, -0.0878],\n",
       "                        [-0.0384,  0.0751,  0.0293]],\n",
       "              \n",
       "                       [[ 0.0061, -0.0220, -0.0833],\n",
       "                        [ 0.0124, -0.0083,  0.0255],\n",
       "                        [ 0.0746, -0.0895,  0.0211]],\n",
       "              \n",
       "                       [[-0.1771, -0.1180,  0.0226],\n",
       "                        [ 0.0984, -0.0210, -0.0414],\n",
       "                        [ 0.1382,  0.0387,  0.0620]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0797,  0.0699,  0.0314],\n",
       "                        [-0.0514, -0.1527, -0.0059],\n",
       "                        [-0.0050, -0.0193,  0.0991]],\n",
       "              \n",
       "                       [[-0.1514,  0.0452, -0.0108],\n",
       "                        [-0.0435, -0.1535, -0.0243],\n",
       "                        [ 0.0623, -0.0156, -0.0899]],\n",
       "              \n",
       "                       [[ 0.0136,  0.0049,  0.1030],\n",
       "                        [-0.0593, -0.0197, -0.0076],\n",
       "                        [-0.0189, -0.0357, -0.0282]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0250, -0.0896,  0.1386],\n",
       "                        [-0.0635, -0.0235,  0.0971],\n",
       "                        [-0.0404,  0.0862, -0.0077]],\n",
       "              \n",
       "                       [[-0.0196,  0.0070, -0.0055],\n",
       "                        [-0.0389, -0.1478, -0.0312],\n",
       "                        [ 0.0856,  0.0393, -0.0485]],\n",
       "              \n",
       "                       [[-0.0351,  0.0242, -0.0526],\n",
       "                        [-0.0668, -0.0827,  0.0873],\n",
       "                        [ 0.0886, -0.0227, -0.1589]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1103, -0.0872,  0.0069],\n",
       "                        [-0.0348,  0.0992,  0.0197],\n",
       "                        [-0.0116,  0.0288,  0.0328]],\n",
       "              \n",
       "                       [[-0.0918,  0.0735,  0.0194],\n",
       "                        [-0.1080,  0.0114, -0.0639],\n",
       "                        [-0.0689,  0.0118,  0.0921]],\n",
       "              \n",
       "                       [[ 0.0896, -0.0524,  0.0459],\n",
       "                        [-0.0676, -0.0987,  0.0727],\n",
       "                        [ 0.0799, -0.2089,  0.0608]]]])),\n",
       "             ('pi_features_extractor.cnn.4.bias',\n",
       "              tensor([-0.0527, -0.0421, -0.0194, -0.0534, -0.0266, -0.0121, -0.0038, -0.0021,\n",
       "                      -0.0285, -0.0684, -0.0531, -0.0151, -0.0482, -0.0270, -0.0442, -0.0434,\n",
       "                      -0.0313, -0.0371, -0.0373, -0.0229, -0.0440, -0.0215, -0.0519, -0.0588,\n",
       "                      -0.0308, -0.0252, -0.0491, -0.0177, -0.0092, -0.0191, -0.0484, -0.0235,\n",
       "                      -0.0379, -0.0287, -0.0316, -0.0126, -0.0297, -0.0215, -0.0215, -0.0448,\n",
       "                      -0.0187, -0.0510, -0.0096, -0.0514, -0.0251, -0.0464, -0.0250, -0.0309,\n",
       "                      -0.0291, -0.0448, -0.0306, -0.0332, -0.0095, -0.0130, -0.0548, -0.0416,\n",
       "                      -0.0410, -0.0265, -0.0136, -0.0418,  0.0009, -0.0626, -0.0153, -0.0527])),\n",
       "             ('pi_features_extractor.linear.0.weight',\n",
       "              tensor([[-0.0270, -0.0135, -0.0357,  ..., -0.0760, -0.0304,  0.0015],\n",
       "                      [-0.0007, -0.0621,  0.0162,  ..., -0.0310,  0.0050, -0.0013],\n",
       "                      [-0.0178,  0.0220,  0.0382,  ...,  0.0995, -0.0172,  0.0078],\n",
       "                      ...,\n",
       "                      [-0.0200, -0.0426, -0.1067,  ..., -0.0226, -0.0147, -0.0272],\n",
       "                      [-0.0199,  0.1090, -0.0471,  ...,  0.0651,  0.0328, -0.0295],\n",
       "                      [ 0.0558, -0.0437,  0.0408,  ...,  0.0242,  0.0245,  0.0446]])),\n",
       "             ('pi_features_extractor.linear.0.bias',\n",
       "              tensor([-5.6608e-03,  6.0292e-03, -9.1965e-03, -1.8568e-02, -1.1593e-02,\n",
       "                       9.6789e-03, -1.5750e-02, -2.1523e-02, -1.4694e-02,  1.8843e-03,\n",
       "                      -1.0284e-02, -1.3603e-02, -1.9655e-02,  2.5110e-03, -2.3079e-02,\n",
       "                      -2.5503e-03,  2.5569e-02, -1.5688e-02, -2.0103e-02,  5.9138e-03,\n",
       "                      -2.3874e-03,  1.0382e-02, -1.2352e-03, -6.3961e-03, -3.2044e-03,\n",
       "                       2.0733e-02, -7.9140e-03,  2.1906e-03, -3.3774e-04, -1.2366e-02,\n",
       "                      -8.4314e-03,  6.4223e-03, -1.3893e-02, -1.9243e-02, -9.8721e-03,\n",
       "                      -1.3911e-02, -1.6314e-02,  3.9481e-03,  6.8481e-03, -7.2767e-04,\n",
       "                      -3.5789e-03,  1.7647e-02,  5.1980e-03, -1.5433e-02,  2.0342e-03,\n",
       "                      -3.8536e-03,  4.9479e-03,  1.1522e-02,  3.1461e-03, -2.1221e-02,\n",
       "                      -1.8123e-02,  2.9962e-03, -2.4504e-02, -1.3904e-02, -1.9924e-02,\n",
       "                      -6.5181e-03, -1.1136e-02, -8.0146e-03,  1.1183e-03,  5.8428e-03,\n",
       "                      -6.7766e-03, -1.8218e-02,  2.0625e-02, -4.1976e-03,  9.8920e-03,\n",
       "                       2.7103e-03,  5.1831e-03, -1.0430e-02,  4.0037e-05, -2.4779e-02,\n",
       "                      -2.1182e-02, -4.8570e-04, -1.4988e-02,  4.2176e-04,  1.6978e-02,\n",
       "                      -1.7201e-02, -9.6121e-03, -1.7206e-02, -3.7706e-03, -8.1554e-03,\n",
       "                      -8.9120e-03, -4.4588e-03, -2.7373e-02,  2.3373e-03, -4.0309e-03,\n",
       "                       5.0599e-03, -3.3017e-02, -1.5682e-02, -3.8791e-03, -1.3667e-02,\n",
       "                      -1.1874e-02, -1.3697e-02, -4.7328e-03, -8.9924e-03, -1.7318e-02,\n",
       "                      -7.3571e-03, -5.0703e-03,  1.3889e-02, -1.2070e-02, -1.8983e-02,\n",
       "                      -3.0111e-03, -7.7595e-03,  1.6896e-02, -1.3754e-02,  6.6683e-03,\n",
       "                      -4.5552e-03, -3.7477e-04, -1.2147e-02, -3.4943e-03, -1.3093e-02,\n",
       "                       5.1952e-03,  1.8795e-02,  3.8898e-03, -2.4092e-02,  2.5640e-05,\n",
       "                      -1.4565e-02, -1.4779e-02, -1.6007e-02, -4.0413e-03, -2.6391e-02,\n",
       "                      -9.2754e-03, -6.6702e-03, -1.9132e-02, -1.9438e-02, -1.8338e-02,\n",
       "                      -3.7500e-03,  7.5928e-03, -1.0519e-02, -1.1963e-03,  5.0987e-03,\n",
       "                      -5.1751e-03, -1.9795e-03, -1.2211e-02, -1.1549e-02, -1.8722e-02,\n",
       "                      -5.7123e-03, -3.2459e-02, -7.2956e-03, -2.8802e-02,  3.6083e-03,\n",
       "                       4.6870e-05, -7.6378e-03, -8.7449e-03, -1.4517e-03, -4.2058e-03,\n",
       "                      -1.1429e-02, -1.9129e-02, -8.3722e-03, -1.4606e-02,  1.8631e-03,\n",
       "                      -1.6571e-02,  6.3678e-03, -2.3493e-02, -1.0677e-02, -9.0645e-03,\n",
       "                      -1.2493e-02, -1.7621e-02,  7.2907e-04, -1.5983e-02,  1.2657e-02,\n",
       "                      -1.4844e-02, -3.4709e-02,  3.4632e-03,  5.9516e-03, -1.3603e-02,\n",
       "                      -7.0841e-04, -1.5203e-02, -5.4989e-03, -6.8727e-03, -6.8712e-03,\n",
       "                      -6.7857e-03, -1.2739e-02, -9.4579e-04, -5.7958e-03, -2.0469e-02,\n",
       "                      -4.8724e-03, -1.1285e-02, -1.0248e-02,  1.5599e-02, -1.2677e-02,\n",
       "                      -1.2914e-02,  7.9928e-03, -1.6114e-02, -1.2004e-02, -9.0505e-03,\n",
       "                      -1.7559e-02,  1.1923e-02,  7.7604e-03, -4.7151e-04, -8.8959e-03,\n",
       "                       6.0266e-04, -1.1305e-02, -1.7632e-02, -9.8618e-04, -3.2808e-04,\n",
       "                      -9.2304e-03, -5.8386e-03, -1.2238e-02, -1.0198e-02, -1.9077e-03,\n",
       "                      -1.6158e-02, -1.6521e-02,  4.7318e-03,  1.0410e-02, -2.2033e-02,\n",
       "                       1.1737e-03, -1.2583e-02, -1.3367e-02,  1.6993e-03, -1.0574e-02,\n",
       "                      -3.0460e-03, -8.5488e-03, -1.0641e-02, -2.5659e-02, -1.0535e-02,\n",
       "                      -1.0917e-02, -1.0462e-02, -4.1459e-03, -1.4119e-02, -1.1132e-02,\n",
       "                      -1.0320e-02, -1.4184e-02, -1.0302e-02, -8.1392e-04, -2.7057e-03,\n",
       "                      -4.2100e-03,  1.9071e-02, -1.4972e-02,  3.7827e-03, -8.7062e-03,\n",
       "                       6.6713e-03, -9.7732e-03,  7.0135e-03,  6.3468e-03, -8.1618e-03,\n",
       "                       1.1720e-02, -1.4238e-02, -1.1268e-02,  1.4706e-02,  4.6204e-03,\n",
       "                      -9.1095e-04,  2.2036e-02, -1.6451e-02, -1.4447e-02, -1.8699e-02,\n",
       "                       9.3533e-03, -5.2393e-03,  1.2488e-02, -7.6009e-03, -9.2387e-04,\n",
       "                      -1.9480e-03, -1.4901e-02, -1.6314e-02,  5.9689e-03, -5.6877e-03,\n",
       "                       9.1546e-03])),\n",
       "             ('vf_features_extractor.cnn.0.weight',\n",
       "              tensor([[[[ 5.8862e-02,  3.7363e-01, -1.3097e-01],\n",
       "                        [-1.3117e-01, -1.4281e-01,  1.0642e-02],\n",
       "                        [-3.2974e-01,  5.1945e-02, -1.7016e-01]],\n",
       "              \n",
       "                       [[-1.6550e-01,  2.2424e-01,  6.2481e-01],\n",
       "                        [ 1.1638e-01,  6.0274e-02,  2.3141e-01],\n",
       "                        [-1.1957e-01, -3.1702e-01,  2.2510e-01]],\n",
       "              \n",
       "                       [[-1.1080e-01,  3.4992e-01, -2.3739e-01],\n",
       "                        [-8.8834e-02,  2.8504e-01,  1.4751e-01],\n",
       "                        [ 1.0280e-01, -2.0961e-01, -1.3982e-01]],\n",
       "              \n",
       "                       [[-3.6928e-01,  2.0983e-01, -2.5590e-01],\n",
       "                        [ 1.8024e-02,  4.0449e-01, -2.9480e-01],\n",
       "                        [-1.0230e-01, -4.0876e-02,  4.6758e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3953e-02, -1.4663e-01,  3.7173e-01],\n",
       "                        [ 2.7627e-01,  1.3760e-01,  1.6290e-01],\n",
       "                        [-2.6357e-02, -1.3164e-01, -2.5004e-01]],\n",
       "              \n",
       "                       [[ 1.5716e-01, -6.5916e-01, -3.7163e-01],\n",
       "                        [-1.4906e-01, -3.3604e-01, -9.9113e-02],\n",
       "                        [ 1.2724e-01,  1.5649e-01, -6.1665e-02]],\n",
       "              \n",
       "                       [[-2.0052e-02,  1.7148e-01, -3.4569e-01],\n",
       "                        [ 4.4725e-01, -1.2255e-02,  4.0592e-01],\n",
       "                        [-1.6992e-01, -1.4607e-01, -3.2384e-01]],\n",
       "              \n",
       "                       [[-1.7028e-02, -8.5108e-02, -2.3798e-01],\n",
       "                        [ 2.8127e-01,  1.8218e-02,  2.9830e-01],\n",
       "                        [-1.0245e-01, -3.9497e-02,  2.7497e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8271e-02, -7.2140e-01,  3.2392e-02],\n",
       "                        [ 2.9607e-01, -1.0893e-01, -3.0054e-01],\n",
       "                        [-2.4524e-01, -3.4102e-01,  6.4828e-02]],\n",
       "              \n",
       "                       [[-1.5833e-01,  2.8716e-01, -2.8541e-01],\n",
       "                        [-8.1920e-02,  5.3344e-01, -8.9772e-02],\n",
       "                        [-2.3166e-01,  2.8033e-01, -2.1412e-01]],\n",
       "              \n",
       "                       [[-9.1274e-02,  5.6942e-02, -1.8451e-01],\n",
       "                        [-1.0216e-01,  7.0682e-02,  5.3959e-02],\n",
       "                        [ 3.2387e-01, -2.0344e-01, -4.7135e-02]],\n",
       "              \n",
       "                       [[ 1.5830e-02,  4.4492e-02,  1.4217e-01],\n",
       "                        [-1.3069e-02, -1.6149e-01, -1.3701e-02],\n",
       "                        [-1.9981e-01,  2.9199e-01,  3.8395e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2955e-01, -1.0186e-01,  7.6801e-02],\n",
       "                        [-8.6575e-02, -8.0612e-03, -1.5902e-01],\n",
       "                        [-2.8949e-04, -2.3332e-01,  2.2612e-01]],\n",
       "              \n",
       "                       [[ 3.0940e-02, -2.1828e-01,  4.1376e-01],\n",
       "                        [ 1.4290e-02, -3.3372e-02,  1.5831e-01],\n",
       "                        [ 2.5643e-02, -9.1558e-02,  3.4163e-01]],\n",
       "              \n",
       "                       [[ 8.4127e-02,  3.7897e-02, -1.5717e-01],\n",
       "                        [ 6.7579e-02,  3.5411e-01,  3.2907e-02],\n",
       "                        [-6.1220e-02,  4.9653e-01,  1.0497e-01]],\n",
       "              \n",
       "                       [[ 1.0379e-01, -2.9524e-01,  2.6511e-02],\n",
       "                        [-3.9713e-02, -5.0619e-01, -3.7104e-02],\n",
       "                        [-4.2020e-01,  5.8012e-01,  6.2754e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.3067e-01, -1.3824e-02, -2.5355e-01],\n",
       "                        [ 3.1014e-01,  1.0804e-02,  1.3980e-01],\n",
       "                        [-1.2415e-01,  4.2892e-02,  1.1416e-01]],\n",
       "              \n",
       "                       [[-2.8074e-01,  7.6132e-02,  3.3707e-01],\n",
       "                        [ 4.0284e-02, -2.8315e-01,  6.4632e-02],\n",
       "                        [ 1.1876e-01, -1.0156e-01, -7.2963e-02]],\n",
       "              \n",
       "                       [[ 3.2671e-01, -1.1268e-01,  2.0574e-02],\n",
       "                        [ 1.2063e-01,  2.8370e-02, -2.6460e-01],\n",
       "                        [-5.2230e-02,  3.3347e-02, -1.6008e-01]],\n",
       "              \n",
       "                       [[ 3.0438e-01, -2.1996e-01, -3.7970e-01],\n",
       "                        [-4.8888e-01, -1.0636e-01,  2.4557e-01],\n",
       "                        [ 4.3349e-02,  1.3737e-02,  5.5982e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5865e-01, -1.3829e-01, -3.8599e-02],\n",
       "                        [ 2.3240e-01, -2.6784e-01, -2.6056e-01],\n",
       "                        [ 3.3347e-01,  1.6459e-01, -9.9123e-02]],\n",
       "              \n",
       "                       [[-1.3240e-02, -2.4913e-01,  4.1011e-01],\n",
       "                        [-3.2280e-01,  4.6701e-01, -4.4934e-02],\n",
       "                        [-5.1787e-01, -2.1056e-01,  1.4919e-01]],\n",
       "              \n",
       "                       [[ 1.6178e-01, -9.8057e-02,  6.0526e-02],\n",
       "                        [-1.1812e-01,  1.3447e-01,  2.1761e-01],\n",
       "                        [-4.6781e-01, -6.2003e-02, -1.7766e-01]],\n",
       "              \n",
       "                       [[-1.6266e-01,  2.7354e-03, -2.3151e-01],\n",
       "                        [ 2.1946e-01, -4.2909e-01, -6.8603e-02],\n",
       "                        [ 4.2664e-01, -1.6004e-01, -6.8614e-02]]]])),\n",
       "             ('vf_features_extractor.cnn.0.bias',\n",
       "              tensor([-0.0566, -0.0666,  0.0050,  0.0101, -0.0325, -0.1201, -0.0267, -0.0672,\n",
       "                      -0.0574, -0.0115,  0.0515, -0.0224, -0.0393, -0.0064, -0.0498,  0.0367,\n",
       "                       0.0978,  0.1039,  0.0021, -0.0343, -0.0318, -0.0280,  0.0324, -0.0059,\n",
       "                       0.0608,  0.0087, -0.0349,  0.0326,  0.0145, -0.0126, -0.0186,  0.0100])),\n",
       "             ('vf_features_extractor.cnn.2.weight',\n",
       "              tensor([[[[ 0.0337,  0.0183,  0.1811],\n",
       "                        [-0.0092,  0.0704,  0.0781],\n",
       "                        [ 0.0079,  0.0235,  0.2508]],\n",
       "              \n",
       "                       [[-0.0559, -0.0903, -0.1553],\n",
       "                        [ 0.0236,  0.0402,  0.0951],\n",
       "                        [ 0.1265, -0.1126, -0.1120]],\n",
       "              \n",
       "                       [[-0.0063, -0.0839,  0.0146],\n",
       "                        [ 0.0568,  0.0494,  0.0495],\n",
       "                        [-0.1111, -0.1969, -0.1347]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1430,  0.0147, -0.0547],\n",
       "                        [ 0.0025, -0.1023,  0.1860],\n",
       "                        [ 0.0145, -0.0365, -0.0542]],\n",
       "              \n",
       "                       [[-0.0599, -0.0654, -0.0008],\n",
       "                        [ 0.0207,  0.1879,  0.0056],\n",
       "                        [-0.0875, -0.0323,  0.0365]],\n",
       "              \n",
       "                       [[ 0.2021,  0.0356,  0.0555],\n",
       "                        [ 0.1441, -0.0895,  0.0371],\n",
       "                        [-0.1306, -0.1064, -0.0320]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0295,  0.1417,  0.0898],\n",
       "                        [-0.0841, -0.0365,  0.0656],\n",
       "                        [-0.1357,  0.1170,  0.1063]],\n",
       "              \n",
       "                       [[ 0.1105, -0.0365,  0.0223],\n",
       "                        [-0.0618,  0.0518, -0.0784],\n",
       "                        [ 0.1527,  0.1740, -0.0630]],\n",
       "              \n",
       "                       [[ 0.1227, -0.1392, -0.0040],\n",
       "                        [ 0.0392, -0.0950,  0.1206],\n",
       "                        [-0.0319,  0.0154,  0.0485]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1858,  0.0093, -0.0078],\n",
       "                        [ 0.0195, -0.0297, -0.1388],\n",
       "                        [-0.0933, -0.0209,  0.0919]],\n",
       "              \n",
       "                       [[ 0.0456, -0.0209, -0.0961],\n",
       "                        [ 0.0440, -0.0379, -0.0509],\n",
       "                        [ 0.0703, -0.0644,  0.0500]],\n",
       "              \n",
       "                       [[ 0.1575,  0.1472, -0.1588],\n",
       "                        [ 0.0704, -0.0619,  0.0216],\n",
       "                        [-0.0397,  0.0828,  0.0385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0037,  0.0176, -0.2178],\n",
       "                        [-0.0295, -0.1379,  0.0542],\n",
       "                        [ 0.0287,  0.0869, -0.0711]],\n",
       "              \n",
       "                       [[ 0.0246,  0.0180, -0.0136],\n",
       "                        [ 0.0585, -0.0908,  0.0373],\n",
       "                        [-0.1708,  0.0041, -0.1778]],\n",
       "              \n",
       "                       [[ 0.0947,  0.0598,  0.0550],\n",
       "                        [-0.0396,  0.1413, -0.1427],\n",
       "                        [-0.1346, -0.0290, -0.0006]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0819, -0.0565, -0.0107],\n",
       "                        [ 0.0251,  0.0080, -0.1340],\n",
       "                        [-0.0806, -0.0358,  0.0328]],\n",
       "              \n",
       "                       [[-0.0176, -0.0219,  0.0098],\n",
       "                        [ 0.0743,  0.0146, -0.0068],\n",
       "                        [ 0.0307, -0.0660, -0.1691]],\n",
       "              \n",
       "                       [[-0.0751,  0.0300, -0.0542],\n",
       "                        [-0.1141,  0.0117, -0.0460],\n",
       "                        [ 0.1561,  0.0939,  0.1133]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0220, -0.0986,  0.0897],\n",
       "                        [ 0.0680, -0.1171,  0.0113],\n",
       "                        [-0.0018,  0.0855,  0.0803]],\n",
       "              \n",
       "                       [[ 0.0904,  0.0183, -0.1006],\n",
       "                        [-0.1004, -0.0417, -0.1845],\n",
       "                        [-0.1535,  0.0890, -0.0894]],\n",
       "              \n",
       "                       [[ 0.1373,  0.0621, -0.0894],\n",
       "                        [ 0.2271,  0.1095, -0.0319],\n",
       "                        [ 0.0152, -0.0245,  0.1569]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0120, -0.0119,  0.0167],\n",
       "                        [-0.0655,  0.0904,  0.0507],\n",
       "                        [-0.0890,  0.2800, -0.0387]],\n",
       "              \n",
       "                       [[-0.0526, -0.1061,  0.1017],\n",
       "                        [ 0.0505,  0.0431, -0.0106],\n",
       "                        [ 0.1109, -0.1559,  0.0986]],\n",
       "              \n",
       "                       [[ 0.1002,  0.1639,  0.0977],\n",
       "                        [-0.0913, -0.0571,  0.0487],\n",
       "                        [-0.1078,  0.1614, -0.0788]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1416,  0.0937,  0.0798],\n",
       "                        [ 0.0718,  0.0977, -0.0887],\n",
       "                        [-0.0445,  0.0350, -0.0309]],\n",
       "              \n",
       "                       [[ 0.1969, -0.0258, -0.0243],\n",
       "                        [ 0.2591,  0.0262,  0.0080],\n",
       "                        [-0.0006,  0.0793, -0.2098]],\n",
       "              \n",
       "                       [[ 0.0529, -0.0417,  0.0800],\n",
       "                        [-0.0687, -0.0148,  0.2967],\n",
       "                        [-0.1469, -0.2498, -0.0229]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1094,  0.0152, -0.0539],\n",
       "                        [-0.0680, -0.0788,  0.0701],\n",
       "                        [ 0.0526, -0.1560, -0.2047]],\n",
       "              \n",
       "                       [[ 0.0327, -0.0424, -0.0037],\n",
       "                        [-0.0473, -0.0575,  0.1007],\n",
       "                        [ 0.0497, -0.1394, -0.0099]],\n",
       "              \n",
       "                       [[-0.0807, -0.1619, -0.0035],\n",
       "                        [ 0.0386, -0.0241,  0.0321],\n",
       "                        [-0.1117,  0.0962, -0.1791]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0174, -0.0043, -0.0614],\n",
       "                        [-0.0582,  0.0048, -0.1357],\n",
       "                        [ 0.0407, -0.0188, -0.1285]],\n",
       "              \n",
       "                       [[ 0.1117, -0.0041, -0.1399],\n",
       "                        [ 0.0533, -0.1416, -0.1361],\n",
       "                        [-0.0427,  0.0032, -0.0008]],\n",
       "              \n",
       "                       [[ 0.0627,  0.0510,  0.0315],\n",
       "                        [ 0.1574,  0.1953, -0.1351],\n",
       "                        [ 0.0472, -0.0914,  0.0192]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2125, -0.0262, -0.0840],\n",
       "                        [-0.0027, -0.0503,  0.0810],\n",
       "                        [ 0.0658, -0.0355, -0.0023]],\n",
       "              \n",
       "                       [[-0.0149,  0.0386, -0.0299],\n",
       "                        [-0.0956, -0.1379, -0.0337],\n",
       "                        [ 0.0054,  0.1598, -0.0692]],\n",
       "              \n",
       "                       [[ 0.0698, -0.1232, -0.0237],\n",
       "                        [ 0.0924, -0.0492,  0.0697],\n",
       "                        [-0.0753, -0.0362,  0.0646]]]])),\n",
       "             ('vf_features_extractor.cnn.2.bias',\n",
       "              tensor([-0.0390, -0.0034, -0.0113, -0.0361,  0.0085,  0.0049, -0.0228,  0.0194,\n",
       "                      -0.0314, -0.0193, -0.0153, -0.0270, -0.0255,  0.0063, -0.0083,  0.0100,\n",
       "                       0.0165, -0.0047, -0.0294, -0.0083,  0.0202, -0.0153,  0.0065, -0.0314,\n",
       "                       0.0038,  0.0038, -0.0122, -0.0127, -0.0490,  0.0145, -0.0177,  0.0108,\n",
       "                       0.0031, -0.0147, -0.0546, -0.0104,  0.0075, -0.0224, -0.0226, -0.0075,\n",
       "                      -0.0132, -0.0033, -0.0336, -0.0368,  0.0054, -0.0007, -0.0043, -0.0222,\n",
       "                      -0.0103, -0.0611, -0.0028, -0.0120, -0.0236, -0.0233, -0.0365,  0.0186,\n",
       "                      -0.0335,  0.0064, -0.0251, -0.0194, -0.0224, -0.0334, -0.0377, -0.0148])),\n",
       "             ('vf_features_extractor.cnn.4.weight',\n",
       "              tensor([[[[-0.1014,  0.0709,  0.1082],\n",
       "                        [-0.0704,  0.0229, -0.0548],\n",
       "                        [ 0.0604,  0.0755, -0.1099]],\n",
       "              \n",
       "                       [[ 0.0352, -0.2052, -0.0431],\n",
       "                        [ 0.0014, -0.1739, -0.0260],\n",
       "                        [-0.0592,  0.1083,  0.0191]],\n",
       "              \n",
       "                       [[-0.1012,  0.0074,  0.1031],\n",
       "                        [-0.0348, -0.0550, -0.0482],\n",
       "                        [ 0.0439,  0.0012, -0.0179]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0070,  0.0207,  0.0602],\n",
       "                        [ 0.0391, -0.0656,  0.0200],\n",
       "                        [ 0.0378,  0.0211, -0.1084]],\n",
       "              \n",
       "                       [[-0.0429,  0.0146, -0.0985],\n",
       "                        [ 0.0302, -0.0878,  0.1199],\n",
       "                        [-0.1365,  0.1271, -0.0090]],\n",
       "              \n",
       "                       [[-0.1360,  0.1147, -0.0451],\n",
       "                        [-0.0211,  0.0499,  0.0696],\n",
       "                        [ 0.0633, -0.1438,  0.0214]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0525, -0.1044, -0.0197],\n",
       "                        [ 0.0397, -0.0160, -0.0297],\n",
       "                        [-0.0340,  0.0754,  0.0151]],\n",
       "              \n",
       "                       [[-0.0837,  0.0467,  0.0243],\n",
       "                        [ 0.0600,  0.0197, -0.0111],\n",
       "                        [-0.0211,  0.0185,  0.0020]],\n",
       "              \n",
       "                       [[ 0.0702,  0.0136,  0.0851],\n",
       "                        [-0.0559, -0.0383,  0.0509],\n",
       "                        [ 0.0301,  0.0863, -0.0579]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0008,  0.1314, -0.0715],\n",
       "                        [-0.0519, -0.0206,  0.0187],\n",
       "                        [-0.0610, -0.1474,  0.0442]],\n",
       "              \n",
       "                       [[-0.0570, -0.0038, -0.0652],\n",
       "                        [-0.1259,  0.0309, -0.1133],\n",
       "                        [ 0.0531,  0.0175, -0.0488]],\n",
       "              \n",
       "                       [[-0.0420, -0.1407,  0.0187],\n",
       "                        [ 0.0362,  0.0119,  0.1130],\n",
       "                        [ 0.1020, -0.0303,  0.0771]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0843,  0.0506, -0.0102],\n",
       "                        [-0.0309,  0.0596,  0.1865],\n",
       "                        [ 0.0695, -0.1693, -0.1030]],\n",
       "              \n",
       "                       [[ 0.0419,  0.0717,  0.1250],\n",
       "                        [-0.0795,  0.0079,  0.1064],\n",
       "                        [-0.0167, -0.0967, -0.1259]],\n",
       "              \n",
       "                       [[ 0.0243,  0.0092,  0.0335],\n",
       "                        [ 0.0913, -0.0200,  0.1210],\n",
       "                        [ 0.0838, -0.0482,  0.0845]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0013, -0.0548, -0.1030],\n",
       "                        [ 0.1146,  0.1135, -0.0269],\n",
       "                        [ 0.0268,  0.0550, -0.0531]],\n",
       "              \n",
       "                       [[ 0.0765, -0.0841,  0.0607],\n",
       "                        [ 0.0406,  0.0043, -0.0290],\n",
       "                        [-0.0238,  0.0344, -0.0343]],\n",
       "              \n",
       "                       [[-0.0306, -0.0158,  0.0538],\n",
       "                        [-0.0041,  0.0514,  0.0606],\n",
       "                        [ 0.0687, -0.0608,  0.0098]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0852, -0.0107, -0.0530],\n",
       "                        [ 0.0538, -0.0349, -0.0862],\n",
       "                        [ 0.0586,  0.0060, -0.1364]],\n",
       "              \n",
       "                       [[ 0.0105, -0.0361, -0.0264],\n",
       "                        [ 0.1033, -0.0619, -0.0171],\n",
       "                        [-0.0026,  0.0930, -0.0463]],\n",
       "              \n",
       "                       [[-0.0930, -0.0707,  0.0251],\n",
       "                        [ 0.0259, -0.0004,  0.2019],\n",
       "                        [-0.0139, -0.0725, -0.1661]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0039,  0.0044,  0.0718],\n",
       "                        [ 0.1228, -0.0095,  0.0568],\n",
       "                        [-0.0977, -0.0113,  0.0441]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0876,  0.0224],\n",
       "                        [ 0.0183, -0.0459, -0.0793],\n",
       "                        [-0.0716, -0.0030, -0.0981]],\n",
       "              \n",
       "                       [[-0.0205,  0.0779, -0.1334],\n",
       "                        [-0.1343,  0.0562,  0.0465],\n",
       "                        [ 0.0765, -0.0930, -0.0822]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0020, -0.1609, -0.0816],\n",
       "                        [-0.0171, -0.0815, -0.0878],\n",
       "                        [-0.0384,  0.0751,  0.0293]],\n",
       "              \n",
       "                       [[ 0.0061, -0.0220, -0.0833],\n",
       "                        [ 0.0124, -0.0083,  0.0255],\n",
       "                        [ 0.0746, -0.0895,  0.0211]],\n",
       "              \n",
       "                       [[-0.1771, -0.1180,  0.0226],\n",
       "                        [ 0.0984, -0.0210, -0.0414],\n",
       "                        [ 0.1382,  0.0387,  0.0620]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0797,  0.0699,  0.0314],\n",
       "                        [-0.0514, -0.1527, -0.0059],\n",
       "                        [-0.0050, -0.0193,  0.0991]],\n",
       "              \n",
       "                       [[-0.1514,  0.0452, -0.0108],\n",
       "                        [-0.0435, -0.1535, -0.0243],\n",
       "                        [ 0.0623, -0.0156, -0.0899]],\n",
       "              \n",
       "                       [[ 0.0136,  0.0049,  0.1030],\n",
       "                        [-0.0593, -0.0197, -0.0076],\n",
       "                        [-0.0189, -0.0357, -0.0282]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0250, -0.0896,  0.1386],\n",
       "                        [-0.0635, -0.0235,  0.0971],\n",
       "                        [-0.0404,  0.0862, -0.0077]],\n",
       "              \n",
       "                       [[-0.0196,  0.0070, -0.0055],\n",
       "                        [-0.0389, -0.1478, -0.0312],\n",
       "                        [ 0.0856,  0.0393, -0.0485]],\n",
       "              \n",
       "                       [[-0.0351,  0.0242, -0.0526],\n",
       "                        [-0.0668, -0.0827,  0.0873],\n",
       "                        [ 0.0886, -0.0227, -0.1589]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1103, -0.0872,  0.0069],\n",
       "                        [-0.0348,  0.0992,  0.0197],\n",
       "                        [-0.0116,  0.0288,  0.0328]],\n",
       "              \n",
       "                       [[-0.0918,  0.0735,  0.0194],\n",
       "                        [-0.1080,  0.0114, -0.0639],\n",
       "                        [-0.0689,  0.0118,  0.0921]],\n",
       "              \n",
       "                       [[ 0.0896, -0.0524,  0.0459],\n",
       "                        [-0.0676, -0.0987,  0.0727],\n",
       "                        [ 0.0799, -0.2089,  0.0608]]]])),\n",
       "             ('vf_features_extractor.cnn.4.bias',\n",
       "              tensor([-0.0527, -0.0421, -0.0194, -0.0534, -0.0266, -0.0121, -0.0038, -0.0021,\n",
       "                      -0.0285, -0.0684, -0.0531, -0.0151, -0.0482, -0.0270, -0.0442, -0.0434,\n",
       "                      -0.0313, -0.0371, -0.0373, -0.0229, -0.0440, -0.0215, -0.0519, -0.0588,\n",
       "                      -0.0308, -0.0252, -0.0491, -0.0177, -0.0092, -0.0191, -0.0484, -0.0235,\n",
       "                      -0.0379, -0.0287, -0.0316, -0.0126, -0.0297, -0.0215, -0.0215, -0.0448,\n",
       "                      -0.0187, -0.0510, -0.0096, -0.0514, -0.0251, -0.0464, -0.0250, -0.0309,\n",
       "                      -0.0291, -0.0448, -0.0306, -0.0332, -0.0095, -0.0130, -0.0548, -0.0416,\n",
       "                      -0.0410, -0.0265, -0.0136, -0.0418,  0.0009, -0.0626, -0.0153, -0.0527])),\n",
       "             ('vf_features_extractor.linear.0.weight',\n",
       "              tensor([[-0.0270, -0.0135, -0.0357,  ..., -0.0760, -0.0304,  0.0015],\n",
       "                      [-0.0007, -0.0621,  0.0162,  ..., -0.0310,  0.0050, -0.0013],\n",
       "                      [-0.0178,  0.0220,  0.0382,  ...,  0.0995, -0.0172,  0.0078],\n",
       "                      ...,\n",
       "                      [-0.0200, -0.0426, -0.1067,  ..., -0.0226, -0.0147, -0.0272],\n",
       "                      [-0.0199,  0.1090, -0.0471,  ...,  0.0651,  0.0328, -0.0295],\n",
       "                      [ 0.0558, -0.0437,  0.0408,  ...,  0.0242,  0.0245,  0.0446]])),\n",
       "             ('vf_features_extractor.linear.0.bias',\n",
       "              tensor([-5.6608e-03,  6.0292e-03, -9.1965e-03, -1.8568e-02, -1.1593e-02,\n",
       "                       9.6789e-03, -1.5750e-02, -2.1523e-02, -1.4694e-02,  1.8843e-03,\n",
       "                      -1.0284e-02, -1.3603e-02, -1.9655e-02,  2.5110e-03, -2.3079e-02,\n",
       "                      -2.5503e-03,  2.5569e-02, -1.5688e-02, -2.0103e-02,  5.9138e-03,\n",
       "                      -2.3874e-03,  1.0382e-02, -1.2352e-03, -6.3961e-03, -3.2044e-03,\n",
       "                       2.0733e-02, -7.9140e-03,  2.1906e-03, -3.3774e-04, -1.2366e-02,\n",
       "                      -8.4314e-03,  6.4223e-03, -1.3893e-02, -1.9243e-02, -9.8721e-03,\n",
       "                      -1.3911e-02, -1.6314e-02,  3.9481e-03,  6.8481e-03, -7.2767e-04,\n",
       "                      -3.5789e-03,  1.7647e-02,  5.1980e-03, -1.5433e-02,  2.0342e-03,\n",
       "                      -3.8536e-03,  4.9479e-03,  1.1522e-02,  3.1461e-03, -2.1221e-02,\n",
       "                      -1.8123e-02,  2.9962e-03, -2.4504e-02, -1.3904e-02, -1.9924e-02,\n",
       "                      -6.5181e-03, -1.1136e-02, -8.0146e-03,  1.1183e-03,  5.8428e-03,\n",
       "                      -6.7766e-03, -1.8218e-02,  2.0625e-02, -4.1976e-03,  9.8920e-03,\n",
       "                       2.7103e-03,  5.1831e-03, -1.0430e-02,  4.0037e-05, -2.4779e-02,\n",
       "                      -2.1182e-02, -4.8570e-04, -1.4988e-02,  4.2176e-04,  1.6978e-02,\n",
       "                      -1.7201e-02, -9.6121e-03, -1.7206e-02, -3.7706e-03, -8.1554e-03,\n",
       "                      -8.9120e-03, -4.4588e-03, -2.7373e-02,  2.3373e-03, -4.0309e-03,\n",
       "                       5.0599e-03, -3.3017e-02, -1.5682e-02, -3.8791e-03, -1.3667e-02,\n",
       "                      -1.1874e-02, -1.3697e-02, -4.7328e-03, -8.9924e-03, -1.7318e-02,\n",
       "                      -7.3571e-03, -5.0703e-03,  1.3889e-02, -1.2070e-02, -1.8983e-02,\n",
       "                      -3.0111e-03, -7.7595e-03,  1.6896e-02, -1.3754e-02,  6.6683e-03,\n",
       "                      -4.5552e-03, -3.7477e-04, -1.2147e-02, -3.4943e-03, -1.3093e-02,\n",
       "                       5.1952e-03,  1.8795e-02,  3.8898e-03, -2.4092e-02,  2.5640e-05,\n",
       "                      -1.4565e-02, -1.4779e-02, -1.6007e-02, -4.0413e-03, -2.6391e-02,\n",
       "                      -9.2754e-03, -6.6702e-03, -1.9132e-02, -1.9438e-02, -1.8338e-02,\n",
       "                      -3.7500e-03,  7.5928e-03, -1.0519e-02, -1.1963e-03,  5.0987e-03,\n",
       "                      -5.1751e-03, -1.9795e-03, -1.2211e-02, -1.1549e-02, -1.8722e-02,\n",
       "                      -5.7123e-03, -3.2459e-02, -7.2956e-03, -2.8802e-02,  3.6083e-03,\n",
       "                       4.6870e-05, -7.6378e-03, -8.7449e-03, -1.4517e-03, -4.2058e-03,\n",
       "                      -1.1429e-02, -1.9129e-02, -8.3722e-03, -1.4606e-02,  1.8631e-03,\n",
       "                      -1.6571e-02,  6.3678e-03, -2.3493e-02, -1.0677e-02, -9.0645e-03,\n",
       "                      -1.2493e-02, -1.7621e-02,  7.2907e-04, -1.5983e-02,  1.2657e-02,\n",
       "                      -1.4844e-02, -3.4709e-02,  3.4632e-03,  5.9516e-03, -1.3603e-02,\n",
       "                      -7.0841e-04, -1.5203e-02, -5.4989e-03, -6.8727e-03, -6.8712e-03,\n",
       "                      -6.7857e-03, -1.2739e-02, -9.4579e-04, -5.7958e-03, -2.0469e-02,\n",
       "                      -4.8724e-03, -1.1285e-02, -1.0248e-02,  1.5599e-02, -1.2677e-02,\n",
       "                      -1.2914e-02,  7.9928e-03, -1.6114e-02, -1.2004e-02, -9.0505e-03,\n",
       "                      -1.7559e-02,  1.1923e-02,  7.7604e-03, -4.7151e-04, -8.8959e-03,\n",
       "                       6.0266e-04, -1.1305e-02, -1.7632e-02, -9.8618e-04, -3.2808e-04,\n",
       "                      -9.2304e-03, -5.8386e-03, -1.2238e-02, -1.0198e-02, -1.9077e-03,\n",
       "                      -1.6158e-02, -1.6521e-02,  4.7318e-03,  1.0410e-02, -2.2033e-02,\n",
       "                       1.1737e-03, -1.2583e-02, -1.3367e-02,  1.6993e-03, -1.0574e-02,\n",
       "                      -3.0460e-03, -8.5488e-03, -1.0641e-02, -2.5659e-02, -1.0535e-02,\n",
       "                      -1.0917e-02, -1.0462e-02, -4.1459e-03, -1.4119e-02, -1.1132e-02,\n",
       "                      -1.0320e-02, -1.4184e-02, -1.0302e-02, -8.1392e-04, -2.7057e-03,\n",
       "                      -4.2100e-03,  1.9071e-02, -1.4972e-02,  3.7827e-03, -8.7062e-03,\n",
       "                       6.6713e-03, -9.7732e-03,  7.0135e-03,  6.3468e-03, -8.1618e-03,\n",
       "                       1.1720e-02, -1.4238e-02, -1.1268e-02,  1.4706e-02,  4.6204e-03,\n",
       "                      -9.1095e-04,  2.2036e-02, -1.6451e-02, -1.4447e-02, -1.8699e-02,\n",
       "                       9.3533e-03, -5.2393e-03,  1.2488e-02, -7.6009e-03, -9.2387e-04,\n",
       "                      -1.9480e-03, -1.4901e-02, -1.6314e-02,  5.9689e-03, -5.6877e-03,\n",
       "                       9.1546e-03])),\n",
       "             ('mlp_extractor.policy_net.0.weight',\n",
       "              tensor([[ 0.0052, -0.0291, -0.1622,  ..., -0.0602,  0.0157, -0.1659],\n",
       "                      [ 0.2019, -0.0419, -0.0568,  ..., -0.0626,  0.1577,  0.0271],\n",
       "                      [-0.0572,  0.1457,  0.0097,  ..., -0.0697,  0.0149,  0.1527],\n",
       "                      ...,\n",
       "                      [ 0.1710, -0.0119, -0.0412,  ..., -0.0447, -0.0182, -0.2364],\n",
       "                      [ 0.0447,  0.1429,  0.0491,  ...,  0.0427, -0.1254, -0.0774],\n",
       "                      [ 0.0038, -0.0645,  0.0989,  ...,  0.0437,  0.0210,  0.1546]])),\n",
       "             ('mlp_extractor.policy_net.0.bias',\n",
       "              tensor([-3.7934e-02, -1.0120e-02, -1.7950e-02,  1.3979e-02, -8.9758e-03,\n",
       "                       9.3981e-03,  1.4142e-02, -1.4561e-02,  7.6285e-03, -7.7994e-04,\n",
       "                       3.3254e-02,  3.0155e-03, -5.0676e-03, -8.6990e-03, -6.2035e-03,\n",
       "                      -1.2432e-02,  2.6509e-02,  2.8312e-02, -1.0761e-02, -6.4396e-03,\n",
       "                      -2.3653e-02, -5.9161e-03, -1.6559e-03,  2.3093e-03,  2.1843e-02,\n",
       "                      -5.1557e-03,  3.7100e-02,  2.4642e-02, -2.5497e-02,  2.5407e-02,\n",
       "                       3.0578e-02,  2.9345e-02,  7.7088e-03, -1.1796e-02, -1.3831e-02,\n",
       "                      -2.3595e-02, -1.1430e-03, -1.2029e-02, -7.1556e-03,  1.3530e-02,\n",
       "                      -2.2087e-02, -5.5528e-03,  4.2695e-03,  2.3459e-04, -3.0454e-05,\n",
       "                      -2.4168e-02,  7.0001e-03, -2.1349e-02,  8.1098e-03,  2.3649e-04,\n",
       "                      -1.2144e-02, -1.6706e-02, -1.0958e-02, -2.8586e-03,  3.7588e-02,\n",
       "                      -8.2629e-03,  4.8411e-03, -8.2878e-03,  1.0644e-02,  5.4867e-03,\n",
       "                       6.1514e-03,  9.5967e-03,  1.0890e-02,  4.9025e-03,  1.5948e-02,\n",
       "                       2.1311e-02,  9.8605e-03, -6.4243e-03, -2.9398e-03, -3.6904e-03,\n",
       "                      -9.9446e-03,  1.9047e-02,  1.4092e-02,  2.4026e-03,  3.2092e-02,\n",
       "                      -1.5059e-02,  8.1860e-03,  2.6424e-02, -3.0271e-02,  3.8252e-02,\n",
       "                       1.3251e-02, -1.6951e-02,  5.3191e-03,  2.9410e-02, -2.0283e-02,\n",
       "                       2.5827e-02, -4.1000e-03, -1.0457e-02,  2.1510e-03,  1.4410e-02,\n",
       "                      -4.7814e-03,  3.4634e-03,  4.0821e-03,  2.1709e-02,  3.6088e-02,\n",
       "                       8.9005e-03,  1.4891e-02,  6.9741e-04, -1.8474e-02,  7.3035e-03,\n",
       "                       1.6245e-02, -3.5832e-02,  8.3168e-03, -1.0705e-02,  2.0325e-02,\n",
       "                       2.9341e-02, -3.1170e-02,  1.2995e-02,  1.0005e-02, -3.5040e-02,\n",
       "                       1.2313e-02, -1.4531e-02,  2.3488e-02,  8.1426e-03, -1.0364e-02,\n",
       "                       2.7742e-03, -3.1425e-02,  1.2838e-04, -1.4976e-02, -4.1408e-03,\n",
       "                       8.6572e-03,  1.7360e-02,  3.3624e-02,  1.0835e-02, -1.7576e-02,\n",
       "                      -1.2138e-02,  1.5603e-02, -1.0795e-02,  2.0145e-02, -2.9814e-03,\n",
       "                       1.9765e-03, -8.7999e-03, -6.0783e-03,  1.3500e-02, -3.3708e-02,\n",
       "                      -1.0044e-02,  1.5282e-02,  1.2506e-02,  1.2176e-02,  7.7159e-03,\n",
       "                       3.4869e-02,  1.3253e-02,  5.5851e-05,  1.8154e-03, -6.9276e-04,\n",
       "                      -1.5390e-02,  2.1272e-02,  1.5382e-02, -1.2867e-03, -1.2366e-02,\n",
       "                      -2.6879e-02, -2.3791e-04, -1.2761e-02, -1.2157e-02, -1.4863e-02,\n",
       "                       4.1211e-02, -3.5103e-03,  1.8319e-02, -4.5932e-03, -5.1984e-03,\n",
       "                       2.5223e-02,  6.9816e-03, -8.6695e-03,  1.1261e-02, -1.7240e-03,\n",
       "                      -6.5262e-04, -8.2426e-03, -3.1230e-03, -3.0566e-02,  2.8768e-02,\n",
       "                       1.2229e-02,  8.3468e-03,  2.0897e-03,  1.0116e-02,  1.9699e-03,\n",
       "                       2.2369e-03, -1.7555e-02, -4.4118e-02,  2.1739e-02, -4.9466e-02,\n",
       "                      -8.6298e-03, -4.1051e-02,  2.9664e-02,  1.9345e-02, -2.0059e-02,\n",
       "                       2.3699e-02, -3.7010e-02,  2.4064e-02, -3.7450e-03,  4.3794e-02,\n",
       "                       3.8838e-02,  8.5117e-03, -7.4019e-03,  2.0133e-02,  2.1669e-02,\n",
       "                      -1.1451e-02,  1.6833e-02, -1.3509e-02, -7.1325e-04,  1.1084e-02,\n",
       "                       2.7922e-02,  1.0219e-02, -7.6056e-05, -1.0354e-02, -2.5249e-02,\n",
       "                       1.2617e-02, -2.6633e-03,  3.5738e-03,  3.5735e-04,  1.8399e-02,\n",
       "                      -4.8047e-03,  4.1018e-03,  4.1222e-03,  1.7260e-02, -1.0157e-02,\n",
       "                      -1.2880e-02, -2.6215e-02, -2.7168e-02,  1.0103e-02,  1.7706e-02,\n",
       "                      -4.7546e-02,  9.3363e-03, -2.8084e-02, -1.0535e-02, -1.5182e-02,\n",
       "                      -1.3819e-02, -1.1448e-02, -6.4746e-03,  7.6021e-04,  1.2651e-02,\n",
       "                      -1.0050e-02,  2.2821e-02,  1.5586e-02, -2.1990e-02, -9.9179e-03,\n",
       "                      -1.3580e-02,  1.8374e-03, -1.4163e-02, -5.2409e-03, -1.2622e-02,\n",
       "                      -7.0958e-04,  2.5395e-02, -1.7106e-02,  1.8910e-02,  4.9914e-06,\n",
       "                       3.1792e-03, -1.6064e-02,  6.5150e-03, -1.2743e-03,  1.4860e-03,\n",
       "                       7.6464e-03, -1.0430e-02, -7.9494e-03,  7.8145e-04,  4.2292e-03,\n",
       "                      -1.3421e-02])),\n",
       "             ('mlp_extractor.policy_net.2.weight',\n",
       "              tensor([[ 0.0511,  0.0201, -0.1065,  ...,  0.1073, -0.1929,  0.0241],\n",
       "                      [-0.0182, -0.0378,  0.0256,  ...,  0.0010, -0.0474,  0.1143],\n",
       "                      [-0.1059, -0.0264,  0.0380,  ...,  0.0188,  0.0859, -0.0179],\n",
       "                      ...,\n",
       "                      [ 0.0793, -0.0118, -0.1422,  ...,  0.1023,  0.1145, -0.0365],\n",
       "                      [-0.2033,  0.0724, -0.0057,  ...,  0.1733,  0.0949,  0.0662],\n",
       "                      [-0.1075, -0.1196,  0.0106,  ..., -0.0087, -0.0097,  0.0297]])),\n",
       "             ('mlp_extractor.policy_net.2.bias',\n",
       "              tensor([ 5.8172e-03, -9.2728e-03, -1.5235e-02,  2.1914e-02, -1.1689e-02,\n",
       "                      -3.3092e-03,  3.9647e-03,  3.0486e-02, -1.0433e-03, -2.3171e-02,\n",
       "                      -3.3122e-02,  7.0034e-03,  2.3954e-02,  8.0406e-03,  2.2886e-02,\n",
       "                       4.0525e-02, -3.2603e-02,  1.2374e-02,  1.5371e-02,  1.8317e-02,\n",
       "                      -3.2269e-02,  3.0887e-03,  9.6856e-04, -4.9347e-03, -8.1643e-03,\n",
       "                      -6.9902e-03, -2.0729e-02, -1.7335e-02,  1.0368e-02,  4.6599e-02,\n",
       "                      -9.1468e-03,  6.8571e-03, -3.8949e-02, -2.3278e-02,  2.9535e-02,\n",
       "                       2.7574e-02, -2.5148e-02, -4.7471e-03, -3.7972e-03,  3.3504e-02,\n",
       "                       1.0143e-03,  1.5877e-02,  4.4178e-03, -3.8147e-04,  5.7864e-03,\n",
       "                       8.3002e-03, -4.5355e-03, -1.7833e-03,  5.7902e-03, -3.3542e-02,\n",
       "                      -4.1374e-02, -4.3449e-03,  2.2690e-02,  4.9732e-02, -3.6212e-02,\n",
       "                      -2.2802e-02, -6.3588e-03,  3.5946e-02, -1.8580e-02,  1.8553e-02,\n",
       "                       1.3691e-03,  3.3293e-02,  1.0821e-02, -1.0577e-02, -3.1498e-03,\n",
       "                      -1.4162e-02, -4.9431e-04,  5.2355e-03,  2.2729e-02, -1.2883e-02,\n",
       "                       5.9154e-02,  1.1512e-02, -7.2364e-03,  4.1261e-02, -2.6351e-03,\n",
       "                      -3.3032e-03,  3.3423e-02, -1.7533e-02, -1.6128e-02, -5.7894e-03,\n",
       "                      -1.4025e-02,  2.8735e-02, -2.5581e-02,  1.1237e-02, -3.9039e-02,\n",
       "                      -3.7581e-02, -1.1970e-02, -1.2555e-02,  1.9434e-02, -2.8948e-03,\n",
       "                      -2.3720e-02,  2.3603e-03, -2.1667e-02,  7.3620e-03,  6.9243e-03,\n",
       "                      -2.9235e-02, -6.6256e-03,  5.0314e-03, -4.4027e-02, -1.1383e-02,\n",
       "                      -8.4184e-03,  5.0313e-03, -2.0207e-02, -4.1501e-03,  2.3522e-02,\n",
       "                       8.4851e-03, -2.2156e-03, -2.1147e-03,  5.7881e-02, -1.9192e-02,\n",
       "                      -1.7235e-02, -1.0253e-03,  1.4571e-02, -3.1924e-02,  1.9331e-02,\n",
       "                       2.0114e-02, -8.6965e-03,  3.2256e-02,  4.3058e-03,  5.4712e-02,\n",
       "                       1.9615e-02,  1.8704e-03,  5.2401e-02, -3.4430e-02, -8.1612e-05,\n",
       "                       5.9762e-04,  2.5525e-02, -1.6064e-02, -2.2107e-04,  5.0914e-03,\n",
       "                       1.0815e-02, -1.0005e-02, -1.7143e-02, -1.5681e-02,  8.5298e-03,\n",
       "                      -3.6848e-02,  2.3611e-03,  9.8262e-03,  2.9744e-02,  1.9323e-02,\n",
       "                      -1.6335e-02,  3.2883e-03, -1.7270e-02,  2.2763e-02,  9.8032e-03,\n",
       "                      -1.2764e-02,  4.0871e-02, -9.9673e-03, -8.9770e-03,  2.0862e-02,\n",
       "                       3.0616e-03, -1.7059e-02,  3.8725e-03, -4.2900e-02,  3.4070e-02,\n",
       "                       2.7956e-02,  1.5438e-02,  1.4472e-02, -8.1820e-03, -1.1573e-02,\n",
       "                       1.9302e-02,  3.4712e-02, -2.1957e-02,  3.6883e-02,  8.5630e-03,\n",
       "                      -2.2851e-02,  6.6175e-04,  9.5112e-04,  1.5366e-02,  7.0738e-03,\n",
       "                       1.7809e-02, -1.1229e-02, -4.7060e-04, -1.4683e-02,  8.8176e-03,\n",
       "                      -5.0882e-03, -3.6376e-03,  3.1334e-02,  2.2544e-02,  9.8405e-04,\n",
       "                      -2.3720e-03, -1.2918e-02,  1.5443e-02,  8.2233e-03,  7.1529e-03,\n",
       "                       3.2825e-02, -2.0104e-03, -1.7655e-02, -1.4801e-02,  5.4752e-03,\n",
       "                       4.5423e-03, -1.3051e-02, -3.9650e-02, -2.9016e-02, -8.5384e-03,\n",
       "                      -2.8884e-02, -3.0124e-02,  6.3246e-03, -1.5233e-02, -3.7544e-03,\n",
       "                      -1.7659e-02,  1.9056e-02, -1.4498e-03,  1.3431e-02, -1.0964e-02,\n",
       "                       4.5452e-02,  1.2764e-02, -2.1018e-02,  3.3983e-02, -3.1912e-02,\n",
       "                       3.3260e-02, -1.0320e-02,  1.0350e-02, -1.9775e-02, -4.2863e-02,\n",
       "                      -5.0495e-03,  9.6319e-03, -7.5421e-03,  1.2882e-02,  4.0134e-03,\n",
       "                       6.3385e-03, -3.0139e-03,  8.3679e-03,  4.1635e-03, -6.2613e-03,\n",
       "                       2.6277e-02, -1.4394e-02, -1.3608e-02, -7.6196e-03,  9.5283e-03,\n",
       "                       1.7422e-03,  2.5673e-03, -2.9025e-03,  2.9847e-03,  2.5024e-03,\n",
       "                       2.5046e-02, -2.5419e-03, -7.8934e-04, -2.0001e-02,  2.9911e-02,\n",
       "                      -1.8285e-02,  7.0310e-03, -1.1704e-03, -1.3317e-02,  1.7797e-02,\n",
       "                      -1.4191e-02,  1.4188e-02,  1.0172e-02,  1.6443e-02, -4.8110e-03,\n",
       "                      -1.3569e-02, -1.8782e-02,  1.6926e-02,  2.8619e-03, -3.7016e-03,\n",
       "                      -2.4370e-02])),\n",
       "             ('mlp_extractor.value_net.0.weight',\n",
       "              tensor([[ 0.0258, -0.0781,  0.1049,  ...,  0.0501, -0.0005, -0.0208],\n",
       "                      [ 0.1494,  0.0542,  0.0675,  ...,  0.0640,  0.0272,  0.0994],\n",
       "                      [-0.0923, -0.0055,  0.1079,  ...,  0.0536, -0.0654,  0.0674],\n",
       "                      ...,\n",
       "                      [ 0.0520, -0.0476,  0.0897,  ...,  0.0859,  0.0255,  0.0612],\n",
       "                      [-0.0903,  0.1567,  0.1841,  ..., -0.1402, -0.2208, -0.0551],\n",
       "                      [ 0.0460,  0.0967, -0.1723,  ..., -0.0152, -0.0825,  0.1534]])),\n",
       "             ('mlp_extractor.value_net.0.bias',\n",
       "              tensor([ 0.0073, -0.0171,  0.0155, -0.0193, -0.0133, -0.0160, -0.0482, -0.0190,\n",
       "                      -0.0075,  0.0030, -0.0123, -0.0150, -0.0414,  0.0151, -0.0232, -0.0071,\n",
       "                       0.0317, -0.0380,  0.0064, -0.0079, -0.0125,  0.0227,  0.0055,  0.0281,\n",
       "                      -0.0529,  0.0325,  0.0030, -0.0118,  0.0103, -0.0017,  0.0199, -0.0090,\n",
       "                      -0.0195, -0.0411,  0.0095,  0.0086,  0.0282, -0.0010,  0.0117,  0.0123,\n",
       "                       0.0093,  0.0220, -0.0035, -0.0292,  0.0189, -0.0098, -0.0344,  0.0114,\n",
       "                      -0.0050, -0.0643, -0.0059,  0.0310,  0.0136, -0.0199,  0.0402,  0.0118,\n",
       "                      -0.0216,  0.0063,  0.0250, -0.0296,  0.0183, -0.0258, -0.0150,  0.0188,\n",
       "                       0.0134,  0.0280,  0.0019,  0.0076, -0.0032,  0.0001,  0.0159,  0.0034,\n",
       "                      -0.0075, -0.0161,  0.0066,  0.0083, -0.0256, -0.0052, -0.0293,  0.0066,\n",
       "                       0.0029,  0.0149,  0.0256,  0.0195, -0.0138, -0.0393, -0.0222, -0.0050,\n",
       "                       0.0161,  0.0128,  0.0078, -0.0042, -0.0154, -0.0137, -0.0071, -0.0200,\n",
       "                      -0.0319,  0.0311, -0.0018, -0.0017, -0.0239, -0.0181,  0.0355,  0.0221,\n",
       "                      -0.0281, -0.0100, -0.0033, -0.0069,  0.0126, -0.0165,  0.0251,  0.0010,\n",
       "                       0.0250,  0.0176, -0.0393, -0.0370, -0.0079,  0.0139, -0.0199, -0.0082,\n",
       "                       0.0288,  0.0476,  0.0187,  0.0241,  0.0296, -0.0201, -0.0502, -0.0255,\n",
       "                       0.0019,  0.0212, -0.0188, -0.0122, -0.0228,  0.0101, -0.0274, -0.0159,\n",
       "                       0.0330, -0.0052,  0.0089,  0.0152, -0.0158,  0.0064, -0.0217,  0.0302,\n",
       "                       0.0088,  0.0203,  0.0293,  0.0118, -0.0266, -0.0313,  0.0287,  0.0292,\n",
       "                       0.0227,  0.0242,  0.0089, -0.0319,  0.0309,  0.0305,  0.0053,  0.0116,\n",
       "                       0.0179, -0.0401,  0.0046,  0.0064, -0.0346,  0.0299, -0.0042, -0.0296,\n",
       "                       0.0248,  0.0164,  0.0080,  0.0439, -0.0256, -0.0213,  0.0053,  0.0067,\n",
       "                       0.0025, -0.0117, -0.0139, -0.0202,  0.0104, -0.0056,  0.0295,  0.0389,\n",
       "                       0.0347, -0.0263,  0.0114, -0.0407,  0.0029,  0.0330, -0.0109,  0.0093,\n",
       "                       0.0185, -0.0436, -0.0021,  0.0105,  0.0289,  0.0050,  0.0291, -0.0307,\n",
       "                      -0.0111,  0.0218,  0.0322, -0.0216, -0.0034,  0.0108,  0.0139,  0.0242,\n",
       "                      -0.0039, -0.0260,  0.0204, -0.0051, -0.0184, -0.0102, -0.0113, -0.0258,\n",
       "                      -0.0226,  0.0083,  0.0291,  0.0410, -0.0232, -0.0176, -0.0105, -0.0313,\n",
       "                       0.0339,  0.0156, -0.0041,  0.0539, -0.0181, -0.0149,  0.0247,  0.0223,\n",
       "                       0.0065, -0.0142,  0.0087,  0.0416, -0.0010, -0.0007, -0.0284,  0.0091,\n",
       "                      -0.0299, -0.0273, -0.0013,  0.0311,  0.0177,  0.0006, -0.0274,  0.0434,\n",
       "                       0.0060,  0.0048, -0.0065,  0.0375,  0.0143, -0.0056,  0.0025,  0.0400])),\n",
       "             ('mlp_extractor.value_net.2.weight',\n",
       "              tensor([[ 0.1031, -0.0784,  0.1225,  ...,  0.0166, -0.0647,  0.0448],\n",
       "                      [-0.0746, -0.2045,  0.0213,  ...,  0.0200,  0.0301,  0.0594],\n",
       "                      [-0.0485,  0.1501, -0.0747,  ..., -0.0354, -0.0677,  0.0100],\n",
       "                      ...,\n",
       "                      [ 0.3010, -0.0592, -0.0250,  ..., -0.1353, -0.0817, -0.0257],\n",
       "                      [ 0.0583, -0.0296, -0.0965,  ...,  0.1907,  0.0751, -0.0286],\n",
       "                      [-0.0687,  0.1230,  0.0270,  ...,  0.0339,  0.0858, -0.0454]])),\n",
       "             ('mlp_extractor.value_net.2.bias',\n",
       "              tensor([ 3.5799e-03,  3.5292e-03, -1.9715e-02, -1.0328e-02,  1.7350e-02,\n",
       "                      -1.7284e-02,  9.3694e-04, -1.8285e-02, -6.7587e-03,  3.6638e-03,\n",
       "                      -1.4437e-02,  1.9942e-02, -2.1250e-02, -2.2902e-02,  2.3250e-02,\n",
       "                      -9.0199e-03, -2.0914e-02,  1.6462e-02,  1.6864e-02,  1.6971e-02,\n",
       "                       1.0805e-02,  9.4597e-03,  6.0784e-04, -3.4437e-03, -1.5691e-02,\n",
       "                       1.0027e-03,  1.3647e-02, -5.8386e-03, -1.6246e-02,  1.9832e-02,\n",
       "                       1.8696e-02, -1.8948e-02, -6.1973e-03,  1.1848e-02,  1.3520e-02,\n",
       "                      -5.1360e-03, -1.0215e-02,  1.6143e-02,  1.0493e-02,  9.4610e-03,\n",
       "                      -2.1828e-02,  1.2389e-02, -2.3929e-02, -1.5668e-02, -5.4613e-04,\n",
       "                       9.8429e-03, -4.7456e-03,  1.1693e-02,  1.6548e-02, -2.3037e-02,\n",
       "                       6.6384e-04, -2.4440e-03,  1.8023e-02, -1.5377e-02,  2.9876e-03,\n",
       "                       1.4220e-02, -6.3246e-03,  6.4127e-03,  2.1948e-02,  1.6072e-02,\n",
       "                      -3.6497e-03,  7.4768e-03,  1.9767e-02, -1.7684e-02, -5.7277e-03,\n",
       "                      -5.6413e-03, -1.7375e-02,  1.5375e-02,  1.7958e-02, -1.6137e-02,\n",
       "                      -1.2186e-02,  1.5668e-05,  2.5710e-03, -6.8798e-03, -1.8157e-02,\n",
       "                      -1.4367e-02, -6.2862e-03, -1.1924e-02, -1.5660e-02,  1.9036e-02,\n",
       "                      -2.3311e-02,  9.5750e-03, -1.9810e-02,  2.0722e-02,  6.2475e-04,\n",
       "                      -1.5477e-02,  1.1501e-02, -1.0731e-02,  2.7525e-03, -8.3308e-03,\n",
       "                      -2.5942e-02, -1.4650e-03, -8.8326e-03,  2.0180e-03, -7.1282e-03,\n",
       "                       4.4672e-03,  4.1499e-03,  1.4123e-02, -3.6176e-03,  1.8223e-02,\n",
       "                       2.1647e-03,  6.9139e-03,  1.0047e-03, -4.0867e-03,  1.2341e-02,\n",
       "                      -7.2736e-03,  2.3376e-02,  1.7278e-02,  6.8736e-04, -1.8320e-02,\n",
       "                       1.3428e-02, -1.5306e-02,  2.0008e-02,  1.6215e-06,  1.6775e-02,\n",
       "                      -1.5133e-02, -1.3126e-02, -1.2041e-02,  1.5071e-02, -1.9596e-02,\n",
       "                      -2.3280e-02,  1.5094e-02, -2.1058e-02,  2.0434e-02, -1.8828e-03,\n",
       "                      -5.4423e-03, -2.1646e-02,  5.7857e-03,  2.1414e-02,  1.6875e-03,\n",
       "                       2.2360e-02, -2.1373e-02, -9.8489e-03,  1.6259e-02,  1.7101e-02,\n",
       "                      -2.2432e-02,  1.9357e-02, -1.9886e-02, -2.0919e-02, -1.9031e-02,\n",
       "                      -1.6509e-03, -1.6547e-03,  1.5982e-02,  5.1847e-03,  1.9170e-02,\n",
       "                       1.7896e-02,  2.4410e-03,  1.1951e-02, -2.4551e-02,  1.6849e-02,\n",
       "                      -1.9074e-02, -2.2394e-02, -2.1093e-02,  2.0049e-02, -1.7392e-02,\n",
       "                       2.3051e-02, -1.7531e-02,  4.6713e-04, -3.2929e-03,  3.0393e-03,\n",
       "                       1.0845e-02, -2.2677e-02, -1.7766e-02, -5.2143e-03, -1.9969e-02,\n",
       "                      -2.1128e-02, -1.7207e-02,  3.5592e-03,  3.8090e-03,  1.3139e-02,\n",
       "                      -2.2284e-02,  1.3133e-02, -1.9177e-03, -1.9009e-02, -2.1424e-02,\n",
       "                       1.5563e-03,  1.4668e-02, -2.0922e-02, -2.2657e-03,  2.2310e-02,\n",
       "                      -1.1378e-02, -2.0817e-02,  6.2105e-04,  1.2367e-02, -4.5331e-03,\n",
       "                       1.0558e-02,  5.1795e-03, -2.2744e-02,  1.8500e-02, -2.2728e-02,\n",
       "                      -1.8266e-02,  4.4167e-03,  2.2934e-02, -1.0485e-02, -1.5243e-02,\n",
       "                      -3.7956e-03, -1.3557e-02, -1.7258e-02,  2.4479e-02, -2.1338e-02,\n",
       "                      -1.9147e-02,  2.0108e-02,  6.1759e-03,  8.7468e-03, -3.2058e-03,\n",
       "                       1.2333e-02, -2.0609e-02, -3.1282e-03, -2.4115e-03, -1.0368e-02,\n",
       "                      -1.8686e-02, -9.9143e-03, -1.2893e-02, -7.8900e-03, -1.9347e-02,\n",
       "                       2.9915e-03,  1.7967e-02, -1.4676e-02,  2.0105e-02, -5.5169e-03,\n",
       "                       1.9404e-02,  2.3219e-02,  1.8098e-02, -5.3687e-03, -5.9559e-03,\n",
       "                      -4.4813e-03, -1.5034e-03, -1.3383e-02,  1.9927e-02, -3.6679e-03,\n",
       "                       1.7204e-02, -5.4026e-03,  1.2775e-02,  2.2480e-03, -4.0149e-03,\n",
       "                      -4.6519e-03,  2.7157e-02,  2.2412e-03, -2.5997e-03, -2.6912e-02,\n",
       "                       2.0699e-02, -1.8649e-02,  5.4057e-04,  2.2096e-02, -6.5883e-04,\n",
       "                      -8.6348e-05,  2.0106e-02,  1.8275e-02, -1.8689e-02,  3.5094e-03,\n",
       "                       1.7725e-02,  7.9392e-03, -1.5728e-03,  1.8433e-02,  5.5552e-03,\n",
       "                      -6.0163e-03])),\n",
       "             ('action_net.weight',\n",
       "              tensor([[ 0.0012,  0.0227, -0.0473,  ..., -0.0274, -0.0431,  0.0210],\n",
       "                      [ 0.0113,  0.0733, -0.0241,  ..., -0.0195,  0.0170, -0.0060],\n",
       "                      [ 0.0015, -0.0290,  0.0109,  ..., -0.0131,  0.0136,  0.0368],\n",
       "                      ...,\n",
       "                      [-0.0149,  0.0221,  0.0098,  ...,  0.0015, -0.0339,  0.0399],\n",
       "                      [ 0.0411, -0.0210,  0.0034,  ...,  0.0035, -0.0071,  0.0404],\n",
       "                      [ 0.0169, -0.0078,  0.0210,  ..., -0.0110, -0.0452, -0.0073]])),\n",
       "             ('action_net.bias',\n",
       "              tensor([ 7.1976e-03, -5.1840e-05, -1.8893e-02, -1.4768e-02, -2.1590e-02,\n",
       "                      -5.3293e-04, -2.1903e-02, -3.6274e-02, -6.4636e-03,  2.2269e-02,\n",
       "                      -1.0875e-02,  3.7804e-02, -1.9634e-02, -3.0975e-03,  7.7602e-03,\n",
       "                       2.1053e-02, -1.2791e-02,  4.7547e-02, -5.0211e-04,  3.2260e-02,\n",
       "                       2.1611e-02,  4.7714e-02,  4.0008e-02, -3.6381e-03, -1.5408e-02,\n",
       "                       2.9937e-02,  1.1037e-02, -1.4739e-02, -3.4997e-02,  3.0742e-02,\n",
       "                       1.1662e-02,  4.3333e-03, -4.1599e-04, -2.0226e-02,  3.1167e-02,\n",
       "                       4.4749e-03, -1.5468e-02,  1.3803e-02,  3.2176e-02,  1.3382e-02,\n",
       "                      -1.9587e-02,  4.2042e-03,  2.7800e-03,  3.3353e-02,  2.5322e-02,\n",
       "                       3.6295e-02, -2.6026e-03, -1.0599e-02, -2.5099e-02,  1.8091e-02,\n",
       "                       6.1407e-02,  1.6070e-02,  5.6761e-02,  4.9916e-03,  2.9991e-02,\n",
       "                      -1.8809e-02, -1.3155e-03,  1.8749e-03, -1.5828e-02, -5.5678e-03,\n",
       "                      -2.2151e-02, -1.0909e-02, -5.0003e-02, -1.3498e-02])),\n",
       "             ('value_net.weight',\n",
       "              tensor([[-3.3037e-03,  5.3284e-03, -9.3936e-02,  9.3759e-02, -7.8912e-02,\n",
       "                        1.7651e-02, -3.1864e-03,  1.4838e-02,  3.6118e-02, -2.1965e-03,\n",
       "                       -1.8197e-02, -1.1277e-01,  3.9909e-02,  1.2386e-01,  7.8707e-02,\n",
       "                        4.8020e-02, -5.5264e-02,  2.9150e-02,  1.2501e-01,  7.0784e-02,\n",
       "                        1.1205e-01,  5.6027e-03, -5.6052e-03, -1.5464e-03, -2.6084e-02,\n",
       "                        1.8369e-02,  6.4251e-02,  5.6639e-03, -8.8315e-03, -4.6602e-02,\n",
       "                       -5.5952e-02,  1.3690e-01,  2.1227e-02,  5.3258e-02, -9.6172e-03,\n",
       "                        4.0385e-04, -1.2305e-03, -1.4693e-01,  1.1193e-01, -1.1170e-03,\n",
       "                        3.9019e-02, -2.3649e-02,  9.3961e-02, -9.2013e-02,  4.6556e-03,\n",
       "                        2.4766e-02, -1.1856e-02, -4.0379e-02, -9.1541e-03, -4.7995e-02,\n",
       "                        1.2343e-03, -1.1859e-03, -9.0648e-02, -1.1912e-01, -3.0946e-03,\n",
       "                       -4.7574e-02,  1.3759e-02, -3.0798e-03, -8.3888e-02,  3.3826e-02,\n",
       "                        2.1512e-03,  3.5112e-03, -3.0947e-02, -3.9469e-02,  1.4467e-03,\n",
       "                        5.8429e-03, -4.3625e-02, -9.0233e-03,  6.3658e-02,  1.1783e-01,\n",
       "                       -8.9585e-02, -3.9797e-03,  2.1342e-03,  1.6873e-03, -4.2570e-02,\n",
       "                        1.7917e-02, -4.5486e-04, -6.3664e-02,  3.0962e-02,  7.5418e-02,\n",
       "                       -8.5835e-02, -3.8027e-03, -5.4829e-02, -8.5183e-02,  4.9747e-03,\n",
       "                       -1.7616e-02,  3.7681e-02, -8.1497e-03, -3.2110e-02, -4.7939e-03,\n",
       "                        5.9446e-02,  1.2871e-04, -1.1236e-03,  1.0122e-04,  5.9017e-03,\n",
       "                        3.4359e-03, -2.4740e-03, -9.4853e-02, -2.3892e-03, -8.1743e-02,\n",
       "                       -1.4456e-04, -1.7734e-03,  5.2059e-03, -2.7922e-03, -1.3474e-02,\n",
       "                        3.6450e-02,  7.0219e-02,  6.5782e-02, -1.7412e-03,  4.3386e-02,\n",
       "                       -3.6895e-03, -4.2182e-02, -5.8059e-02, -2.2665e-03, -5.7482e-02,\n",
       "                       -9.4000e-03,  3.1009e-02, -6.0081e-02,  2.9139e-02,  1.0468e-01,\n",
       "                        1.1024e-01,  8.5318e-02, -6.7113e-02, -1.1693e-01,  2.0401e-03,\n",
       "                        9.4724e-03,  4.8819e-02,  7.7481e-03,  7.7007e-02, -2.4200e-03,\n",
       "                        8.8408e-02, -5.8496e-02, -5.1439e-04,  9.0237e-02,  3.7648e-02,\n",
       "                        6.7163e-02, -6.7338e-02,  1.0306e-01,  5.6972e-02,  6.1626e-02,\n",
       "                        5.8335e-03,  4.4375e-03, -7.0211e-02,  2.6161e-03,  5.2987e-02,\n",
       "                       -6.7511e-02, -2.0358e-02,  1.0349e-01,  5.6568e-02,  2.9279e-02,\n",
       "                       -7.6973e-02,  5.6301e-02,  3.8001e-02, -7.7740e-02,  2.8528e-02,\n",
       "                        5.9497e-02, -5.6108e-02, -2.2918e-03,  6.8027e-04, -4.1869e-03,\n",
       "                        1.2244e-03,  5.1292e-02,  3.3933e-02,  1.4602e-03, -4.8650e-02,\n",
       "                        1.5021e-01,  2.3874e-02,  9.1171e-04,  5.1501e-04,  3.2667e-02,\n",
       "                        6.0254e-02,  4.0823e-02,  6.8889e-04, -5.0441e-02,  2.6259e-02,\n",
       "                       -2.2578e-03, -1.6464e-01, -4.4331e-02,  1.3884e-03, -8.8885e-02,\n",
       "                       -6.9349e-02,  1.5955e-01,  5.2212e-03,  3.4174e-02, -1.0216e-02,\n",
       "                       -4.7145e-02, -5.4640e-03,  4.1004e-02,  1.3680e-01,  3.7153e-02,\n",
       "                        1.3271e-01, -1.7563e-02, -7.9908e-02, -5.3408e-03,  6.6469e-02,\n",
       "                       -3.7583e-03, -7.7805e-02, -3.3602e-02, -8.1072e-02,  8.2813e-02,\n",
       "                       -5.8939e-02,  2.5783e-02,  5.9611e-03,  5.1634e-02, -1.8126e-03,\n",
       "                       -2.9491e-02,  6.7121e-02, -3.0367e-03, -3.8643e-03, -9.6008e-02,\n",
       "                       -1.0055e-01,  9.4307e-03,  2.6973e-02, -7.6093e-03, -3.8869e-02,\n",
       "                       -1.6433e-03, -5.9397e-02, -7.7529e-02,  5.9596e-02, -8.4991e-03,\n",
       "                        4.8007e-02, -5.4996e-02, -6.5658e-02,  1.5903e-04, -9.2767e-02,\n",
       "                        7.7916e-03,  1.5767e-04, -5.0047e-02, -3.0773e-02, -8.7600e-02,\n",
       "                        8.4599e-02,  1.3865e-03,  9.1907e-03, -1.3307e-04, -4.5890e-03,\n",
       "                        1.2302e-03, -6.6371e-02,  2.2931e-03, -3.8944e-03,  1.7272e-02,\n",
       "                       -2.2133e-02, -5.1664e-02,  5.3131e-04, -1.9438e-02,  3.2887e-02,\n",
       "                       -1.1220e-02, -4.9104e-02,  3.0505e-02,  2.3949e-02, -6.2865e-04,\n",
       "                        7.8438e-02, -3.3102e-04, -1.7982e-03, -3.1845e-02,  3.5578e-02,\n",
       "                        1.4502e-03]])),\n",
       "             ('value_net.bias', tensor([0.0009]))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "92687fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('features_extractor.cnn.0.weight',\n",
       "              tensor([[[[ 5.8862e-02,  3.7363e-01, -1.3097e-01],\n",
       "                        [-1.3117e-01, -1.4281e-01,  1.0642e-02],\n",
       "                        [-3.2974e-01,  5.1945e-02, -1.7016e-01]],\n",
       "              \n",
       "                       [[-1.6550e-01,  2.2424e-01,  6.2481e-01],\n",
       "                        [ 1.1638e-01,  6.0274e-02,  2.3141e-01],\n",
       "                        [-1.1957e-01, -3.1702e-01,  2.2510e-01]],\n",
       "              \n",
       "                       [[-1.1080e-01,  3.4992e-01, -2.3739e-01],\n",
       "                        [-8.8834e-02,  2.8504e-01,  1.4751e-01],\n",
       "                        [ 1.0280e-01, -2.0961e-01, -1.3982e-01]],\n",
       "              \n",
       "                       [[-3.6928e-01,  2.0983e-01, -2.5590e-01],\n",
       "                        [ 1.8024e-02,  4.0449e-01, -2.9480e-01],\n",
       "                        [-1.0230e-01, -4.0876e-02,  4.6758e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3953e-02, -1.4663e-01,  3.7173e-01],\n",
       "                        [ 2.7627e-01,  1.3760e-01,  1.6290e-01],\n",
       "                        [-2.6357e-02, -1.3164e-01, -2.5004e-01]],\n",
       "              \n",
       "                       [[ 1.5716e-01, -6.5916e-01, -3.7163e-01],\n",
       "                        [-1.4906e-01, -3.3604e-01, -9.9113e-02],\n",
       "                        [ 1.2724e-01,  1.5649e-01, -6.1665e-02]],\n",
       "              \n",
       "                       [[-2.0052e-02,  1.7148e-01, -3.4569e-01],\n",
       "                        [ 4.4725e-01, -1.2255e-02,  4.0592e-01],\n",
       "                        [-1.6992e-01, -1.4607e-01, -3.2384e-01]],\n",
       "              \n",
       "                       [[-1.7028e-02, -8.5108e-02, -2.3798e-01],\n",
       "                        [ 2.8127e-01,  1.8218e-02,  2.9830e-01],\n",
       "                        [-1.0245e-01, -3.9497e-02,  2.7497e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8271e-02, -7.2140e-01,  3.2392e-02],\n",
       "                        [ 2.9607e-01, -1.0893e-01, -3.0054e-01],\n",
       "                        [-2.4524e-01, -3.4102e-01,  6.4828e-02]],\n",
       "              \n",
       "                       [[-1.5833e-01,  2.8716e-01, -2.8541e-01],\n",
       "                        [-8.1920e-02,  5.3344e-01, -8.9772e-02],\n",
       "                        [-2.3166e-01,  2.8033e-01, -2.1412e-01]],\n",
       "              \n",
       "                       [[-9.1274e-02,  5.6942e-02, -1.8451e-01],\n",
       "                        [-1.0216e-01,  7.0682e-02,  5.3959e-02],\n",
       "                        [ 3.2387e-01, -2.0344e-01, -4.7135e-02]],\n",
       "              \n",
       "                       [[ 1.5830e-02,  4.4492e-02,  1.4217e-01],\n",
       "                        [-1.3069e-02, -1.6149e-01, -1.3701e-02],\n",
       "                        [-1.9981e-01,  2.9199e-01,  3.8395e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2955e-01, -1.0186e-01,  7.6801e-02],\n",
       "                        [-8.6575e-02, -8.0612e-03, -1.5902e-01],\n",
       "                        [-2.8949e-04, -2.3332e-01,  2.2612e-01]],\n",
       "              \n",
       "                       [[ 3.0940e-02, -2.1828e-01,  4.1376e-01],\n",
       "                        [ 1.4290e-02, -3.3372e-02,  1.5831e-01],\n",
       "                        [ 2.5643e-02, -9.1558e-02,  3.4163e-01]],\n",
       "              \n",
       "                       [[ 8.4127e-02,  3.7897e-02, -1.5717e-01],\n",
       "                        [ 6.7579e-02,  3.5411e-01,  3.2907e-02],\n",
       "                        [-6.1220e-02,  4.9653e-01,  1.0497e-01]],\n",
       "              \n",
       "                       [[ 1.0379e-01, -2.9524e-01,  2.6511e-02],\n",
       "                        [-3.9713e-02, -5.0619e-01, -3.7104e-02],\n",
       "                        [-4.2020e-01,  5.8012e-01,  6.2754e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.3067e-01, -1.3824e-02, -2.5355e-01],\n",
       "                        [ 3.1014e-01,  1.0804e-02,  1.3980e-01],\n",
       "                        [-1.2415e-01,  4.2892e-02,  1.1416e-01]],\n",
       "              \n",
       "                       [[-2.8074e-01,  7.6132e-02,  3.3707e-01],\n",
       "                        [ 4.0284e-02, -2.8315e-01,  6.4632e-02],\n",
       "                        [ 1.1876e-01, -1.0156e-01, -7.2963e-02]],\n",
       "              \n",
       "                       [[ 3.2671e-01, -1.1268e-01,  2.0574e-02],\n",
       "                        [ 1.2063e-01,  2.8370e-02, -2.6460e-01],\n",
       "                        [-5.2230e-02,  3.3347e-02, -1.6008e-01]],\n",
       "              \n",
       "                       [[ 3.0438e-01, -2.1996e-01, -3.7970e-01],\n",
       "                        [-4.8888e-01, -1.0636e-01,  2.4557e-01],\n",
       "                        [ 4.3349e-02,  1.3737e-02,  5.5982e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5865e-01, -1.3829e-01, -3.8599e-02],\n",
       "                        [ 2.3240e-01, -2.6784e-01, -2.6056e-01],\n",
       "                        [ 3.3347e-01,  1.6459e-01, -9.9123e-02]],\n",
       "              \n",
       "                       [[-1.3240e-02, -2.4913e-01,  4.1011e-01],\n",
       "                        [-3.2280e-01,  4.6701e-01, -4.4934e-02],\n",
       "                        [-5.1787e-01, -2.1056e-01,  1.4919e-01]],\n",
       "              \n",
       "                       [[ 1.6178e-01, -9.8057e-02,  6.0526e-02],\n",
       "                        [-1.1812e-01,  1.3447e-01,  2.1761e-01],\n",
       "                        [-4.6781e-01, -6.2003e-02, -1.7766e-01]],\n",
       "              \n",
       "                       [[-1.6266e-01,  2.7354e-03, -2.3151e-01],\n",
       "                        [ 2.1946e-01, -4.2909e-01, -6.8603e-02],\n",
       "                        [ 4.2664e-01, -1.6004e-01, -6.8614e-02]]]], device='cuda:0')),\n",
       "             ('features_extractor.cnn.0.bias',\n",
       "              tensor([-0.0566, -0.0666,  0.0050,  0.0101, -0.0325, -0.1201, -0.0267, -0.0672,\n",
       "                      -0.0574, -0.0115,  0.0515, -0.0224, -0.0393, -0.0064, -0.0498,  0.0367,\n",
       "                       0.0978,  0.1039,  0.0021, -0.0343, -0.0318, -0.0280,  0.0324, -0.0059,\n",
       "                       0.0608,  0.0087, -0.0349,  0.0326,  0.0145, -0.0126, -0.0186,  0.0100],\n",
       "                     device='cuda:0')),\n",
       "             ('features_extractor.cnn.2.weight',\n",
       "              tensor([[[[ 0.0337,  0.0183,  0.1811],\n",
       "                        [-0.0092,  0.0704,  0.0781],\n",
       "                        [ 0.0079,  0.0235,  0.2508]],\n",
       "              \n",
       "                       [[-0.0559, -0.0903, -0.1553],\n",
       "                        [ 0.0236,  0.0402,  0.0951],\n",
       "                        [ 0.1265, -0.1126, -0.1120]],\n",
       "              \n",
       "                       [[-0.0063, -0.0839,  0.0146],\n",
       "                        [ 0.0568,  0.0494,  0.0495],\n",
       "                        [-0.1111, -0.1969, -0.1347]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1430,  0.0147, -0.0547],\n",
       "                        [ 0.0025, -0.1023,  0.1860],\n",
       "                        [ 0.0145, -0.0365, -0.0542]],\n",
       "              \n",
       "                       [[-0.0599, -0.0654, -0.0008],\n",
       "                        [ 0.0207,  0.1879,  0.0056],\n",
       "                        [-0.0875, -0.0323,  0.0365]],\n",
       "              \n",
       "                       [[ 0.2021,  0.0356,  0.0555],\n",
       "                        [ 0.1441, -0.0895,  0.0371],\n",
       "                        [-0.1306, -0.1064, -0.0320]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0295,  0.1417,  0.0898],\n",
       "                        [-0.0841, -0.0365,  0.0656],\n",
       "                        [-0.1357,  0.1170,  0.1063]],\n",
       "              \n",
       "                       [[ 0.1105, -0.0365,  0.0223],\n",
       "                        [-0.0618,  0.0518, -0.0784],\n",
       "                        [ 0.1527,  0.1740, -0.0630]],\n",
       "              \n",
       "                       [[ 0.1227, -0.1392, -0.0040],\n",
       "                        [ 0.0392, -0.0950,  0.1206],\n",
       "                        [-0.0319,  0.0154,  0.0485]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1858,  0.0093, -0.0078],\n",
       "                        [ 0.0195, -0.0297, -0.1388],\n",
       "                        [-0.0933, -0.0209,  0.0919]],\n",
       "              \n",
       "                       [[ 0.0456, -0.0209, -0.0961],\n",
       "                        [ 0.0440, -0.0379, -0.0509],\n",
       "                        [ 0.0703, -0.0644,  0.0500]],\n",
       "              \n",
       "                       [[ 0.1575,  0.1472, -0.1588],\n",
       "                        [ 0.0704, -0.0619,  0.0216],\n",
       "                        [-0.0397,  0.0828,  0.0385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0037,  0.0176, -0.2178],\n",
       "                        [-0.0295, -0.1379,  0.0542],\n",
       "                        [ 0.0287,  0.0869, -0.0711]],\n",
       "              \n",
       "                       [[ 0.0246,  0.0180, -0.0136],\n",
       "                        [ 0.0585, -0.0908,  0.0373],\n",
       "                        [-0.1708,  0.0041, -0.1778]],\n",
       "              \n",
       "                       [[ 0.0947,  0.0598,  0.0550],\n",
       "                        [-0.0396,  0.1413, -0.1427],\n",
       "                        [-0.1346, -0.0290, -0.0006]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0819, -0.0565, -0.0107],\n",
       "                        [ 0.0251,  0.0080, -0.1340],\n",
       "                        [-0.0806, -0.0358,  0.0328]],\n",
       "              \n",
       "                       [[-0.0176, -0.0219,  0.0098],\n",
       "                        [ 0.0743,  0.0146, -0.0068],\n",
       "                        [ 0.0307, -0.0660, -0.1691]],\n",
       "              \n",
       "                       [[-0.0751,  0.0300, -0.0542],\n",
       "                        [-0.1141,  0.0117, -0.0460],\n",
       "                        [ 0.1561,  0.0939,  0.1133]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0220, -0.0986,  0.0897],\n",
       "                        [ 0.0680, -0.1171,  0.0113],\n",
       "                        [-0.0018,  0.0855,  0.0803]],\n",
       "              \n",
       "                       [[ 0.0904,  0.0183, -0.1006],\n",
       "                        [-0.1004, -0.0417, -0.1845],\n",
       "                        [-0.1535,  0.0890, -0.0894]],\n",
       "              \n",
       "                       [[ 0.1373,  0.0621, -0.0894],\n",
       "                        [ 0.2271,  0.1095, -0.0319],\n",
       "                        [ 0.0152, -0.0245,  0.1569]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0120, -0.0119,  0.0167],\n",
       "                        [-0.0655,  0.0904,  0.0507],\n",
       "                        [-0.0890,  0.2800, -0.0387]],\n",
       "              \n",
       "                       [[-0.0526, -0.1061,  0.1017],\n",
       "                        [ 0.0505,  0.0431, -0.0106],\n",
       "                        [ 0.1109, -0.1559,  0.0986]],\n",
       "              \n",
       "                       [[ 0.1002,  0.1639,  0.0977],\n",
       "                        [-0.0913, -0.0571,  0.0487],\n",
       "                        [-0.1078,  0.1614, -0.0788]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1416,  0.0937,  0.0798],\n",
       "                        [ 0.0718,  0.0977, -0.0887],\n",
       "                        [-0.0445,  0.0350, -0.0309]],\n",
       "              \n",
       "                       [[ 0.1969, -0.0258, -0.0243],\n",
       "                        [ 0.2591,  0.0262,  0.0080],\n",
       "                        [-0.0006,  0.0793, -0.2098]],\n",
       "              \n",
       "                       [[ 0.0529, -0.0417,  0.0800],\n",
       "                        [-0.0687, -0.0148,  0.2967],\n",
       "                        [-0.1469, -0.2498, -0.0229]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1094,  0.0152, -0.0539],\n",
       "                        [-0.0680, -0.0788,  0.0701],\n",
       "                        [ 0.0526, -0.1560, -0.2047]],\n",
       "              \n",
       "                       [[ 0.0327, -0.0424, -0.0037],\n",
       "                        [-0.0473, -0.0575,  0.1007],\n",
       "                        [ 0.0497, -0.1394, -0.0099]],\n",
       "              \n",
       "                       [[-0.0807, -0.1619, -0.0035],\n",
       "                        [ 0.0386, -0.0241,  0.0321],\n",
       "                        [-0.1117,  0.0962, -0.1791]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0174, -0.0043, -0.0614],\n",
       "                        [-0.0582,  0.0048, -0.1357],\n",
       "                        [ 0.0407, -0.0188, -0.1285]],\n",
       "              \n",
       "                       [[ 0.1117, -0.0041, -0.1399],\n",
       "                        [ 0.0533, -0.1416, -0.1361],\n",
       "                        [-0.0427,  0.0032, -0.0008]],\n",
       "              \n",
       "                       [[ 0.0627,  0.0510,  0.0315],\n",
       "                        [ 0.1574,  0.1953, -0.1351],\n",
       "                        [ 0.0472, -0.0914,  0.0192]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2125, -0.0262, -0.0840],\n",
       "                        [-0.0027, -0.0503,  0.0810],\n",
       "                        [ 0.0658, -0.0355, -0.0023]],\n",
       "              \n",
       "                       [[-0.0149,  0.0386, -0.0299],\n",
       "                        [-0.0956, -0.1379, -0.0337],\n",
       "                        [ 0.0054,  0.1598, -0.0692]],\n",
       "              \n",
       "                       [[ 0.0698, -0.1232, -0.0237],\n",
       "                        [ 0.0924, -0.0492,  0.0697],\n",
       "                        [-0.0753, -0.0362,  0.0646]]]], device='cuda:0')),\n",
       "             ('features_extractor.cnn.2.bias',\n",
       "              tensor([-0.0390, -0.0034, -0.0113, -0.0361,  0.0085,  0.0049, -0.0228,  0.0194,\n",
       "                      -0.0314, -0.0193, -0.0153, -0.0270, -0.0255,  0.0063, -0.0083,  0.0100,\n",
       "                       0.0165, -0.0047, -0.0294, -0.0083,  0.0202, -0.0153,  0.0065, -0.0314,\n",
       "                       0.0038,  0.0038, -0.0122, -0.0127, -0.0490,  0.0145, -0.0177,  0.0108,\n",
       "                       0.0031, -0.0147, -0.0546, -0.0104,  0.0075, -0.0224, -0.0226, -0.0075,\n",
       "                      -0.0132, -0.0033, -0.0336, -0.0368,  0.0054, -0.0007, -0.0043, -0.0222,\n",
       "                      -0.0103, -0.0611, -0.0028, -0.0120, -0.0236, -0.0233, -0.0365,  0.0186,\n",
       "                      -0.0335,  0.0064, -0.0251, -0.0194, -0.0224, -0.0334, -0.0377, -0.0148],\n",
       "                     device='cuda:0')),\n",
       "             ('features_extractor.cnn.4.weight',\n",
       "              tensor([[[[-0.1014,  0.0709,  0.1082],\n",
       "                        [-0.0704,  0.0229, -0.0548],\n",
       "                        [ 0.0604,  0.0755, -0.1099]],\n",
       "              \n",
       "                       [[ 0.0352, -0.2052, -0.0431],\n",
       "                        [ 0.0014, -0.1739, -0.0260],\n",
       "                        [-0.0592,  0.1083,  0.0191]],\n",
       "              \n",
       "                       [[-0.1012,  0.0074,  0.1031],\n",
       "                        [-0.0348, -0.0550, -0.0482],\n",
       "                        [ 0.0439,  0.0012, -0.0179]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0070,  0.0207,  0.0602],\n",
       "                        [ 0.0391, -0.0656,  0.0200],\n",
       "                        [ 0.0378,  0.0211, -0.1084]],\n",
       "              \n",
       "                       [[-0.0429,  0.0146, -0.0985],\n",
       "                        [ 0.0302, -0.0878,  0.1199],\n",
       "                        [-0.1365,  0.1271, -0.0090]],\n",
       "              \n",
       "                       [[-0.1360,  0.1147, -0.0451],\n",
       "                        [-0.0211,  0.0499,  0.0696],\n",
       "                        [ 0.0633, -0.1438,  0.0214]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0525, -0.1044, -0.0197],\n",
       "                        [ 0.0397, -0.0160, -0.0297],\n",
       "                        [-0.0340,  0.0754,  0.0151]],\n",
       "              \n",
       "                       [[-0.0837,  0.0467,  0.0243],\n",
       "                        [ 0.0600,  0.0197, -0.0111],\n",
       "                        [-0.0211,  0.0185,  0.0020]],\n",
       "              \n",
       "                       [[ 0.0702,  0.0136,  0.0851],\n",
       "                        [-0.0559, -0.0383,  0.0509],\n",
       "                        [ 0.0301,  0.0863, -0.0579]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0008,  0.1314, -0.0715],\n",
       "                        [-0.0519, -0.0206,  0.0187],\n",
       "                        [-0.0610, -0.1474,  0.0442]],\n",
       "              \n",
       "                       [[-0.0570, -0.0038, -0.0652],\n",
       "                        [-0.1259,  0.0309, -0.1133],\n",
       "                        [ 0.0531,  0.0175, -0.0488]],\n",
       "              \n",
       "                       [[-0.0420, -0.1407,  0.0187],\n",
       "                        [ 0.0362,  0.0119,  0.1130],\n",
       "                        [ 0.1020, -0.0303,  0.0771]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0843,  0.0506, -0.0102],\n",
       "                        [-0.0309,  0.0596,  0.1865],\n",
       "                        [ 0.0695, -0.1693, -0.1030]],\n",
       "              \n",
       "                       [[ 0.0419,  0.0717,  0.1250],\n",
       "                        [-0.0795,  0.0079,  0.1064],\n",
       "                        [-0.0167, -0.0967, -0.1259]],\n",
       "              \n",
       "                       [[ 0.0243,  0.0092,  0.0335],\n",
       "                        [ 0.0913, -0.0200,  0.1210],\n",
       "                        [ 0.0838, -0.0482,  0.0845]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0013, -0.0548, -0.1030],\n",
       "                        [ 0.1146,  0.1135, -0.0269],\n",
       "                        [ 0.0268,  0.0550, -0.0531]],\n",
       "              \n",
       "                       [[ 0.0765, -0.0841,  0.0607],\n",
       "                        [ 0.0406,  0.0043, -0.0290],\n",
       "                        [-0.0238,  0.0344, -0.0343]],\n",
       "              \n",
       "                       [[-0.0306, -0.0158,  0.0538],\n",
       "                        [-0.0041,  0.0514,  0.0606],\n",
       "                        [ 0.0687, -0.0608,  0.0098]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0852, -0.0107, -0.0530],\n",
       "                        [ 0.0538, -0.0349, -0.0862],\n",
       "                        [ 0.0586,  0.0060, -0.1364]],\n",
       "              \n",
       "                       [[ 0.0105, -0.0361, -0.0264],\n",
       "                        [ 0.1033, -0.0619, -0.0171],\n",
       "                        [-0.0026,  0.0930, -0.0463]],\n",
       "              \n",
       "                       [[-0.0930, -0.0707,  0.0251],\n",
       "                        [ 0.0259, -0.0004,  0.2019],\n",
       "                        [-0.0139, -0.0725, -0.1661]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0039,  0.0044,  0.0718],\n",
       "                        [ 0.1228, -0.0095,  0.0568],\n",
       "                        [-0.0977, -0.0113,  0.0441]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0876,  0.0224],\n",
       "                        [ 0.0183, -0.0459, -0.0793],\n",
       "                        [-0.0716, -0.0030, -0.0981]],\n",
       "              \n",
       "                       [[-0.0205,  0.0779, -0.1334],\n",
       "                        [-0.1343,  0.0562,  0.0465],\n",
       "                        [ 0.0765, -0.0930, -0.0822]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0020, -0.1609, -0.0816],\n",
       "                        [-0.0171, -0.0815, -0.0878],\n",
       "                        [-0.0384,  0.0751,  0.0293]],\n",
       "              \n",
       "                       [[ 0.0061, -0.0220, -0.0833],\n",
       "                        [ 0.0124, -0.0083,  0.0255],\n",
       "                        [ 0.0746, -0.0895,  0.0211]],\n",
       "              \n",
       "                       [[-0.1771, -0.1180,  0.0226],\n",
       "                        [ 0.0984, -0.0210, -0.0414],\n",
       "                        [ 0.1382,  0.0387,  0.0620]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0797,  0.0699,  0.0314],\n",
       "                        [-0.0514, -0.1527, -0.0059],\n",
       "                        [-0.0050, -0.0193,  0.0991]],\n",
       "              \n",
       "                       [[-0.1514,  0.0452, -0.0108],\n",
       "                        [-0.0435, -0.1535, -0.0243],\n",
       "                        [ 0.0623, -0.0156, -0.0899]],\n",
       "              \n",
       "                       [[ 0.0136,  0.0049,  0.1030],\n",
       "                        [-0.0593, -0.0197, -0.0076],\n",
       "                        [-0.0189, -0.0357, -0.0282]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0250, -0.0896,  0.1386],\n",
       "                        [-0.0635, -0.0235,  0.0971],\n",
       "                        [-0.0404,  0.0862, -0.0077]],\n",
       "              \n",
       "                       [[-0.0196,  0.0070, -0.0055],\n",
       "                        [-0.0389, -0.1478, -0.0312],\n",
       "                        [ 0.0856,  0.0393, -0.0485]],\n",
       "              \n",
       "                       [[-0.0351,  0.0242, -0.0526],\n",
       "                        [-0.0668, -0.0827,  0.0873],\n",
       "                        [ 0.0886, -0.0227, -0.1589]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1103, -0.0872,  0.0069],\n",
       "                        [-0.0348,  0.0992,  0.0197],\n",
       "                        [-0.0116,  0.0288,  0.0328]],\n",
       "              \n",
       "                       [[-0.0918,  0.0735,  0.0194],\n",
       "                        [-0.1080,  0.0114, -0.0639],\n",
       "                        [-0.0689,  0.0118,  0.0921]],\n",
       "              \n",
       "                       [[ 0.0896, -0.0524,  0.0459],\n",
       "                        [-0.0676, -0.0987,  0.0727],\n",
       "                        [ 0.0799, -0.2089,  0.0608]]]], device='cuda:0')),\n",
       "             ('features_extractor.cnn.4.bias',\n",
       "              tensor([-0.0527, -0.0421, -0.0194, -0.0534, -0.0266, -0.0121, -0.0038, -0.0021,\n",
       "                      -0.0285, -0.0684, -0.0531, -0.0151, -0.0482, -0.0270, -0.0442, -0.0434,\n",
       "                      -0.0313, -0.0371, -0.0373, -0.0229, -0.0440, -0.0215, -0.0519, -0.0588,\n",
       "                      -0.0308, -0.0252, -0.0491, -0.0177, -0.0092, -0.0191, -0.0484, -0.0235,\n",
       "                      -0.0379, -0.0287, -0.0316, -0.0126, -0.0297, -0.0215, -0.0215, -0.0448,\n",
       "                      -0.0187, -0.0510, -0.0096, -0.0514, -0.0251, -0.0464, -0.0250, -0.0309,\n",
       "                      -0.0291, -0.0448, -0.0306, -0.0332, -0.0095, -0.0130, -0.0548, -0.0416,\n",
       "                      -0.0410, -0.0265, -0.0136, -0.0418,  0.0009, -0.0626, -0.0153, -0.0527],\n",
       "                     device='cuda:0')),\n",
       "             ('features_extractor.linear.0.weight',\n",
       "              tensor([[-0.0270, -0.0135, -0.0357,  ..., -0.0760, -0.0304,  0.0015],\n",
       "                      [-0.0007, -0.0621,  0.0162,  ..., -0.0310,  0.0050, -0.0013],\n",
       "                      [-0.0178,  0.0220,  0.0382,  ...,  0.0995, -0.0172,  0.0078],\n",
       "                      ...,\n",
       "                      [-0.0200, -0.0426, -0.1067,  ..., -0.0226, -0.0147, -0.0272],\n",
       "                      [-0.0199,  0.1090, -0.0471,  ...,  0.0651,  0.0328, -0.0295],\n",
       "                      [ 0.0558, -0.0437,  0.0408,  ...,  0.0242,  0.0245,  0.0446]],\n",
       "                     device='cuda:0')),\n",
       "             ('features_extractor.linear.0.bias',\n",
       "              tensor([-5.6608e-03,  6.0292e-03, -9.1965e-03, -1.8568e-02, -1.1593e-02,\n",
       "                       9.6789e-03, -1.5750e-02, -2.1523e-02, -1.4694e-02,  1.8843e-03,\n",
       "                      -1.0284e-02, -1.3603e-02, -1.9655e-02,  2.5110e-03, -2.3079e-02,\n",
       "                      -2.5503e-03,  2.5569e-02, -1.5688e-02, -2.0103e-02,  5.9138e-03,\n",
       "                      -2.3874e-03,  1.0382e-02, -1.2352e-03, -6.3961e-03, -3.2044e-03,\n",
       "                       2.0733e-02, -7.9140e-03,  2.1906e-03, -3.3774e-04, -1.2366e-02,\n",
       "                      -8.4314e-03,  6.4223e-03, -1.3893e-02, -1.9243e-02, -9.8721e-03,\n",
       "                      -1.3911e-02, -1.6314e-02,  3.9481e-03,  6.8481e-03, -7.2767e-04,\n",
       "                      -3.5789e-03,  1.7647e-02,  5.1980e-03, -1.5433e-02,  2.0342e-03,\n",
       "                      -3.8536e-03,  4.9479e-03,  1.1522e-02,  3.1461e-03, -2.1221e-02,\n",
       "                      -1.8123e-02,  2.9962e-03, -2.4504e-02, -1.3904e-02, -1.9924e-02,\n",
       "                      -6.5181e-03, -1.1136e-02, -8.0146e-03,  1.1183e-03,  5.8428e-03,\n",
       "                      -6.7766e-03, -1.8218e-02,  2.0625e-02, -4.1976e-03,  9.8920e-03,\n",
       "                       2.7103e-03,  5.1831e-03, -1.0430e-02,  4.0037e-05, -2.4779e-02,\n",
       "                      -2.1182e-02, -4.8570e-04, -1.4988e-02,  4.2176e-04,  1.6978e-02,\n",
       "                      -1.7201e-02, -9.6121e-03, -1.7206e-02, -3.7706e-03, -8.1554e-03,\n",
       "                      -8.9120e-03, -4.4588e-03, -2.7373e-02,  2.3373e-03, -4.0309e-03,\n",
       "                       5.0599e-03, -3.3017e-02, -1.5682e-02, -3.8791e-03, -1.3667e-02,\n",
       "                      -1.1874e-02, -1.3697e-02, -4.7328e-03, -8.9924e-03, -1.7318e-02,\n",
       "                      -7.3571e-03, -5.0703e-03,  1.3889e-02, -1.2070e-02, -1.8983e-02,\n",
       "                      -3.0111e-03, -7.7595e-03,  1.6896e-02, -1.3754e-02,  6.6683e-03,\n",
       "                      -4.5552e-03, -3.7477e-04, -1.2147e-02, -3.4943e-03, -1.3093e-02,\n",
       "                       5.1952e-03,  1.8795e-02,  3.8898e-03, -2.4092e-02,  2.5640e-05,\n",
       "                      -1.4565e-02, -1.4779e-02, -1.6007e-02, -4.0413e-03, -2.6391e-02,\n",
       "                      -9.2754e-03, -6.6702e-03, -1.9132e-02, -1.9438e-02, -1.8338e-02,\n",
       "                      -3.7500e-03,  7.5928e-03, -1.0519e-02, -1.1963e-03,  5.0987e-03,\n",
       "                      -5.1751e-03, -1.9795e-03, -1.2211e-02, -1.1549e-02, -1.8722e-02,\n",
       "                      -5.7123e-03, -3.2459e-02, -7.2956e-03, -2.8802e-02,  3.6083e-03,\n",
       "                       4.6870e-05, -7.6378e-03, -8.7449e-03, -1.4517e-03, -4.2058e-03,\n",
       "                      -1.1429e-02, -1.9129e-02, -8.3722e-03, -1.4606e-02,  1.8631e-03,\n",
       "                      -1.6571e-02,  6.3678e-03, -2.3493e-02, -1.0677e-02, -9.0645e-03,\n",
       "                      -1.2493e-02, -1.7621e-02,  7.2907e-04, -1.5983e-02,  1.2657e-02,\n",
       "                      -1.4844e-02, -3.4709e-02,  3.4632e-03,  5.9516e-03, -1.3603e-02,\n",
       "                      -7.0841e-04, -1.5203e-02, -5.4989e-03, -6.8727e-03, -6.8712e-03,\n",
       "                      -6.7857e-03, -1.2739e-02, -9.4579e-04, -5.7958e-03, -2.0469e-02,\n",
       "                      -4.8724e-03, -1.1285e-02, -1.0248e-02,  1.5599e-02, -1.2677e-02,\n",
       "                      -1.2914e-02,  7.9928e-03, -1.6114e-02, -1.2004e-02, -9.0505e-03,\n",
       "                      -1.7559e-02,  1.1923e-02,  7.7604e-03, -4.7151e-04, -8.8959e-03,\n",
       "                       6.0266e-04, -1.1305e-02, -1.7632e-02, -9.8618e-04, -3.2808e-04,\n",
       "                      -9.2304e-03, -5.8386e-03, -1.2238e-02, -1.0198e-02, -1.9077e-03,\n",
       "                      -1.6158e-02, -1.6521e-02,  4.7318e-03,  1.0410e-02, -2.2033e-02,\n",
       "                       1.1737e-03, -1.2583e-02, -1.3367e-02,  1.6993e-03, -1.0574e-02,\n",
       "                      -3.0460e-03, -8.5488e-03, -1.0641e-02, -2.5659e-02, -1.0535e-02,\n",
       "                      -1.0917e-02, -1.0462e-02, -4.1459e-03, -1.4119e-02, -1.1132e-02,\n",
       "                      -1.0320e-02, -1.4184e-02, -1.0302e-02, -8.1392e-04, -2.7057e-03,\n",
       "                      -4.2100e-03,  1.9071e-02, -1.4972e-02,  3.7827e-03, -8.7062e-03,\n",
       "                       6.6713e-03, -9.7732e-03,  7.0135e-03,  6.3468e-03, -8.1618e-03,\n",
       "                       1.1720e-02, -1.4238e-02, -1.1268e-02,  1.4706e-02,  4.6204e-03,\n",
       "                      -9.1095e-04,  2.2036e-02, -1.6451e-02, -1.4447e-02, -1.8699e-02,\n",
       "                       9.3533e-03, -5.2393e-03,  1.2488e-02, -7.6009e-03, -9.2387e-04,\n",
       "                      -1.9480e-03, -1.4901e-02, -1.6314e-02,  5.9689e-03, -5.6877e-03,\n",
       "                       9.1546e-03], device='cuda:0')),\n",
       "             ('pi_features_extractor.cnn.0.weight',\n",
       "              tensor([[[[ 5.8862e-02,  3.7363e-01, -1.3097e-01],\n",
       "                        [-1.3117e-01, -1.4281e-01,  1.0642e-02],\n",
       "                        [-3.2974e-01,  5.1945e-02, -1.7016e-01]],\n",
       "              \n",
       "                       [[-1.6550e-01,  2.2424e-01,  6.2481e-01],\n",
       "                        [ 1.1638e-01,  6.0274e-02,  2.3141e-01],\n",
       "                        [-1.1957e-01, -3.1702e-01,  2.2510e-01]],\n",
       "              \n",
       "                       [[-1.1080e-01,  3.4992e-01, -2.3739e-01],\n",
       "                        [-8.8834e-02,  2.8504e-01,  1.4751e-01],\n",
       "                        [ 1.0280e-01, -2.0961e-01, -1.3982e-01]],\n",
       "              \n",
       "                       [[-3.6928e-01,  2.0983e-01, -2.5590e-01],\n",
       "                        [ 1.8024e-02,  4.0449e-01, -2.9480e-01],\n",
       "                        [-1.0230e-01, -4.0876e-02,  4.6758e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3953e-02, -1.4663e-01,  3.7173e-01],\n",
       "                        [ 2.7627e-01,  1.3760e-01,  1.6290e-01],\n",
       "                        [-2.6357e-02, -1.3164e-01, -2.5004e-01]],\n",
       "              \n",
       "                       [[ 1.5716e-01, -6.5916e-01, -3.7163e-01],\n",
       "                        [-1.4906e-01, -3.3604e-01, -9.9113e-02],\n",
       "                        [ 1.2724e-01,  1.5649e-01, -6.1665e-02]],\n",
       "              \n",
       "                       [[-2.0052e-02,  1.7148e-01, -3.4569e-01],\n",
       "                        [ 4.4725e-01, -1.2255e-02,  4.0592e-01],\n",
       "                        [-1.6992e-01, -1.4607e-01, -3.2384e-01]],\n",
       "              \n",
       "                       [[-1.7028e-02, -8.5108e-02, -2.3798e-01],\n",
       "                        [ 2.8127e-01,  1.8218e-02,  2.9830e-01],\n",
       "                        [-1.0245e-01, -3.9497e-02,  2.7497e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8271e-02, -7.2140e-01,  3.2392e-02],\n",
       "                        [ 2.9607e-01, -1.0893e-01, -3.0054e-01],\n",
       "                        [-2.4524e-01, -3.4102e-01,  6.4828e-02]],\n",
       "              \n",
       "                       [[-1.5833e-01,  2.8716e-01, -2.8541e-01],\n",
       "                        [-8.1920e-02,  5.3344e-01, -8.9772e-02],\n",
       "                        [-2.3166e-01,  2.8033e-01, -2.1412e-01]],\n",
       "              \n",
       "                       [[-9.1274e-02,  5.6942e-02, -1.8451e-01],\n",
       "                        [-1.0216e-01,  7.0682e-02,  5.3959e-02],\n",
       "                        [ 3.2387e-01, -2.0344e-01, -4.7135e-02]],\n",
       "              \n",
       "                       [[ 1.5830e-02,  4.4492e-02,  1.4217e-01],\n",
       "                        [-1.3069e-02, -1.6149e-01, -1.3701e-02],\n",
       "                        [-1.9981e-01,  2.9199e-01,  3.8395e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2955e-01, -1.0186e-01,  7.6801e-02],\n",
       "                        [-8.6575e-02, -8.0612e-03, -1.5902e-01],\n",
       "                        [-2.8949e-04, -2.3332e-01,  2.2612e-01]],\n",
       "              \n",
       "                       [[ 3.0940e-02, -2.1828e-01,  4.1376e-01],\n",
       "                        [ 1.4290e-02, -3.3372e-02,  1.5831e-01],\n",
       "                        [ 2.5643e-02, -9.1558e-02,  3.4163e-01]],\n",
       "              \n",
       "                       [[ 8.4127e-02,  3.7897e-02, -1.5717e-01],\n",
       "                        [ 6.7579e-02,  3.5411e-01,  3.2907e-02],\n",
       "                        [-6.1220e-02,  4.9653e-01,  1.0497e-01]],\n",
       "              \n",
       "                       [[ 1.0379e-01, -2.9524e-01,  2.6511e-02],\n",
       "                        [-3.9713e-02, -5.0619e-01, -3.7104e-02],\n",
       "                        [-4.2020e-01,  5.8012e-01,  6.2754e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.3067e-01, -1.3824e-02, -2.5355e-01],\n",
       "                        [ 3.1014e-01,  1.0804e-02,  1.3980e-01],\n",
       "                        [-1.2415e-01,  4.2892e-02,  1.1416e-01]],\n",
       "              \n",
       "                       [[-2.8074e-01,  7.6132e-02,  3.3707e-01],\n",
       "                        [ 4.0284e-02, -2.8315e-01,  6.4632e-02],\n",
       "                        [ 1.1876e-01, -1.0156e-01, -7.2963e-02]],\n",
       "              \n",
       "                       [[ 3.2671e-01, -1.1268e-01,  2.0574e-02],\n",
       "                        [ 1.2063e-01,  2.8370e-02, -2.6460e-01],\n",
       "                        [-5.2230e-02,  3.3347e-02, -1.6008e-01]],\n",
       "              \n",
       "                       [[ 3.0438e-01, -2.1996e-01, -3.7970e-01],\n",
       "                        [-4.8888e-01, -1.0636e-01,  2.4557e-01],\n",
       "                        [ 4.3349e-02,  1.3737e-02,  5.5982e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5865e-01, -1.3829e-01, -3.8599e-02],\n",
       "                        [ 2.3240e-01, -2.6784e-01, -2.6056e-01],\n",
       "                        [ 3.3347e-01,  1.6459e-01, -9.9123e-02]],\n",
       "              \n",
       "                       [[-1.3240e-02, -2.4913e-01,  4.1011e-01],\n",
       "                        [-3.2280e-01,  4.6701e-01, -4.4934e-02],\n",
       "                        [-5.1787e-01, -2.1056e-01,  1.4919e-01]],\n",
       "              \n",
       "                       [[ 1.6178e-01, -9.8057e-02,  6.0526e-02],\n",
       "                        [-1.1812e-01,  1.3447e-01,  2.1761e-01],\n",
       "                        [-4.6781e-01, -6.2003e-02, -1.7766e-01]],\n",
       "              \n",
       "                       [[-1.6266e-01,  2.7354e-03, -2.3151e-01],\n",
       "                        [ 2.1946e-01, -4.2909e-01, -6.8603e-02],\n",
       "                        [ 4.2664e-01, -1.6004e-01, -6.8614e-02]]]], device='cuda:0')),\n",
       "             ('pi_features_extractor.cnn.0.bias',\n",
       "              tensor([-0.0566, -0.0666,  0.0050,  0.0101, -0.0325, -0.1201, -0.0267, -0.0672,\n",
       "                      -0.0574, -0.0115,  0.0515, -0.0224, -0.0393, -0.0064, -0.0498,  0.0367,\n",
       "                       0.0978,  0.1039,  0.0021, -0.0343, -0.0318, -0.0280,  0.0324, -0.0059,\n",
       "                       0.0608,  0.0087, -0.0349,  0.0326,  0.0145, -0.0126, -0.0186,  0.0100],\n",
       "                     device='cuda:0')),\n",
       "             ('pi_features_extractor.cnn.2.weight',\n",
       "              tensor([[[[ 0.0337,  0.0183,  0.1811],\n",
       "                        [-0.0092,  0.0704,  0.0781],\n",
       "                        [ 0.0079,  0.0235,  0.2508]],\n",
       "              \n",
       "                       [[-0.0559, -0.0903, -0.1553],\n",
       "                        [ 0.0236,  0.0402,  0.0951],\n",
       "                        [ 0.1265, -0.1126, -0.1120]],\n",
       "              \n",
       "                       [[-0.0063, -0.0839,  0.0146],\n",
       "                        [ 0.0568,  0.0494,  0.0495],\n",
       "                        [-0.1111, -0.1969, -0.1347]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1430,  0.0147, -0.0547],\n",
       "                        [ 0.0025, -0.1023,  0.1860],\n",
       "                        [ 0.0145, -0.0365, -0.0542]],\n",
       "              \n",
       "                       [[-0.0599, -0.0654, -0.0008],\n",
       "                        [ 0.0207,  0.1879,  0.0056],\n",
       "                        [-0.0875, -0.0323,  0.0365]],\n",
       "              \n",
       "                       [[ 0.2021,  0.0356,  0.0555],\n",
       "                        [ 0.1441, -0.0895,  0.0371],\n",
       "                        [-0.1306, -0.1064, -0.0320]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0295,  0.1417,  0.0898],\n",
       "                        [-0.0841, -0.0365,  0.0656],\n",
       "                        [-0.1357,  0.1170,  0.1063]],\n",
       "              \n",
       "                       [[ 0.1105, -0.0365,  0.0223],\n",
       "                        [-0.0618,  0.0518, -0.0784],\n",
       "                        [ 0.1527,  0.1740, -0.0630]],\n",
       "              \n",
       "                       [[ 0.1227, -0.1392, -0.0040],\n",
       "                        [ 0.0392, -0.0950,  0.1206],\n",
       "                        [-0.0319,  0.0154,  0.0485]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1858,  0.0093, -0.0078],\n",
       "                        [ 0.0195, -0.0297, -0.1388],\n",
       "                        [-0.0933, -0.0209,  0.0919]],\n",
       "              \n",
       "                       [[ 0.0456, -0.0209, -0.0961],\n",
       "                        [ 0.0440, -0.0379, -0.0509],\n",
       "                        [ 0.0703, -0.0644,  0.0500]],\n",
       "              \n",
       "                       [[ 0.1575,  0.1472, -0.1588],\n",
       "                        [ 0.0704, -0.0619,  0.0216],\n",
       "                        [-0.0397,  0.0828,  0.0385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0037,  0.0176, -0.2178],\n",
       "                        [-0.0295, -0.1379,  0.0542],\n",
       "                        [ 0.0287,  0.0869, -0.0711]],\n",
       "              \n",
       "                       [[ 0.0246,  0.0180, -0.0136],\n",
       "                        [ 0.0585, -0.0908,  0.0373],\n",
       "                        [-0.1708,  0.0041, -0.1778]],\n",
       "              \n",
       "                       [[ 0.0947,  0.0598,  0.0550],\n",
       "                        [-0.0396,  0.1413, -0.1427],\n",
       "                        [-0.1346, -0.0290, -0.0006]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0819, -0.0565, -0.0107],\n",
       "                        [ 0.0251,  0.0080, -0.1340],\n",
       "                        [-0.0806, -0.0358,  0.0328]],\n",
       "              \n",
       "                       [[-0.0176, -0.0219,  0.0098],\n",
       "                        [ 0.0743,  0.0146, -0.0068],\n",
       "                        [ 0.0307, -0.0660, -0.1691]],\n",
       "              \n",
       "                       [[-0.0751,  0.0300, -0.0542],\n",
       "                        [-0.1141,  0.0117, -0.0460],\n",
       "                        [ 0.1561,  0.0939,  0.1133]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0220, -0.0986,  0.0897],\n",
       "                        [ 0.0680, -0.1171,  0.0113],\n",
       "                        [-0.0018,  0.0855,  0.0803]],\n",
       "              \n",
       "                       [[ 0.0904,  0.0183, -0.1006],\n",
       "                        [-0.1004, -0.0417, -0.1845],\n",
       "                        [-0.1535,  0.0890, -0.0894]],\n",
       "              \n",
       "                       [[ 0.1373,  0.0621, -0.0894],\n",
       "                        [ 0.2271,  0.1095, -0.0319],\n",
       "                        [ 0.0152, -0.0245,  0.1569]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0120, -0.0119,  0.0167],\n",
       "                        [-0.0655,  0.0904,  0.0507],\n",
       "                        [-0.0890,  0.2800, -0.0387]],\n",
       "              \n",
       "                       [[-0.0526, -0.1061,  0.1017],\n",
       "                        [ 0.0505,  0.0431, -0.0106],\n",
       "                        [ 0.1109, -0.1559,  0.0986]],\n",
       "              \n",
       "                       [[ 0.1002,  0.1639,  0.0977],\n",
       "                        [-0.0913, -0.0571,  0.0487],\n",
       "                        [-0.1078,  0.1614, -0.0788]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1416,  0.0937,  0.0798],\n",
       "                        [ 0.0718,  0.0977, -0.0887],\n",
       "                        [-0.0445,  0.0350, -0.0309]],\n",
       "              \n",
       "                       [[ 0.1969, -0.0258, -0.0243],\n",
       "                        [ 0.2591,  0.0262,  0.0080],\n",
       "                        [-0.0006,  0.0793, -0.2098]],\n",
       "              \n",
       "                       [[ 0.0529, -0.0417,  0.0800],\n",
       "                        [-0.0687, -0.0148,  0.2967],\n",
       "                        [-0.1469, -0.2498, -0.0229]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1094,  0.0152, -0.0539],\n",
       "                        [-0.0680, -0.0788,  0.0701],\n",
       "                        [ 0.0526, -0.1560, -0.2047]],\n",
       "              \n",
       "                       [[ 0.0327, -0.0424, -0.0037],\n",
       "                        [-0.0473, -0.0575,  0.1007],\n",
       "                        [ 0.0497, -0.1394, -0.0099]],\n",
       "              \n",
       "                       [[-0.0807, -0.1619, -0.0035],\n",
       "                        [ 0.0386, -0.0241,  0.0321],\n",
       "                        [-0.1117,  0.0962, -0.1791]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0174, -0.0043, -0.0614],\n",
       "                        [-0.0582,  0.0048, -0.1357],\n",
       "                        [ 0.0407, -0.0188, -0.1285]],\n",
       "              \n",
       "                       [[ 0.1117, -0.0041, -0.1399],\n",
       "                        [ 0.0533, -0.1416, -0.1361],\n",
       "                        [-0.0427,  0.0032, -0.0008]],\n",
       "              \n",
       "                       [[ 0.0627,  0.0510,  0.0315],\n",
       "                        [ 0.1574,  0.1953, -0.1351],\n",
       "                        [ 0.0472, -0.0914,  0.0192]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2125, -0.0262, -0.0840],\n",
       "                        [-0.0027, -0.0503,  0.0810],\n",
       "                        [ 0.0658, -0.0355, -0.0023]],\n",
       "              \n",
       "                       [[-0.0149,  0.0386, -0.0299],\n",
       "                        [-0.0956, -0.1379, -0.0337],\n",
       "                        [ 0.0054,  0.1598, -0.0692]],\n",
       "              \n",
       "                       [[ 0.0698, -0.1232, -0.0237],\n",
       "                        [ 0.0924, -0.0492,  0.0697],\n",
       "                        [-0.0753, -0.0362,  0.0646]]]], device='cuda:0')),\n",
       "             ('pi_features_extractor.cnn.2.bias',\n",
       "              tensor([-0.0390, -0.0034, -0.0113, -0.0361,  0.0085,  0.0049, -0.0228,  0.0194,\n",
       "                      -0.0314, -0.0193, -0.0153, -0.0270, -0.0255,  0.0063, -0.0083,  0.0100,\n",
       "                       0.0165, -0.0047, -0.0294, -0.0083,  0.0202, -0.0153,  0.0065, -0.0314,\n",
       "                       0.0038,  0.0038, -0.0122, -0.0127, -0.0490,  0.0145, -0.0177,  0.0108,\n",
       "                       0.0031, -0.0147, -0.0546, -0.0104,  0.0075, -0.0224, -0.0226, -0.0075,\n",
       "                      -0.0132, -0.0033, -0.0336, -0.0368,  0.0054, -0.0007, -0.0043, -0.0222,\n",
       "                      -0.0103, -0.0611, -0.0028, -0.0120, -0.0236, -0.0233, -0.0365,  0.0186,\n",
       "                      -0.0335,  0.0064, -0.0251, -0.0194, -0.0224, -0.0334, -0.0377, -0.0148],\n",
       "                     device='cuda:0')),\n",
       "             ('pi_features_extractor.cnn.4.weight',\n",
       "              tensor([[[[-0.1014,  0.0709,  0.1082],\n",
       "                        [-0.0704,  0.0229, -0.0548],\n",
       "                        [ 0.0604,  0.0755, -0.1099]],\n",
       "              \n",
       "                       [[ 0.0352, -0.2052, -0.0431],\n",
       "                        [ 0.0014, -0.1739, -0.0260],\n",
       "                        [-0.0592,  0.1083,  0.0191]],\n",
       "              \n",
       "                       [[-0.1012,  0.0074,  0.1031],\n",
       "                        [-0.0348, -0.0550, -0.0482],\n",
       "                        [ 0.0439,  0.0012, -0.0179]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0070,  0.0207,  0.0602],\n",
       "                        [ 0.0391, -0.0656,  0.0200],\n",
       "                        [ 0.0378,  0.0211, -0.1084]],\n",
       "              \n",
       "                       [[-0.0429,  0.0146, -0.0985],\n",
       "                        [ 0.0302, -0.0878,  0.1199],\n",
       "                        [-0.1365,  0.1271, -0.0090]],\n",
       "              \n",
       "                       [[-0.1360,  0.1147, -0.0451],\n",
       "                        [-0.0211,  0.0499,  0.0696],\n",
       "                        [ 0.0633, -0.1438,  0.0214]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0525, -0.1044, -0.0197],\n",
       "                        [ 0.0397, -0.0160, -0.0297],\n",
       "                        [-0.0340,  0.0754,  0.0151]],\n",
       "              \n",
       "                       [[-0.0837,  0.0467,  0.0243],\n",
       "                        [ 0.0600,  0.0197, -0.0111],\n",
       "                        [-0.0211,  0.0185,  0.0020]],\n",
       "              \n",
       "                       [[ 0.0702,  0.0136,  0.0851],\n",
       "                        [-0.0559, -0.0383,  0.0509],\n",
       "                        [ 0.0301,  0.0863, -0.0579]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0008,  0.1314, -0.0715],\n",
       "                        [-0.0519, -0.0206,  0.0187],\n",
       "                        [-0.0610, -0.1474,  0.0442]],\n",
       "              \n",
       "                       [[-0.0570, -0.0038, -0.0652],\n",
       "                        [-0.1259,  0.0309, -0.1133],\n",
       "                        [ 0.0531,  0.0175, -0.0488]],\n",
       "              \n",
       "                       [[-0.0420, -0.1407,  0.0187],\n",
       "                        [ 0.0362,  0.0119,  0.1130],\n",
       "                        [ 0.1020, -0.0303,  0.0771]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0843,  0.0506, -0.0102],\n",
       "                        [-0.0309,  0.0596,  0.1865],\n",
       "                        [ 0.0695, -0.1693, -0.1030]],\n",
       "              \n",
       "                       [[ 0.0419,  0.0717,  0.1250],\n",
       "                        [-0.0795,  0.0079,  0.1064],\n",
       "                        [-0.0167, -0.0967, -0.1259]],\n",
       "              \n",
       "                       [[ 0.0243,  0.0092,  0.0335],\n",
       "                        [ 0.0913, -0.0200,  0.1210],\n",
       "                        [ 0.0838, -0.0482,  0.0845]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0013, -0.0548, -0.1030],\n",
       "                        [ 0.1146,  0.1135, -0.0269],\n",
       "                        [ 0.0268,  0.0550, -0.0531]],\n",
       "              \n",
       "                       [[ 0.0765, -0.0841,  0.0607],\n",
       "                        [ 0.0406,  0.0043, -0.0290],\n",
       "                        [-0.0238,  0.0344, -0.0343]],\n",
       "              \n",
       "                       [[-0.0306, -0.0158,  0.0538],\n",
       "                        [-0.0041,  0.0514,  0.0606],\n",
       "                        [ 0.0687, -0.0608,  0.0098]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0852, -0.0107, -0.0530],\n",
       "                        [ 0.0538, -0.0349, -0.0862],\n",
       "                        [ 0.0586,  0.0060, -0.1364]],\n",
       "              \n",
       "                       [[ 0.0105, -0.0361, -0.0264],\n",
       "                        [ 0.1033, -0.0619, -0.0171],\n",
       "                        [-0.0026,  0.0930, -0.0463]],\n",
       "              \n",
       "                       [[-0.0930, -0.0707,  0.0251],\n",
       "                        [ 0.0259, -0.0004,  0.2019],\n",
       "                        [-0.0139, -0.0725, -0.1661]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0039,  0.0044,  0.0718],\n",
       "                        [ 0.1228, -0.0095,  0.0568],\n",
       "                        [-0.0977, -0.0113,  0.0441]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0876,  0.0224],\n",
       "                        [ 0.0183, -0.0459, -0.0793],\n",
       "                        [-0.0716, -0.0030, -0.0981]],\n",
       "              \n",
       "                       [[-0.0205,  0.0779, -0.1334],\n",
       "                        [-0.1343,  0.0562,  0.0465],\n",
       "                        [ 0.0765, -0.0930, -0.0822]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0020, -0.1609, -0.0816],\n",
       "                        [-0.0171, -0.0815, -0.0878],\n",
       "                        [-0.0384,  0.0751,  0.0293]],\n",
       "              \n",
       "                       [[ 0.0061, -0.0220, -0.0833],\n",
       "                        [ 0.0124, -0.0083,  0.0255],\n",
       "                        [ 0.0746, -0.0895,  0.0211]],\n",
       "              \n",
       "                       [[-0.1771, -0.1180,  0.0226],\n",
       "                        [ 0.0984, -0.0210, -0.0414],\n",
       "                        [ 0.1382,  0.0387,  0.0620]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0797,  0.0699,  0.0314],\n",
       "                        [-0.0514, -0.1527, -0.0059],\n",
       "                        [-0.0050, -0.0193,  0.0991]],\n",
       "              \n",
       "                       [[-0.1514,  0.0452, -0.0108],\n",
       "                        [-0.0435, -0.1535, -0.0243],\n",
       "                        [ 0.0623, -0.0156, -0.0899]],\n",
       "              \n",
       "                       [[ 0.0136,  0.0049,  0.1030],\n",
       "                        [-0.0593, -0.0197, -0.0076],\n",
       "                        [-0.0189, -0.0357, -0.0282]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0250, -0.0896,  0.1386],\n",
       "                        [-0.0635, -0.0235,  0.0971],\n",
       "                        [-0.0404,  0.0862, -0.0077]],\n",
       "              \n",
       "                       [[-0.0196,  0.0070, -0.0055],\n",
       "                        [-0.0389, -0.1478, -0.0312],\n",
       "                        [ 0.0856,  0.0393, -0.0485]],\n",
       "              \n",
       "                       [[-0.0351,  0.0242, -0.0526],\n",
       "                        [-0.0668, -0.0827,  0.0873],\n",
       "                        [ 0.0886, -0.0227, -0.1589]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1103, -0.0872,  0.0069],\n",
       "                        [-0.0348,  0.0992,  0.0197],\n",
       "                        [-0.0116,  0.0288,  0.0328]],\n",
       "              \n",
       "                       [[-0.0918,  0.0735,  0.0194],\n",
       "                        [-0.1080,  0.0114, -0.0639],\n",
       "                        [-0.0689,  0.0118,  0.0921]],\n",
       "              \n",
       "                       [[ 0.0896, -0.0524,  0.0459],\n",
       "                        [-0.0676, -0.0987,  0.0727],\n",
       "                        [ 0.0799, -0.2089,  0.0608]]]], device='cuda:0')),\n",
       "             ('pi_features_extractor.cnn.4.bias',\n",
       "              tensor([-0.0527, -0.0421, -0.0194, -0.0534, -0.0266, -0.0121, -0.0038, -0.0021,\n",
       "                      -0.0285, -0.0684, -0.0531, -0.0151, -0.0482, -0.0270, -0.0442, -0.0434,\n",
       "                      -0.0313, -0.0371, -0.0373, -0.0229, -0.0440, -0.0215, -0.0519, -0.0588,\n",
       "                      -0.0308, -0.0252, -0.0491, -0.0177, -0.0092, -0.0191, -0.0484, -0.0235,\n",
       "                      -0.0379, -0.0287, -0.0316, -0.0126, -0.0297, -0.0215, -0.0215, -0.0448,\n",
       "                      -0.0187, -0.0510, -0.0096, -0.0514, -0.0251, -0.0464, -0.0250, -0.0309,\n",
       "                      -0.0291, -0.0448, -0.0306, -0.0332, -0.0095, -0.0130, -0.0548, -0.0416,\n",
       "                      -0.0410, -0.0265, -0.0136, -0.0418,  0.0009, -0.0626, -0.0153, -0.0527],\n",
       "                     device='cuda:0')),\n",
       "             ('pi_features_extractor.linear.0.weight',\n",
       "              tensor([[-0.0270, -0.0135, -0.0357,  ..., -0.0760, -0.0304,  0.0015],\n",
       "                      [-0.0007, -0.0621,  0.0162,  ..., -0.0310,  0.0050, -0.0013],\n",
       "                      [-0.0178,  0.0220,  0.0382,  ...,  0.0995, -0.0172,  0.0078],\n",
       "                      ...,\n",
       "                      [-0.0200, -0.0426, -0.1067,  ..., -0.0226, -0.0147, -0.0272],\n",
       "                      [-0.0199,  0.1090, -0.0471,  ...,  0.0651,  0.0328, -0.0295],\n",
       "                      [ 0.0558, -0.0437,  0.0408,  ...,  0.0242,  0.0245,  0.0446]],\n",
       "                     device='cuda:0')),\n",
       "             ('pi_features_extractor.linear.0.bias',\n",
       "              tensor([-5.6608e-03,  6.0292e-03, -9.1965e-03, -1.8568e-02, -1.1593e-02,\n",
       "                       9.6789e-03, -1.5750e-02, -2.1523e-02, -1.4694e-02,  1.8843e-03,\n",
       "                      -1.0284e-02, -1.3603e-02, -1.9655e-02,  2.5110e-03, -2.3079e-02,\n",
       "                      -2.5503e-03,  2.5569e-02, -1.5688e-02, -2.0103e-02,  5.9138e-03,\n",
       "                      -2.3874e-03,  1.0382e-02, -1.2352e-03, -6.3961e-03, -3.2044e-03,\n",
       "                       2.0733e-02, -7.9140e-03,  2.1906e-03, -3.3774e-04, -1.2366e-02,\n",
       "                      -8.4314e-03,  6.4223e-03, -1.3893e-02, -1.9243e-02, -9.8721e-03,\n",
       "                      -1.3911e-02, -1.6314e-02,  3.9481e-03,  6.8481e-03, -7.2767e-04,\n",
       "                      -3.5789e-03,  1.7647e-02,  5.1980e-03, -1.5433e-02,  2.0342e-03,\n",
       "                      -3.8536e-03,  4.9479e-03,  1.1522e-02,  3.1461e-03, -2.1221e-02,\n",
       "                      -1.8123e-02,  2.9962e-03, -2.4504e-02, -1.3904e-02, -1.9924e-02,\n",
       "                      -6.5181e-03, -1.1136e-02, -8.0146e-03,  1.1183e-03,  5.8428e-03,\n",
       "                      -6.7766e-03, -1.8218e-02,  2.0625e-02, -4.1976e-03,  9.8920e-03,\n",
       "                       2.7103e-03,  5.1831e-03, -1.0430e-02,  4.0037e-05, -2.4779e-02,\n",
       "                      -2.1182e-02, -4.8570e-04, -1.4988e-02,  4.2176e-04,  1.6978e-02,\n",
       "                      -1.7201e-02, -9.6121e-03, -1.7206e-02, -3.7706e-03, -8.1554e-03,\n",
       "                      -8.9120e-03, -4.4588e-03, -2.7373e-02,  2.3373e-03, -4.0309e-03,\n",
       "                       5.0599e-03, -3.3017e-02, -1.5682e-02, -3.8791e-03, -1.3667e-02,\n",
       "                      -1.1874e-02, -1.3697e-02, -4.7328e-03, -8.9924e-03, -1.7318e-02,\n",
       "                      -7.3571e-03, -5.0703e-03,  1.3889e-02, -1.2070e-02, -1.8983e-02,\n",
       "                      -3.0111e-03, -7.7595e-03,  1.6896e-02, -1.3754e-02,  6.6683e-03,\n",
       "                      -4.5552e-03, -3.7477e-04, -1.2147e-02, -3.4943e-03, -1.3093e-02,\n",
       "                       5.1952e-03,  1.8795e-02,  3.8898e-03, -2.4092e-02,  2.5640e-05,\n",
       "                      -1.4565e-02, -1.4779e-02, -1.6007e-02, -4.0413e-03, -2.6391e-02,\n",
       "                      -9.2754e-03, -6.6702e-03, -1.9132e-02, -1.9438e-02, -1.8338e-02,\n",
       "                      -3.7500e-03,  7.5928e-03, -1.0519e-02, -1.1963e-03,  5.0987e-03,\n",
       "                      -5.1751e-03, -1.9795e-03, -1.2211e-02, -1.1549e-02, -1.8722e-02,\n",
       "                      -5.7123e-03, -3.2459e-02, -7.2956e-03, -2.8802e-02,  3.6083e-03,\n",
       "                       4.6870e-05, -7.6378e-03, -8.7449e-03, -1.4517e-03, -4.2058e-03,\n",
       "                      -1.1429e-02, -1.9129e-02, -8.3722e-03, -1.4606e-02,  1.8631e-03,\n",
       "                      -1.6571e-02,  6.3678e-03, -2.3493e-02, -1.0677e-02, -9.0645e-03,\n",
       "                      -1.2493e-02, -1.7621e-02,  7.2907e-04, -1.5983e-02,  1.2657e-02,\n",
       "                      -1.4844e-02, -3.4709e-02,  3.4632e-03,  5.9516e-03, -1.3603e-02,\n",
       "                      -7.0841e-04, -1.5203e-02, -5.4989e-03, -6.8727e-03, -6.8712e-03,\n",
       "                      -6.7857e-03, -1.2739e-02, -9.4579e-04, -5.7958e-03, -2.0469e-02,\n",
       "                      -4.8724e-03, -1.1285e-02, -1.0248e-02,  1.5599e-02, -1.2677e-02,\n",
       "                      -1.2914e-02,  7.9928e-03, -1.6114e-02, -1.2004e-02, -9.0505e-03,\n",
       "                      -1.7559e-02,  1.1923e-02,  7.7604e-03, -4.7151e-04, -8.8959e-03,\n",
       "                       6.0266e-04, -1.1305e-02, -1.7632e-02, -9.8618e-04, -3.2808e-04,\n",
       "                      -9.2304e-03, -5.8386e-03, -1.2238e-02, -1.0198e-02, -1.9077e-03,\n",
       "                      -1.6158e-02, -1.6521e-02,  4.7318e-03,  1.0410e-02, -2.2033e-02,\n",
       "                       1.1737e-03, -1.2583e-02, -1.3367e-02,  1.6993e-03, -1.0574e-02,\n",
       "                      -3.0460e-03, -8.5488e-03, -1.0641e-02, -2.5659e-02, -1.0535e-02,\n",
       "                      -1.0917e-02, -1.0462e-02, -4.1459e-03, -1.4119e-02, -1.1132e-02,\n",
       "                      -1.0320e-02, -1.4184e-02, -1.0302e-02, -8.1392e-04, -2.7057e-03,\n",
       "                      -4.2100e-03,  1.9071e-02, -1.4972e-02,  3.7827e-03, -8.7062e-03,\n",
       "                       6.6713e-03, -9.7732e-03,  7.0135e-03,  6.3468e-03, -8.1618e-03,\n",
       "                       1.1720e-02, -1.4238e-02, -1.1268e-02,  1.4706e-02,  4.6204e-03,\n",
       "                      -9.1095e-04,  2.2036e-02, -1.6451e-02, -1.4447e-02, -1.8699e-02,\n",
       "                       9.3533e-03, -5.2393e-03,  1.2488e-02, -7.6009e-03, -9.2387e-04,\n",
       "                      -1.9480e-03, -1.4901e-02, -1.6314e-02,  5.9689e-03, -5.6877e-03,\n",
       "                       9.1546e-03], device='cuda:0')),\n",
       "             ('vf_features_extractor.cnn.0.weight',\n",
       "              tensor([[[[ 5.8862e-02,  3.7363e-01, -1.3097e-01],\n",
       "                        [-1.3117e-01, -1.4281e-01,  1.0642e-02],\n",
       "                        [-3.2974e-01,  5.1945e-02, -1.7016e-01]],\n",
       "              \n",
       "                       [[-1.6550e-01,  2.2424e-01,  6.2481e-01],\n",
       "                        [ 1.1638e-01,  6.0274e-02,  2.3141e-01],\n",
       "                        [-1.1957e-01, -3.1702e-01,  2.2510e-01]],\n",
       "              \n",
       "                       [[-1.1080e-01,  3.4992e-01, -2.3739e-01],\n",
       "                        [-8.8834e-02,  2.8504e-01,  1.4751e-01],\n",
       "                        [ 1.0280e-01, -2.0961e-01, -1.3982e-01]],\n",
       "              \n",
       "                       [[-3.6928e-01,  2.0983e-01, -2.5590e-01],\n",
       "                        [ 1.8024e-02,  4.0449e-01, -2.9480e-01],\n",
       "                        [-1.0230e-01, -4.0876e-02,  4.6758e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 4.3953e-02, -1.4663e-01,  3.7173e-01],\n",
       "                        [ 2.7627e-01,  1.3760e-01,  1.6290e-01],\n",
       "                        [-2.6357e-02, -1.3164e-01, -2.5004e-01]],\n",
       "              \n",
       "                       [[ 1.5716e-01, -6.5916e-01, -3.7163e-01],\n",
       "                        [-1.4906e-01, -3.3604e-01, -9.9113e-02],\n",
       "                        [ 1.2724e-01,  1.5649e-01, -6.1665e-02]],\n",
       "              \n",
       "                       [[-2.0052e-02,  1.7148e-01, -3.4569e-01],\n",
       "                        [ 4.4725e-01, -1.2255e-02,  4.0592e-01],\n",
       "                        [-1.6992e-01, -1.4607e-01, -3.2384e-01]],\n",
       "              \n",
       "                       [[-1.7028e-02, -8.5108e-02, -2.3798e-01],\n",
       "                        [ 2.8127e-01,  1.8218e-02,  2.9830e-01],\n",
       "                        [-1.0245e-01, -3.9497e-02,  2.7497e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-3.8271e-02, -7.2140e-01,  3.2392e-02],\n",
       "                        [ 2.9607e-01, -1.0893e-01, -3.0054e-01],\n",
       "                        [-2.4524e-01, -3.4102e-01,  6.4828e-02]],\n",
       "              \n",
       "                       [[-1.5833e-01,  2.8716e-01, -2.8541e-01],\n",
       "                        [-8.1920e-02,  5.3344e-01, -8.9772e-02],\n",
       "                        [-2.3166e-01,  2.8033e-01, -2.1412e-01]],\n",
       "              \n",
       "                       [[-9.1274e-02,  5.6942e-02, -1.8451e-01],\n",
       "                        [-1.0216e-01,  7.0682e-02,  5.3959e-02],\n",
       "                        [ 3.2387e-01, -2.0344e-01, -4.7135e-02]],\n",
       "              \n",
       "                       [[ 1.5830e-02,  4.4492e-02,  1.4217e-01],\n",
       "                        [-1.3069e-02, -1.6149e-01, -1.3701e-02],\n",
       "                        [-1.9981e-01,  2.9199e-01,  3.8395e-01]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 4.2955e-01, -1.0186e-01,  7.6801e-02],\n",
       "                        [-8.6575e-02, -8.0612e-03, -1.5902e-01],\n",
       "                        [-2.8949e-04, -2.3332e-01,  2.2612e-01]],\n",
       "              \n",
       "                       [[ 3.0940e-02, -2.1828e-01,  4.1376e-01],\n",
       "                        [ 1.4290e-02, -3.3372e-02,  1.5831e-01],\n",
       "                        [ 2.5643e-02, -9.1558e-02,  3.4163e-01]],\n",
       "              \n",
       "                       [[ 8.4127e-02,  3.7897e-02, -1.5717e-01],\n",
       "                        [ 6.7579e-02,  3.5411e-01,  3.2907e-02],\n",
       "                        [-6.1220e-02,  4.9653e-01,  1.0497e-01]],\n",
       "              \n",
       "                       [[ 1.0379e-01, -2.9524e-01,  2.6511e-02],\n",
       "                        [-3.9713e-02, -5.0619e-01, -3.7104e-02],\n",
       "                        [-4.2020e-01,  5.8012e-01,  6.2754e-02]]],\n",
       "              \n",
       "              \n",
       "                      [[[-7.3067e-01, -1.3824e-02, -2.5355e-01],\n",
       "                        [ 3.1014e-01,  1.0804e-02,  1.3980e-01],\n",
       "                        [-1.2415e-01,  4.2892e-02,  1.1416e-01]],\n",
       "              \n",
       "                       [[-2.8074e-01,  7.6132e-02,  3.3707e-01],\n",
       "                        [ 4.0284e-02, -2.8315e-01,  6.4632e-02],\n",
       "                        [ 1.1876e-01, -1.0156e-01, -7.2963e-02]],\n",
       "              \n",
       "                       [[ 3.2671e-01, -1.1268e-01,  2.0574e-02],\n",
       "                        [ 1.2063e-01,  2.8370e-02, -2.6460e-01],\n",
       "                        [-5.2230e-02,  3.3347e-02, -1.6008e-01]],\n",
       "              \n",
       "                       [[ 3.0438e-01, -2.1996e-01, -3.7970e-01],\n",
       "                        [-4.8888e-01, -1.0636e-01,  2.4557e-01],\n",
       "                        [ 4.3349e-02,  1.3737e-02,  5.5982e-01]]],\n",
       "              \n",
       "              \n",
       "                      [[[-1.5865e-01, -1.3829e-01, -3.8599e-02],\n",
       "                        [ 2.3240e-01, -2.6784e-01, -2.6056e-01],\n",
       "                        [ 3.3347e-01,  1.6459e-01, -9.9123e-02]],\n",
       "              \n",
       "                       [[-1.3240e-02, -2.4913e-01,  4.1011e-01],\n",
       "                        [-3.2280e-01,  4.6701e-01, -4.4934e-02],\n",
       "                        [-5.1787e-01, -2.1056e-01,  1.4919e-01]],\n",
       "              \n",
       "                       [[ 1.6178e-01, -9.8057e-02,  6.0526e-02],\n",
       "                        [-1.1812e-01,  1.3447e-01,  2.1761e-01],\n",
       "                        [-4.6781e-01, -6.2003e-02, -1.7766e-01]],\n",
       "              \n",
       "                       [[-1.6266e-01,  2.7354e-03, -2.3151e-01],\n",
       "                        [ 2.1946e-01, -4.2909e-01, -6.8603e-02],\n",
       "                        [ 4.2664e-01, -1.6004e-01, -6.8614e-02]]]], device='cuda:0')),\n",
       "             ('vf_features_extractor.cnn.0.bias',\n",
       "              tensor([-0.0566, -0.0666,  0.0050,  0.0101, -0.0325, -0.1201, -0.0267, -0.0672,\n",
       "                      -0.0574, -0.0115,  0.0515, -0.0224, -0.0393, -0.0064, -0.0498,  0.0367,\n",
       "                       0.0978,  0.1039,  0.0021, -0.0343, -0.0318, -0.0280,  0.0324, -0.0059,\n",
       "                       0.0608,  0.0087, -0.0349,  0.0326,  0.0145, -0.0126, -0.0186,  0.0100],\n",
       "                     device='cuda:0')),\n",
       "             ('vf_features_extractor.cnn.2.weight',\n",
       "              tensor([[[[ 0.0337,  0.0183,  0.1811],\n",
       "                        [-0.0092,  0.0704,  0.0781],\n",
       "                        [ 0.0079,  0.0235,  0.2508]],\n",
       "              \n",
       "                       [[-0.0559, -0.0903, -0.1553],\n",
       "                        [ 0.0236,  0.0402,  0.0951],\n",
       "                        [ 0.1265, -0.1126, -0.1120]],\n",
       "              \n",
       "                       [[-0.0063, -0.0839,  0.0146],\n",
       "                        [ 0.0568,  0.0494,  0.0495],\n",
       "                        [-0.1111, -0.1969, -0.1347]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1430,  0.0147, -0.0547],\n",
       "                        [ 0.0025, -0.1023,  0.1860],\n",
       "                        [ 0.0145, -0.0365, -0.0542]],\n",
       "              \n",
       "                       [[-0.0599, -0.0654, -0.0008],\n",
       "                        [ 0.0207,  0.1879,  0.0056],\n",
       "                        [-0.0875, -0.0323,  0.0365]],\n",
       "              \n",
       "                       [[ 0.2021,  0.0356,  0.0555],\n",
       "                        [ 0.1441, -0.0895,  0.0371],\n",
       "                        [-0.1306, -0.1064, -0.0320]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0295,  0.1417,  0.0898],\n",
       "                        [-0.0841, -0.0365,  0.0656],\n",
       "                        [-0.1357,  0.1170,  0.1063]],\n",
       "              \n",
       "                       [[ 0.1105, -0.0365,  0.0223],\n",
       "                        [-0.0618,  0.0518, -0.0784],\n",
       "                        [ 0.1527,  0.1740, -0.0630]],\n",
       "              \n",
       "                       [[ 0.1227, -0.1392, -0.0040],\n",
       "                        [ 0.0392, -0.0950,  0.1206],\n",
       "                        [-0.0319,  0.0154,  0.0485]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1858,  0.0093, -0.0078],\n",
       "                        [ 0.0195, -0.0297, -0.1388],\n",
       "                        [-0.0933, -0.0209,  0.0919]],\n",
       "              \n",
       "                       [[ 0.0456, -0.0209, -0.0961],\n",
       "                        [ 0.0440, -0.0379, -0.0509],\n",
       "                        [ 0.0703, -0.0644,  0.0500]],\n",
       "              \n",
       "                       [[ 0.1575,  0.1472, -0.1588],\n",
       "                        [ 0.0704, -0.0619,  0.0216],\n",
       "                        [-0.0397,  0.0828,  0.0385]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0037,  0.0176, -0.2178],\n",
       "                        [-0.0295, -0.1379,  0.0542],\n",
       "                        [ 0.0287,  0.0869, -0.0711]],\n",
       "              \n",
       "                       [[ 0.0246,  0.0180, -0.0136],\n",
       "                        [ 0.0585, -0.0908,  0.0373],\n",
       "                        [-0.1708,  0.0041, -0.1778]],\n",
       "              \n",
       "                       [[ 0.0947,  0.0598,  0.0550],\n",
       "                        [-0.0396,  0.1413, -0.1427],\n",
       "                        [-0.1346, -0.0290, -0.0006]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0819, -0.0565, -0.0107],\n",
       "                        [ 0.0251,  0.0080, -0.1340],\n",
       "                        [-0.0806, -0.0358,  0.0328]],\n",
       "              \n",
       "                       [[-0.0176, -0.0219,  0.0098],\n",
       "                        [ 0.0743,  0.0146, -0.0068],\n",
       "                        [ 0.0307, -0.0660, -0.1691]],\n",
       "              \n",
       "                       [[-0.0751,  0.0300, -0.0542],\n",
       "                        [-0.1141,  0.0117, -0.0460],\n",
       "                        [ 0.1561,  0.0939,  0.1133]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0220, -0.0986,  0.0897],\n",
       "                        [ 0.0680, -0.1171,  0.0113],\n",
       "                        [-0.0018,  0.0855,  0.0803]],\n",
       "              \n",
       "                       [[ 0.0904,  0.0183, -0.1006],\n",
       "                        [-0.1004, -0.0417, -0.1845],\n",
       "                        [-0.1535,  0.0890, -0.0894]],\n",
       "              \n",
       "                       [[ 0.1373,  0.0621, -0.0894],\n",
       "                        [ 0.2271,  0.1095, -0.0319],\n",
       "                        [ 0.0152, -0.0245,  0.1569]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0120, -0.0119,  0.0167],\n",
       "                        [-0.0655,  0.0904,  0.0507],\n",
       "                        [-0.0890,  0.2800, -0.0387]],\n",
       "              \n",
       "                       [[-0.0526, -0.1061,  0.1017],\n",
       "                        [ 0.0505,  0.0431, -0.0106],\n",
       "                        [ 0.1109, -0.1559,  0.0986]],\n",
       "              \n",
       "                       [[ 0.1002,  0.1639,  0.0977],\n",
       "                        [-0.0913, -0.0571,  0.0487],\n",
       "                        [-0.1078,  0.1614, -0.0788]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.1416,  0.0937,  0.0798],\n",
       "                        [ 0.0718,  0.0977, -0.0887],\n",
       "                        [-0.0445,  0.0350, -0.0309]],\n",
       "              \n",
       "                       [[ 0.1969, -0.0258, -0.0243],\n",
       "                        [ 0.2591,  0.0262,  0.0080],\n",
       "                        [-0.0006,  0.0793, -0.2098]],\n",
       "              \n",
       "                       [[ 0.0529, -0.0417,  0.0800],\n",
       "                        [-0.0687, -0.0148,  0.2967],\n",
       "                        [-0.1469, -0.2498, -0.0229]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.1094,  0.0152, -0.0539],\n",
       "                        [-0.0680, -0.0788,  0.0701],\n",
       "                        [ 0.0526, -0.1560, -0.2047]],\n",
       "              \n",
       "                       [[ 0.0327, -0.0424, -0.0037],\n",
       "                        [-0.0473, -0.0575,  0.1007],\n",
       "                        [ 0.0497, -0.1394, -0.0099]],\n",
       "              \n",
       "                       [[-0.0807, -0.1619, -0.0035],\n",
       "                        [ 0.0386, -0.0241,  0.0321],\n",
       "                        [-0.1117,  0.0962, -0.1791]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0174, -0.0043, -0.0614],\n",
       "                        [-0.0582,  0.0048, -0.1357],\n",
       "                        [ 0.0407, -0.0188, -0.1285]],\n",
       "              \n",
       "                       [[ 0.1117, -0.0041, -0.1399],\n",
       "                        [ 0.0533, -0.1416, -0.1361],\n",
       "                        [-0.0427,  0.0032, -0.0008]],\n",
       "              \n",
       "                       [[ 0.0627,  0.0510,  0.0315],\n",
       "                        [ 0.1574,  0.1953, -0.1351],\n",
       "                        [ 0.0472, -0.0914,  0.0192]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.2125, -0.0262, -0.0840],\n",
       "                        [-0.0027, -0.0503,  0.0810],\n",
       "                        [ 0.0658, -0.0355, -0.0023]],\n",
       "              \n",
       "                       [[-0.0149,  0.0386, -0.0299],\n",
       "                        [-0.0956, -0.1379, -0.0337],\n",
       "                        [ 0.0054,  0.1598, -0.0692]],\n",
       "              \n",
       "                       [[ 0.0698, -0.1232, -0.0237],\n",
       "                        [ 0.0924, -0.0492,  0.0697],\n",
       "                        [-0.0753, -0.0362,  0.0646]]]], device='cuda:0')),\n",
       "             ('vf_features_extractor.cnn.2.bias',\n",
       "              tensor([-0.0390, -0.0034, -0.0113, -0.0361,  0.0085,  0.0049, -0.0228,  0.0194,\n",
       "                      -0.0314, -0.0193, -0.0153, -0.0270, -0.0255,  0.0063, -0.0083,  0.0100,\n",
       "                       0.0165, -0.0047, -0.0294, -0.0083,  0.0202, -0.0153,  0.0065, -0.0314,\n",
       "                       0.0038,  0.0038, -0.0122, -0.0127, -0.0490,  0.0145, -0.0177,  0.0108,\n",
       "                       0.0031, -0.0147, -0.0546, -0.0104,  0.0075, -0.0224, -0.0226, -0.0075,\n",
       "                      -0.0132, -0.0033, -0.0336, -0.0368,  0.0054, -0.0007, -0.0043, -0.0222,\n",
       "                      -0.0103, -0.0611, -0.0028, -0.0120, -0.0236, -0.0233, -0.0365,  0.0186,\n",
       "                      -0.0335,  0.0064, -0.0251, -0.0194, -0.0224, -0.0334, -0.0377, -0.0148],\n",
       "                     device='cuda:0')),\n",
       "             ('vf_features_extractor.cnn.4.weight',\n",
       "              tensor([[[[-0.1014,  0.0709,  0.1082],\n",
       "                        [-0.0704,  0.0229, -0.0548],\n",
       "                        [ 0.0604,  0.0755, -0.1099]],\n",
       "              \n",
       "                       [[ 0.0352, -0.2052, -0.0431],\n",
       "                        [ 0.0014, -0.1739, -0.0260],\n",
       "                        [-0.0592,  0.1083,  0.0191]],\n",
       "              \n",
       "                       [[-0.1012,  0.0074,  0.1031],\n",
       "                        [-0.0348, -0.0550, -0.0482],\n",
       "                        [ 0.0439,  0.0012, -0.0179]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0070,  0.0207,  0.0602],\n",
       "                        [ 0.0391, -0.0656,  0.0200],\n",
       "                        [ 0.0378,  0.0211, -0.1084]],\n",
       "              \n",
       "                       [[-0.0429,  0.0146, -0.0985],\n",
       "                        [ 0.0302, -0.0878,  0.1199],\n",
       "                        [-0.1365,  0.1271, -0.0090]],\n",
       "              \n",
       "                       [[-0.1360,  0.1147, -0.0451],\n",
       "                        [-0.0211,  0.0499,  0.0696],\n",
       "                        [ 0.0633, -0.1438,  0.0214]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0525, -0.1044, -0.0197],\n",
       "                        [ 0.0397, -0.0160, -0.0297],\n",
       "                        [-0.0340,  0.0754,  0.0151]],\n",
       "              \n",
       "                       [[-0.0837,  0.0467,  0.0243],\n",
       "                        [ 0.0600,  0.0197, -0.0111],\n",
       "                        [-0.0211,  0.0185,  0.0020]],\n",
       "              \n",
       "                       [[ 0.0702,  0.0136,  0.0851],\n",
       "                        [-0.0559, -0.0383,  0.0509],\n",
       "                        [ 0.0301,  0.0863, -0.0579]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0008,  0.1314, -0.0715],\n",
       "                        [-0.0519, -0.0206,  0.0187],\n",
       "                        [-0.0610, -0.1474,  0.0442]],\n",
       "              \n",
       "                       [[-0.0570, -0.0038, -0.0652],\n",
       "                        [-0.1259,  0.0309, -0.1133],\n",
       "                        [ 0.0531,  0.0175, -0.0488]],\n",
       "              \n",
       "                       [[-0.0420, -0.1407,  0.0187],\n",
       "                        [ 0.0362,  0.0119,  0.1130],\n",
       "                        [ 0.1020, -0.0303,  0.0771]]],\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0843,  0.0506, -0.0102],\n",
       "                        [-0.0309,  0.0596,  0.1865],\n",
       "                        [ 0.0695, -0.1693, -0.1030]],\n",
       "              \n",
       "                       [[ 0.0419,  0.0717,  0.1250],\n",
       "                        [-0.0795,  0.0079,  0.1064],\n",
       "                        [-0.0167, -0.0967, -0.1259]],\n",
       "              \n",
       "                       [[ 0.0243,  0.0092,  0.0335],\n",
       "                        [ 0.0913, -0.0200,  0.1210],\n",
       "                        [ 0.0838, -0.0482,  0.0845]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0013, -0.0548, -0.1030],\n",
       "                        [ 0.1146,  0.1135, -0.0269],\n",
       "                        [ 0.0268,  0.0550, -0.0531]],\n",
       "              \n",
       "                       [[ 0.0765, -0.0841,  0.0607],\n",
       "                        [ 0.0406,  0.0043, -0.0290],\n",
       "                        [-0.0238,  0.0344, -0.0343]],\n",
       "              \n",
       "                       [[-0.0306, -0.0158,  0.0538],\n",
       "                        [-0.0041,  0.0514,  0.0606],\n",
       "                        [ 0.0687, -0.0608,  0.0098]]],\n",
       "              \n",
       "              \n",
       "                      ...,\n",
       "              \n",
       "              \n",
       "                      [[[ 0.0852, -0.0107, -0.0530],\n",
       "                        [ 0.0538, -0.0349, -0.0862],\n",
       "                        [ 0.0586,  0.0060, -0.1364]],\n",
       "              \n",
       "                       [[ 0.0105, -0.0361, -0.0264],\n",
       "                        [ 0.1033, -0.0619, -0.0171],\n",
       "                        [-0.0026,  0.0930, -0.0463]],\n",
       "              \n",
       "                       [[-0.0930, -0.0707,  0.0251],\n",
       "                        [ 0.0259, -0.0004,  0.2019],\n",
       "                        [-0.0139, -0.0725, -0.1661]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[ 0.0039,  0.0044,  0.0718],\n",
       "                        [ 0.1228, -0.0095,  0.0568],\n",
       "                        [-0.0977, -0.0113,  0.0441]],\n",
       "              \n",
       "                       [[ 0.0801,  0.0876,  0.0224],\n",
       "                        [ 0.0183, -0.0459, -0.0793],\n",
       "                        [-0.0716, -0.0030, -0.0981]],\n",
       "              \n",
       "                       [[-0.0205,  0.0779, -0.1334],\n",
       "                        [-0.1343,  0.0562,  0.0465],\n",
       "                        [ 0.0765, -0.0930, -0.0822]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0020, -0.1609, -0.0816],\n",
       "                        [-0.0171, -0.0815, -0.0878],\n",
       "                        [-0.0384,  0.0751,  0.0293]],\n",
       "              \n",
       "                       [[ 0.0061, -0.0220, -0.0833],\n",
       "                        [ 0.0124, -0.0083,  0.0255],\n",
       "                        [ 0.0746, -0.0895,  0.0211]],\n",
       "              \n",
       "                       [[-0.1771, -0.1180,  0.0226],\n",
       "                        [ 0.0984, -0.0210, -0.0414],\n",
       "                        [ 0.1382,  0.0387,  0.0620]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.0797,  0.0699,  0.0314],\n",
       "                        [-0.0514, -0.1527, -0.0059],\n",
       "                        [-0.0050, -0.0193,  0.0991]],\n",
       "              \n",
       "                       [[-0.1514,  0.0452, -0.0108],\n",
       "                        [-0.0435, -0.1535, -0.0243],\n",
       "                        [ 0.0623, -0.0156, -0.0899]],\n",
       "              \n",
       "                       [[ 0.0136,  0.0049,  0.1030],\n",
       "                        [-0.0593, -0.0197, -0.0076],\n",
       "                        [-0.0189, -0.0357, -0.0282]]],\n",
       "              \n",
       "              \n",
       "                      [[[-0.0250, -0.0896,  0.1386],\n",
       "                        [-0.0635, -0.0235,  0.0971],\n",
       "                        [-0.0404,  0.0862, -0.0077]],\n",
       "              \n",
       "                       [[-0.0196,  0.0070, -0.0055],\n",
       "                        [-0.0389, -0.1478, -0.0312],\n",
       "                        [ 0.0856,  0.0393, -0.0485]],\n",
       "              \n",
       "                       [[-0.0351,  0.0242, -0.0526],\n",
       "                        [-0.0668, -0.0827,  0.0873],\n",
       "                        [ 0.0886, -0.0227, -0.1589]],\n",
       "              \n",
       "                       ...,\n",
       "              \n",
       "                       [[-0.1103, -0.0872,  0.0069],\n",
       "                        [-0.0348,  0.0992,  0.0197],\n",
       "                        [-0.0116,  0.0288,  0.0328]],\n",
       "              \n",
       "                       [[-0.0918,  0.0735,  0.0194],\n",
       "                        [-0.1080,  0.0114, -0.0639],\n",
       "                        [-0.0689,  0.0118,  0.0921]],\n",
       "              \n",
       "                       [[ 0.0896, -0.0524,  0.0459],\n",
       "                        [-0.0676, -0.0987,  0.0727],\n",
       "                        [ 0.0799, -0.2089,  0.0608]]]], device='cuda:0')),\n",
       "             ('vf_features_extractor.cnn.4.bias',\n",
       "              tensor([-0.0527, -0.0421, -0.0194, -0.0534, -0.0266, -0.0121, -0.0038, -0.0021,\n",
       "                      -0.0285, -0.0684, -0.0531, -0.0151, -0.0482, -0.0270, -0.0442, -0.0434,\n",
       "                      -0.0313, -0.0371, -0.0373, -0.0229, -0.0440, -0.0215, -0.0519, -0.0588,\n",
       "                      -0.0308, -0.0252, -0.0491, -0.0177, -0.0092, -0.0191, -0.0484, -0.0235,\n",
       "                      -0.0379, -0.0287, -0.0316, -0.0126, -0.0297, -0.0215, -0.0215, -0.0448,\n",
       "                      -0.0187, -0.0510, -0.0096, -0.0514, -0.0251, -0.0464, -0.0250, -0.0309,\n",
       "                      -0.0291, -0.0448, -0.0306, -0.0332, -0.0095, -0.0130, -0.0548, -0.0416,\n",
       "                      -0.0410, -0.0265, -0.0136, -0.0418,  0.0009, -0.0626, -0.0153, -0.0527],\n",
       "                     device='cuda:0')),\n",
       "             ('vf_features_extractor.linear.0.weight',\n",
       "              tensor([[-0.0270, -0.0135, -0.0357,  ..., -0.0760, -0.0304,  0.0015],\n",
       "                      [-0.0007, -0.0621,  0.0162,  ..., -0.0310,  0.0050, -0.0013],\n",
       "                      [-0.0178,  0.0220,  0.0382,  ...,  0.0995, -0.0172,  0.0078],\n",
       "                      ...,\n",
       "                      [-0.0200, -0.0426, -0.1067,  ..., -0.0226, -0.0147, -0.0272],\n",
       "                      [-0.0199,  0.1090, -0.0471,  ...,  0.0651,  0.0328, -0.0295],\n",
       "                      [ 0.0558, -0.0437,  0.0408,  ...,  0.0242,  0.0245,  0.0446]],\n",
       "                     device='cuda:0')),\n",
       "             ('vf_features_extractor.linear.0.bias',\n",
       "              tensor([-5.6608e-03,  6.0292e-03, -9.1965e-03, -1.8568e-02, -1.1593e-02,\n",
       "                       9.6789e-03, -1.5750e-02, -2.1523e-02, -1.4694e-02,  1.8843e-03,\n",
       "                      -1.0284e-02, -1.3603e-02, -1.9655e-02,  2.5110e-03, -2.3079e-02,\n",
       "                      -2.5503e-03,  2.5569e-02, -1.5688e-02, -2.0103e-02,  5.9138e-03,\n",
       "                      -2.3874e-03,  1.0382e-02, -1.2352e-03, -6.3961e-03, -3.2044e-03,\n",
       "                       2.0733e-02, -7.9140e-03,  2.1906e-03, -3.3774e-04, -1.2366e-02,\n",
       "                      -8.4314e-03,  6.4223e-03, -1.3893e-02, -1.9243e-02, -9.8721e-03,\n",
       "                      -1.3911e-02, -1.6314e-02,  3.9481e-03,  6.8481e-03, -7.2767e-04,\n",
       "                      -3.5789e-03,  1.7647e-02,  5.1980e-03, -1.5433e-02,  2.0342e-03,\n",
       "                      -3.8536e-03,  4.9479e-03,  1.1522e-02,  3.1461e-03, -2.1221e-02,\n",
       "                      -1.8123e-02,  2.9962e-03, -2.4504e-02, -1.3904e-02, -1.9924e-02,\n",
       "                      -6.5181e-03, -1.1136e-02, -8.0146e-03,  1.1183e-03,  5.8428e-03,\n",
       "                      -6.7766e-03, -1.8218e-02,  2.0625e-02, -4.1976e-03,  9.8920e-03,\n",
       "                       2.7103e-03,  5.1831e-03, -1.0430e-02,  4.0037e-05, -2.4779e-02,\n",
       "                      -2.1182e-02, -4.8570e-04, -1.4988e-02,  4.2176e-04,  1.6978e-02,\n",
       "                      -1.7201e-02, -9.6121e-03, -1.7206e-02, -3.7706e-03, -8.1554e-03,\n",
       "                      -8.9120e-03, -4.4588e-03, -2.7373e-02,  2.3373e-03, -4.0309e-03,\n",
       "                       5.0599e-03, -3.3017e-02, -1.5682e-02, -3.8791e-03, -1.3667e-02,\n",
       "                      -1.1874e-02, -1.3697e-02, -4.7328e-03, -8.9924e-03, -1.7318e-02,\n",
       "                      -7.3571e-03, -5.0703e-03,  1.3889e-02, -1.2070e-02, -1.8983e-02,\n",
       "                      -3.0111e-03, -7.7595e-03,  1.6896e-02, -1.3754e-02,  6.6683e-03,\n",
       "                      -4.5552e-03, -3.7477e-04, -1.2147e-02, -3.4943e-03, -1.3093e-02,\n",
       "                       5.1952e-03,  1.8795e-02,  3.8898e-03, -2.4092e-02,  2.5640e-05,\n",
       "                      -1.4565e-02, -1.4779e-02, -1.6007e-02, -4.0413e-03, -2.6391e-02,\n",
       "                      -9.2754e-03, -6.6702e-03, -1.9132e-02, -1.9438e-02, -1.8338e-02,\n",
       "                      -3.7500e-03,  7.5928e-03, -1.0519e-02, -1.1963e-03,  5.0987e-03,\n",
       "                      -5.1751e-03, -1.9795e-03, -1.2211e-02, -1.1549e-02, -1.8722e-02,\n",
       "                      -5.7123e-03, -3.2459e-02, -7.2956e-03, -2.8802e-02,  3.6083e-03,\n",
       "                       4.6870e-05, -7.6378e-03, -8.7449e-03, -1.4517e-03, -4.2058e-03,\n",
       "                      -1.1429e-02, -1.9129e-02, -8.3722e-03, -1.4606e-02,  1.8631e-03,\n",
       "                      -1.6571e-02,  6.3678e-03, -2.3493e-02, -1.0677e-02, -9.0645e-03,\n",
       "                      -1.2493e-02, -1.7621e-02,  7.2907e-04, -1.5983e-02,  1.2657e-02,\n",
       "                      -1.4844e-02, -3.4709e-02,  3.4632e-03,  5.9516e-03, -1.3603e-02,\n",
       "                      -7.0841e-04, -1.5203e-02, -5.4989e-03, -6.8727e-03, -6.8712e-03,\n",
       "                      -6.7857e-03, -1.2739e-02, -9.4579e-04, -5.7958e-03, -2.0469e-02,\n",
       "                      -4.8724e-03, -1.1285e-02, -1.0248e-02,  1.5599e-02, -1.2677e-02,\n",
       "                      -1.2914e-02,  7.9928e-03, -1.6114e-02, -1.2004e-02, -9.0505e-03,\n",
       "                      -1.7559e-02,  1.1923e-02,  7.7604e-03, -4.7151e-04, -8.8959e-03,\n",
       "                       6.0266e-04, -1.1305e-02, -1.7632e-02, -9.8618e-04, -3.2808e-04,\n",
       "                      -9.2304e-03, -5.8386e-03, -1.2238e-02, -1.0198e-02, -1.9077e-03,\n",
       "                      -1.6158e-02, -1.6521e-02,  4.7318e-03,  1.0410e-02, -2.2033e-02,\n",
       "                       1.1737e-03, -1.2583e-02, -1.3367e-02,  1.6993e-03, -1.0574e-02,\n",
       "                      -3.0460e-03, -8.5488e-03, -1.0641e-02, -2.5659e-02, -1.0535e-02,\n",
       "                      -1.0917e-02, -1.0462e-02, -4.1459e-03, -1.4119e-02, -1.1132e-02,\n",
       "                      -1.0320e-02, -1.4184e-02, -1.0302e-02, -8.1392e-04, -2.7057e-03,\n",
       "                      -4.2100e-03,  1.9071e-02, -1.4972e-02,  3.7827e-03, -8.7062e-03,\n",
       "                       6.6713e-03, -9.7732e-03,  7.0135e-03,  6.3468e-03, -8.1618e-03,\n",
       "                       1.1720e-02, -1.4238e-02, -1.1268e-02,  1.4706e-02,  4.6204e-03,\n",
       "                      -9.1095e-04,  2.2036e-02, -1.6451e-02, -1.4447e-02, -1.8699e-02,\n",
       "                       9.3533e-03, -5.2393e-03,  1.2488e-02, -7.6009e-03, -9.2387e-04,\n",
       "                      -1.9480e-03, -1.4901e-02, -1.6314e-02,  5.9689e-03, -5.6877e-03,\n",
       "                       9.1546e-03], device='cuda:0')),\n",
       "             ('mlp_extractor.policy_net.0.weight',\n",
       "              tensor([[ 0.0052, -0.0291, -0.1622,  ..., -0.0602,  0.0157, -0.1659],\n",
       "                      [ 0.2019, -0.0419, -0.0568,  ..., -0.0626,  0.1577,  0.0271],\n",
       "                      [-0.0572,  0.1457,  0.0097,  ..., -0.0697,  0.0149,  0.1527],\n",
       "                      ...,\n",
       "                      [ 0.1710, -0.0119, -0.0412,  ..., -0.0447, -0.0182, -0.2364],\n",
       "                      [ 0.0447,  0.1429,  0.0491,  ...,  0.0427, -0.1254, -0.0774],\n",
       "                      [ 0.0038, -0.0645,  0.0989,  ...,  0.0437,  0.0210,  0.1546]],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.policy_net.0.bias',\n",
       "              tensor([-3.7934e-02, -1.0120e-02, -1.7950e-02,  1.3979e-02, -8.9758e-03,\n",
       "                       9.3981e-03,  1.4142e-02, -1.4561e-02,  7.6285e-03, -7.7994e-04,\n",
       "                       3.3254e-02,  3.0155e-03, -5.0676e-03, -8.6990e-03, -6.2035e-03,\n",
       "                      -1.2432e-02,  2.6509e-02,  2.8312e-02, -1.0761e-02, -6.4396e-03,\n",
       "                      -2.3653e-02, -5.9161e-03, -1.6559e-03,  2.3093e-03,  2.1843e-02,\n",
       "                      -5.1557e-03,  3.7100e-02,  2.4642e-02, -2.5497e-02,  2.5407e-02,\n",
       "                       3.0578e-02,  2.9345e-02,  7.7088e-03, -1.1796e-02, -1.3831e-02,\n",
       "                      -2.3595e-02, -1.1430e-03, -1.2029e-02, -7.1556e-03,  1.3530e-02,\n",
       "                      -2.2087e-02, -5.5528e-03,  4.2695e-03,  2.3459e-04, -3.0454e-05,\n",
       "                      -2.4168e-02,  7.0001e-03, -2.1349e-02,  8.1098e-03,  2.3649e-04,\n",
       "                      -1.2144e-02, -1.6706e-02, -1.0958e-02, -2.8586e-03,  3.7588e-02,\n",
       "                      -8.2629e-03,  4.8411e-03, -8.2878e-03,  1.0644e-02,  5.4867e-03,\n",
       "                       6.1514e-03,  9.5967e-03,  1.0890e-02,  4.9025e-03,  1.5948e-02,\n",
       "                       2.1311e-02,  9.8605e-03, -6.4243e-03, -2.9398e-03, -3.6904e-03,\n",
       "                      -9.9446e-03,  1.9047e-02,  1.4092e-02,  2.4026e-03,  3.2092e-02,\n",
       "                      -1.5059e-02,  8.1860e-03,  2.6424e-02, -3.0271e-02,  3.8252e-02,\n",
       "                       1.3251e-02, -1.6951e-02,  5.3191e-03,  2.9410e-02, -2.0283e-02,\n",
       "                       2.5827e-02, -4.1000e-03, -1.0457e-02,  2.1510e-03,  1.4410e-02,\n",
       "                      -4.7814e-03,  3.4634e-03,  4.0821e-03,  2.1709e-02,  3.6088e-02,\n",
       "                       8.9005e-03,  1.4891e-02,  6.9741e-04, -1.8474e-02,  7.3035e-03,\n",
       "                       1.6245e-02, -3.5832e-02,  8.3168e-03, -1.0705e-02,  2.0325e-02,\n",
       "                       2.9341e-02, -3.1170e-02,  1.2995e-02,  1.0005e-02, -3.5040e-02,\n",
       "                       1.2313e-02, -1.4531e-02,  2.3488e-02,  8.1426e-03, -1.0364e-02,\n",
       "                       2.7742e-03, -3.1425e-02,  1.2838e-04, -1.4976e-02, -4.1408e-03,\n",
       "                       8.6572e-03,  1.7360e-02,  3.3624e-02,  1.0835e-02, -1.7576e-02,\n",
       "                      -1.2138e-02,  1.5603e-02, -1.0795e-02,  2.0145e-02, -2.9814e-03,\n",
       "                       1.9765e-03, -8.7999e-03, -6.0783e-03,  1.3500e-02, -3.3708e-02,\n",
       "                      -1.0044e-02,  1.5282e-02,  1.2506e-02,  1.2176e-02,  7.7159e-03,\n",
       "                       3.4869e-02,  1.3253e-02,  5.5851e-05,  1.8154e-03, -6.9276e-04,\n",
       "                      -1.5390e-02,  2.1272e-02,  1.5382e-02, -1.2867e-03, -1.2366e-02,\n",
       "                      -2.6879e-02, -2.3791e-04, -1.2761e-02, -1.2157e-02, -1.4863e-02,\n",
       "                       4.1211e-02, -3.5103e-03,  1.8319e-02, -4.5932e-03, -5.1984e-03,\n",
       "                       2.5223e-02,  6.9816e-03, -8.6695e-03,  1.1261e-02, -1.7240e-03,\n",
       "                      -6.5262e-04, -8.2426e-03, -3.1230e-03, -3.0566e-02,  2.8768e-02,\n",
       "                       1.2229e-02,  8.3468e-03,  2.0897e-03,  1.0116e-02,  1.9699e-03,\n",
       "                       2.2369e-03, -1.7555e-02, -4.4118e-02,  2.1739e-02, -4.9466e-02,\n",
       "                      -8.6298e-03, -4.1051e-02,  2.9664e-02,  1.9345e-02, -2.0059e-02,\n",
       "                       2.3699e-02, -3.7010e-02,  2.4064e-02, -3.7450e-03,  4.3794e-02,\n",
       "                       3.8838e-02,  8.5117e-03, -7.4019e-03,  2.0133e-02,  2.1669e-02,\n",
       "                      -1.1451e-02,  1.6833e-02, -1.3509e-02, -7.1325e-04,  1.1084e-02,\n",
       "                       2.7922e-02,  1.0219e-02, -7.6056e-05, -1.0354e-02, -2.5249e-02,\n",
       "                       1.2617e-02, -2.6633e-03,  3.5738e-03,  3.5735e-04,  1.8399e-02,\n",
       "                      -4.8047e-03,  4.1018e-03,  4.1222e-03,  1.7260e-02, -1.0157e-02,\n",
       "                      -1.2880e-02, -2.6215e-02, -2.7168e-02,  1.0103e-02,  1.7706e-02,\n",
       "                      -4.7546e-02,  9.3363e-03, -2.8084e-02, -1.0535e-02, -1.5182e-02,\n",
       "                      -1.3819e-02, -1.1448e-02, -6.4746e-03,  7.6021e-04,  1.2651e-02,\n",
       "                      -1.0050e-02,  2.2821e-02,  1.5586e-02, -2.1990e-02, -9.9179e-03,\n",
       "                      -1.3580e-02,  1.8374e-03, -1.4163e-02, -5.2409e-03, -1.2622e-02,\n",
       "                      -7.0958e-04,  2.5395e-02, -1.7106e-02,  1.8910e-02,  4.9914e-06,\n",
       "                       3.1792e-03, -1.6064e-02,  6.5150e-03, -1.2743e-03,  1.4860e-03,\n",
       "                       7.6464e-03, -1.0430e-02, -7.9494e-03,  7.8145e-04,  4.2292e-03,\n",
       "                      -1.3421e-02], device='cuda:0')),\n",
       "             ('mlp_extractor.policy_net.2.weight',\n",
       "              tensor([[ 0.0511,  0.0201, -0.1065,  ...,  0.1073, -0.1929,  0.0241],\n",
       "                      [-0.0182, -0.0378,  0.0256,  ...,  0.0010, -0.0474,  0.1143],\n",
       "                      [-0.1059, -0.0264,  0.0380,  ...,  0.0188,  0.0859, -0.0179],\n",
       "                      ...,\n",
       "                      [ 0.0793, -0.0118, -0.1422,  ...,  0.1023,  0.1145, -0.0365],\n",
       "                      [-0.2033,  0.0724, -0.0057,  ...,  0.1733,  0.0949,  0.0662],\n",
       "                      [-0.1075, -0.1196,  0.0106,  ..., -0.0087, -0.0097,  0.0297]],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.policy_net.2.bias',\n",
       "              tensor([ 5.8172e-03, -9.2728e-03, -1.5235e-02,  2.1914e-02, -1.1689e-02,\n",
       "                      -3.3092e-03,  3.9647e-03,  3.0486e-02, -1.0433e-03, -2.3171e-02,\n",
       "                      -3.3122e-02,  7.0034e-03,  2.3954e-02,  8.0406e-03,  2.2886e-02,\n",
       "                       4.0525e-02, -3.2603e-02,  1.2374e-02,  1.5371e-02,  1.8317e-02,\n",
       "                      -3.2269e-02,  3.0887e-03,  9.6856e-04, -4.9347e-03, -8.1643e-03,\n",
       "                      -6.9902e-03, -2.0729e-02, -1.7335e-02,  1.0368e-02,  4.6599e-02,\n",
       "                      -9.1468e-03,  6.8571e-03, -3.8949e-02, -2.3278e-02,  2.9535e-02,\n",
       "                       2.7574e-02, -2.5148e-02, -4.7471e-03, -3.7972e-03,  3.3504e-02,\n",
       "                       1.0143e-03,  1.5877e-02,  4.4178e-03, -3.8147e-04,  5.7864e-03,\n",
       "                       8.3002e-03, -4.5355e-03, -1.7833e-03,  5.7902e-03, -3.3542e-02,\n",
       "                      -4.1374e-02, -4.3449e-03,  2.2690e-02,  4.9732e-02, -3.6212e-02,\n",
       "                      -2.2802e-02, -6.3588e-03,  3.5946e-02, -1.8580e-02,  1.8553e-02,\n",
       "                       1.3691e-03,  3.3293e-02,  1.0821e-02, -1.0577e-02, -3.1498e-03,\n",
       "                      -1.4162e-02, -4.9431e-04,  5.2355e-03,  2.2729e-02, -1.2883e-02,\n",
       "                       5.9154e-02,  1.1512e-02, -7.2364e-03,  4.1261e-02, -2.6351e-03,\n",
       "                      -3.3032e-03,  3.3423e-02, -1.7533e-02, -1.6128e-02, -5.7894e-03,\n",
       "                      -1.4025e-02,  2.8735e-02, -2.5581e-02,  1.1237e-02, -3.9039e-02,\n",
       "                      -3.7581e-02, -1.1970e-02, -1.2555e-02,  1.9434e-02, -2.8948e-03,\n",
       "                      -2.3720e-02,  2.3603e-03, -2.1667e-02,  7.3620e-03,  6.9243e-03,\n",
       "                      -2.9235e-02, -6.6256e-03,  5.0314e-03, -4.4027e-02, -1.1383e-02,\n",
       "                      -8.4184e-03,  5.0313e-03, -2.0207e-02, -4.1501e-03,  2.3522e-02,\n",
       "                       8.4851e-03, -2.2156e-03, -2.1147e-03,  5.7881e-02, -1.9192e-02,\n",
       "                      -1.7235e-02, -1.0253e-03,  1.4571e-02, -3.1924e-02,  1.9331e-02,\n",
       "                       2.0114e-02, -8.6965e-03,  3.2256e-02,  4.3058e-03,  5.4712e-02,\n",
       "                       1.9615e-02,  1.8704e-03,  5.2401e-02, -3.4430e-02, -8.1612e-05,\n",
       "                       5.9762e-04,  2.5525e-02, -1.6064e-02, -2.2107e-04,  5.0914e-03,\n",
       "                       1.0815e-02, -1.0005e-02, -1.7143e-02, -1.5681e-02,  8.5298e-03,\n",
       "                      -3.6848e-02,  2.3611e-03,  9.8262e-03,  2.9744e-02,  1.9323e-02,\n",
       "                      -1.6335e-02,  3.2883e-03, -1.7270e-02,  2.2763e-02,  9.8032e-03,\n",
       "                      -1.2764e-02,  4.0871e-02, -9.9673e-03, -8.9770e-03,  2.0862e-02,\n",
       "                       3.0616e-03, -1.7059e-02,  3.8725e-03, -4.2900e-02,  3.4070e-02,\n",
       "                       2.7956e-02,  1.5438e-02,  1.4472e-02, -8.1820e-03, -1.1573e-02,\n",
       "                       1.9302e-02,  3.4712e-02, -2.1957e-02,  3.6883e-02,  8.5630e-03,\n",
       "                      -2.2851e-02,  6.6175e-04,  9.5112e-04,  1.5366e-02,  7.0738e-03,\n",
       "                       1.7809e-02, -1.1229e-02, -4.7060e-04, -1.4683e-02,  8.8176e-03,\n",
       "                      -5.0882e-03, -3.6376e-03,  3.1334e-02,  2.2544e-02,  9.8405e-04,\n",
       "                      -2.3720e-03, -1.2918e-02,  1.5443e-02,  8.2233e-03,  7.1529e-03,\n",
       "                       3.2825e-02, -2.0104e-03, -1.7655e-02, -1.4801e-02,  5.4752e-03,\n",
       "                       4.5423e-03, -1.3051e-02, -3.9650e-02, -2.9016e-02, -8.5384e-03,\n",
       "                      -2.8884e-02, -3.0124e-02,  6.3246e-03, -1.5233e-02, -3.7544e-03,\n",
       "                      -1.7659e-02,  1.9056e-02, -1.4498e-03,  1.3431e-02, -1.0964e-02,\n",
       "                       4.5452e-02,  1.2764e-02, -2.1018e-02,  3.3983e-02, -3.1912e-02,\n",
       "                       3.3260e-02, -1.0320e-02,  1.0350e-02, -1.9775e-02, -4.2863e-02,\n",
       "                      -5.0495e-03,  9.6319e-03, -7.5421e-03,  1.2882e-02,  4.0134e-03,\n",
       "                       6.3385e-03, -3.0139e-03,  8.3679e-03,  4.1635e-03, -6.2613e-03,\n",
       "                       2.6277e-02, -1.4394e-02, -1.3608e-02, -7.6196e-03,  9.5283e-03,\n",
       "                       1.7422e-03,  2.5673e-03, -2.9025e-03,  2.9847e-03,  2.5024e-03,\n",
       "                       2.5046e-02, -2.5419e-03, -7.8934e-04, -2.0001e-02,  2.9911e-02,\n",
       "                      -1.8285e-02,  7.0310e-03, -1.1704e-03, -1.3317e-02,  1.7797e-02,\n",
       "                      -1.4191e-02,  1.4188e-02,  1.0172e-02,  1.6443e-02, -4.8110e-03,\n",
       "                      -1.3569e-02, -1.8782e-02,  1.6926e-02,  2.8619e-03, -3.7016e-03,\n",
       "                      -2.4370e-02], device='cuda:0')),\n",
       "             ('mlp_extractor.value_net.0.weight',\n",
       "              tensor([[ 0.0258, -0.0781,  0.1049,  ...,  0.0501, -0.0005, -0.0208],\n",
       "                      [ 0.1494,  0.0542,  0.0675,  ...,  0.0640,  0.0272,  0.0994],\n",
       "                      [-0.0923, -0.0055,  0.1079,  ...,  0.0536, -0.0654,  0.0674],\n",
       "                      ...,\n",
       "                      [ 0.0520, -0.0476,  0.0897,  ...,  0.0859,  0.0255,  0.0612],\n",
       "                      [-0.0903,  0.1567,  0.1841,  ..., -0.1402, -0.2208, -0.0551],\n",
       "                      [ 0.0460,  0.0967, -0.1723,  ..., -0.0152, -0.0825,  0.1534]],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.value_net.0.bias',\n",
       "              tensor([ 0.0073, -0.0171,  0.0155, -0.0193, -0.0133, -0.0160, -0.0482, -0.0190,\n",
       "                      -0.0075,  0.0030, -0.0123, -0.0150, -0.0414,  0.0151, -0.0232, -0.0071,\n",
       "                       0.0317, -0.0380,  0.0064, -0.0079, -0.0125,  0.0227,  0.0055,  0.0281,\n",
       "                      -0.0529,  0.0325,  0.0030, -0.0118,  0.0103, -0.0017,  0.0199, -0.0090,\n",
       "                      -0.0195, -0.0411,  0.0095,  0.0086,  0.0282, -0.0010,  0.0117,  0.0123,\n",
       "                       0.0093,  0.0220, -0.0035, -0.0292,  0.0189, -0.0098, -0.0344,  0.0114,\n",
       "                      -0.0050, -0.0643, -0.0059,  0.0310,  0.0136, -0.0199,  0.0402,  0.0118,\n",
       "                      -0.0216,  0.0063,  0.0250, -0.0296,  0.0183, -0.0258, -0.0150,  0.0188,\n",
       "                       0.0134,  0.0280,  0.0019,  0.0076, -0.0032,  0.0001,  0.0159,  0.0034,\n",
       "                      -0.0075, -0.0161,  0.0066,  0.0083, -0.0256, -0.0052, -0.0293,  0.0066,\n",
       "                       0.0029,  0.0149,  0.0256,  0.0195, -0.0138, -0.0393, -0.0222, -0.0050,\n",
       "                       0.0161,  0.0128,  0.0078, -0.0042, -0.0154, -0.0137, -0.0071, -0.0200,\n",
       "                      -0.0319,  0.0311, -0.0018, -0.0017, -0.0239, -0.0181,  0.0355,  0.0221,\n",
       "                      -0.0281, -0.0100, -0.0033, -0.0069,  0.0126, -0.0165,  0.0251,  0.0010,\n",
       "                       0.0250,  0.0176, -0.0393, -0.0370, -0.0079,  0.0139, -0.0199, -0.0082,\n",
       "                       0.0288,  0.0476,  0.0187,  0.0241,  0.0296, -0.0201, -0.0502, -0.0255,\n",
       "                       0.0019,  0.0212, -0.0188, -0.0122, -0.0228,  0.0101, -0.0274, -0.0159,\n",
       "                       0.0330, -0.0052,  0.0089,  0.0152, -0.0158,  0.0064, -0.0217,  0.0302,\n",
       "                       0.0088,  0.0203,  0.0293,  0.0118, -0.0266, -0.0313,  0.0287,  0.0292,\n",
       "                       0.0227,  0.0242,  0.0089, -0.0319,  0.0309,  0.0305,  0.0053,  0.0116,\n",
       "                       0.0179, -0.0401,  0.0046,  0.0064, -0.0346,  0.0299, -0.0042, -0.0296,\n",
       "                       0.0248,  0.0164,  0.0080,  0.0439, -0.0256, -0.0213,  0.0053,  0.0067,\n",
       "                       0.0025, -0.0117, -0.0139, -0.0202,  0.0104, -0.0056,  0.0295,  0.0389,\n",
       "                       0.0347, -0.0263,  0.0114, -0.0407,  0.0029,  0.0330, -0.0109,  0.0093,\n",
       "                       0.0185, -0.0436, -0.0021,  0.0105,  0.0289,  0.0050,  0.0291, -0.0307,\n",
       "                      -0.0111,  0.0218,  0.0322, -0.0216, -0.0034,  0.0108,  0.0139,  0.0242,\n",
       "                      -0.0039, -0.0260,  0.0204, -0.0051, -0.0184, -0.0102, -0.0113, -0.0258,\n",
       "                      -0.0226,  0.0083,  0.0291,  0.0410, -0.0232, -0.0176, -0.0105, -0.0313,\n",
       "                       0.0339,  0.0156, -0.0041,  0.0539, -0.0181, -0.0149,  0.0247,  0.0223,\n",
       "                       0.0065, -0.0142,  0.0087,  0.0416, -0.0010, -0.0007, -0.0284,  0.0091,\n",
       "                      -0.0299, -0.0273, -0.0013,  0.0311,  0.0177,  0.0006, -0.0274,  0.0434,\n",
       "                       0.0060,  0.0048, -0.0065,  0.0375,  0.0143, -0.0056,  0.0025,  0.0400],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.value_net.2.weight',\n",
       "              tensor([[ 0.1031, -0.0784,  0.1225,  ...,  0.0166, -0.0647,  0.0448],\n",
       "                      [-0.0746, -0.2045,  0.0213,  ...,  0.0200,  0.0301,  0.0594],\n",
       "                      [-0.0485,  0.1501, -0.0747,  ..., -0.0354, -0.0677,  0.0100],\n",
       "                      ...,\n",
       "                      [ 0.3010, -0.0592, -0.0250,  ..., -0.1353, -0.0817, -0.0257],\n",
       "                      [ 0.0583, -0.0296, -0.0965,  ...,  0.1907,  0.0751, -0.0286],\n",
       "                      [-0.0687,  0.1230,  0.0270,  ...,  0.0339,  0.0858, -0.0454]],\n",
       "                     device='cuda:0')),\n",
       "             ('mlp_extractor.value_net.2.bias',\n",
       "              tensor([ 3.5799e-03,  3.5292e-03, -1.9715e-02, -1.0328e-02,  1.7350e-02,\n",
       "                      -1.7284e-02,  9.3694e-04, -1.8285e-02, -6.7587e-03,  3.6638e-03,\n",
       "                      -1.4437e-02,  1.9942e-02, -2.1250e-02, -2.2902e-02,  2.3250e-02,\n",
       "                      -9.0199e-03, -2.0914e-02,  1.6462e-02,  1.6864e-02,  1.6971e-02,\n",
       "                       1.0805e-02,  9.4597e-03,  6.0784e-04, -3.4437e-03, -1.5691e-02,\n",
       "                       1.0027e-03,  1.3647e-02, -5.8386e-03, -1.6246e-02,  1.9832e-02,\n",
       "                       1.8696e-02, -1.8948e-02, -6.1973e-03,  1.1848e-02,  1.3520e-02,\n",
       "                      -5.1360e-03, -1.0215e-02,  1.6143e-02,  1.0493e-02,  9.4610e-03,\n",
       "                      -2.1828e-02,  1.2389e-02, -2.3929e-02, -1.5668e-02, -5.4613e-04,\n",
       "                       9.8429e-03, -4.7456e-03,  1.1693e-02,  1.6548e-02, -2.3037e-02,\n",
       "                       6.6384e-04, -2.4440e-03,  1.8023e-02, -1.5377e-02,  2.9876e-03,\n",
       "                       1.4220e-02, -6.3246e-03,  6.4127e-03,  2.1948e-02,  1.6072e-02,\n",
       "                      -3.6497e-03,  7.4768e-03,  1.9767e-02, -1.7684e-02, -5.7277e-03,\n",
       "                      -5.6413e-03, -1.7375e-02,  1.5375e-02,  1.7958e-02, -1.6137e-02,\n",
       "                      -1.2186e-02,  1.5668e-05,  2.5710e-03, -6.8798e-03, -1.8157e-02,\n",
       "                      -1.4367e-02, -6.2862e-03, -1.1924e-02, -1.5660e-02,  1.9036e-02,\n",
       "                      -2.3311e-02,  9.5750e-03, -1.9810e-02,  2.0722e-02,  6.2475e-04,\n",
       "                      -1.5477e-02,  1.1501e-02, -1.0731e-02,  2.7525e-03, -8.3308e-03,\n",
       "                      -2.5942e-02, -1.4650e-03, -8.8326e-03,  2.0180e-03, -7.1282e-03,\n",
       "                       4.4672e-03,  4.1499e-03,  1.4123e-02, -3.6176e-03,  1.8223e-02,\n",
       "                       2.1647e-03,  6.9139e-03,  1.0047e-03, -4.0867e-03,  1.2341e-02,\n",
       "                      -7.2736e-03,  2.3376e-02,  1.7278e-02,  6.8736e-04, -1.8320e-02,\n",
       "                       1.3428e-02, -1.5306e-02,  2.0008e-02,  1.6215e-06,  1.6775e-02,\n",
       "                      -1.5133e-02, -1.3126e-02, -1.2041e-02,  1.5071e-02, -1.9596e-02,\n",
       "                      -2.3280e-02,  1.5094e-02, -2.1058e-02,  2.0434e-02, -1.8828e-03,\n",
       "                      -5.4423e-03, -2.1646e-02,  5.7857e-03,  2.1414e-02,  1.6875e-03,\n",
       "                       2.2360e-02, -2.1373e-02, -9.8489e-03,  1.6259e-02,  1.7101e-02,\n",
       "                      -2.2432e-02,  1.9357e-02, -1.9886e-02, -2.0919e-02, -1.9031e-02,\n",
       "                      -1.6509e-03, -1.6547e-03,  1.5982e-02,  5.1847e-03,  1.9170e-02,\n",
       "                       1.7896e-02,  2.4410e-03,  1.1951e-02, -2.4551e-02,  1.6849e-02,\n",
       "                      -1.9074e-02, -2.2394e-02, -2.1093e-02,  2.0049e-02, -1.7392e-02,\n",
       "                       2.3051e-02, -1.7531e-02,  4.6713e-04, -3.2929e-03,  3.0393e-03,\n",
       "                       1.0845e-02, -2.2677e-02, -1.7766e-02, -5.2143e-03, -1.9969e-02,\n",
       "                      -2.1128e-02, -1.7207e-02,  3.5592e-03,  3.8090e-03,  1.3139e-02,\n",
       "                      -2.2284e-02,  1.3133e-02, -1.9177e-03, -1.9009e-02, -2.1424e-02,\n",
       "                       1.5563e-03,  1.4668e-02, -2.0922e-02, -2.2657e-03,  2.2310e-02,\n",
       "                      -1.1378e-02, -2.0817e-02,  6.2105e-04,  1.2367e-02, -4.5331e-03,\n",
       "                       1.0558e-02,  5.1795e-03, -2.2744e-02,  1.8500e-02, -2.2728e-02,\n",
       "                      -1.8266e-02,  4.4167e-03,  2.2934e-02, -1.0485e-02, -1.5243e-02,\n",
       "                      -3.7956e-03, -1.3557e-02, -1.7258e-02,  2.4479e-02, -2.1338e-02,\n",
       "                      -1.9147e-02,  2.0108e-02,  6.1759e-03,  8.7468e-03, -3.2058e-03,\n",
       "                       1.2333e-02, -2.0609e-02, -3.1282e-03, -2.4115e-03, -1.0368e-02,\n",
       "                      -1.8686e-02, -9.9143e-03, -1.2893e-02, -7.8900e-03, -1.9347e-02,\n",
       "                       2.9915e-03,  1.7967e-02, -1.4676e-02,  2.0105e-02, -5.5169e-03,\n",
       "                       1.9404e-02,  2.3219e-02,  1.8098e-02, -5.3687e-03, -5.9559e-03,\n",
       "                      -4.4813e-03, -1.5034e-03, -1.3383e-02,  1.9927e-02, -3.6679e-03,\n",
       "                       1.7204e-02, -5.4026e-03,  1.2775e-02,  2.2480e-03, -4.0149e-03,\n",
       "                      -4.6519e-03,  2.7157e-02,  2.2412e-03, -2.5997e-03, -2.6912e-02,\n",
       "                       2.0699e-02, -1.8649e-02,  5.4057e-04,  2.2096e-02, -6.5883e-04,\n",
       "                      -8.6348e-05,  2.0106e-02,  1.8275e-02, -1.8689e-02,  3.5094e-03,\n",
       "                       1.7725e-02,  7.9392e-03, -1.5728e-03,  1.8433e-02,  5.5552e-03,\n",
       "                      -6.0163e-03], device='cuda:0')),\n",
       "             ('action_net.weight',\n",
       "              tensor([[ 0.0012,  0.0227, -0.0473,  ..., -0.0274, -0.0431,  0.0210],\n",
       "                      [ 0.0113,  0.0733, -0.0241,  ..., -0.0195,  0.0170, -0.0060],\n",
       "                      [ 0.0015, -0.0290,  0.0109,  ..., -0.0131,  0.0136,  0.0368],\n",
       "                      ...,\n",
       "                      [-0.0149,  0.0221,  0.0098,  ...,  0.0015, -0.0339,  0.0399],\n",
       "                      [ 0.0411, -0.0210,  0.0034,  ...,  0.0035, -0.0071,  0.0404],\n",
       "                      [ 0.0169, -0.0078,  0.0210,  ..., -0.0110, -0.0452, -0.0073]],\n",
       "                     device='cuda:0')),\n",
       "             ('action_net.bias',\n",
       "              tensor([ 7.1976e-03, -5.1840e-05, -1.8893e-02, -1.4768e-02, -2.1590e-02,\n",
       "                      -5.3293e-04, -2.1903e-02, -3.6274e-02, -6.4636e-03,  2.2269e-02,\n",
       "                      -1.0875e-02,  3.7804e-02, -1.9634e-02, -3.0975e-03,  7.7602e-03,\n",
       "                       2.1053e-02, -1.2791e-02,  4.7547e-02, -5.0211e-04,  3.2260e-02,\n",
       "                       2.1611e-02,  4.7714e-02,  4.0008e-02, -3.6381e-03, -1.5408e-02,\n",
       "                       2.9937e-02,  1.1037e-02, -1.4739e-02, -3.4997e-02,  3.0742e-02,\n",
       "                       1.1662e-02,  4.3333e-03, -4.1599e-04, -2.0226e-02,  3.1167e-02,\n",
       "                       4.4749e-03, -1.5468e-02,  1.3803e-02,  3.2176e-02,  1.3382e-02,\n",
       "                      -1.9587e-02,  4.2042e-03,  2.7800e-03,  3.3353e-02,  2.5322e-02,\n",
       "                       3.6295e-02, -2.6026e-03, -1.0599e-02, -2.5099e-02,  1.8091e-02,\n",
       "                       6.1407e-02,  1.6070e-02,  5.6761e-02,  4.9916e-03,  2.9991e-02,\n",
       "                      -1.8809e-02, -1.3155e-03,  1.8749e-03, -1.5828e-02, -5.5678e-03,\n",
       "                      -2.2151e-02, -1.0909e-02, -5.0003e-02, -1.3498e-02], device='cuda:0')),\n",
       "             ('value_net.weight',\n",
       "              tensor([[-3.3037e-03,  5.3284e-03, -9.3936e-02,  9.3759e-02, -7.8912e-02,\n",
       "                        1.7651e-02, -3.1864e-03,  1.4838e-02,  3.6118e-02, -2.1965e-03,\n",
       "                       -1.8197e-02, -1.1277e-01,  3.9909e-02,  1.2386e-01,  7.8707e-02,\n",
       "                        4.8020e-02, -5.5264e-02,  2.9150e-02,  1.2501e-01,  7.0784e-02,\n",
       "                        1.1205e-01,  5.6027e-03, -5.6052e-03, -1.5464e-03, -2.6084e-02,\n",
       "                        1.8369e-02,  6.4251e-02,  5.6639e-03, -8.8315e-03, -4.6602e-02,\n",
       "                       -5.5952e-02,  1.3690e-01,  2.1227e-02,  5.3258e-02, -9.6172e-03,\n",
       "                        4.0385e-04, -1.2305e-03, -1.4693e-01,  1.1193e-01, -1.1170e-03,\n",
       "                        3.9019e-02, -2.3649e-02,  9.3961e-02, -9.2013e-02,  4.6556e-03,\n",
       "                        2.4766e-02, -1.1856e-02, -4.0379e-02, -9.1541e-03, -4.7995e-02,\n",
       "                        1.2343e-03, -1.1859e-03, -9.0648e-02, -1.1912e-01, -3.0946e-03,\n",
       "                       -4.7574e-02,  1.3759e-02, -3.0798e-03, -8.3888e-02,  3.3826e-02,\n",
       "                        2.1512e-03,  3.5112e-03, -3.0947e-02, -3.9469e-02,  1.4467e-03,\n",
       "                        5.8429e-03, -4.3625e-02, -9.0233e-03,  6.3658e-02,  1.1783e-01,\n",
       "                       -8.9585e-02, -3.9797e-03,  2.1342e-03,  1.6873e-03, -4.2570e-02,\n",
       "                        1.7917e-02, -4.5486e-04, -6.3664e-02,  3.0962e-02,  7.5418e-02,\n",
       "                       -8.5835e-02, -3.8027e-03, -5.4829e-02, -8.5183e-02,  4.9747e-03,\n",
       "                       -1.7616e-02,  3.7681e-02, -8.1497e-03, -3.2110e-02, -4.7939e-03,\n",
       "                        5.9446e-02,  1.2871e-04, -1.1236e-03,  1.0122e-04,  5.9017e-03,\n",
       "                        3.4359e-03, -2.4740e-03, -9.4853e-02, -2.3892e-03, -8.1743e-02,\n",
       "                       -1.4456e-04, -1.7734e-03,  5.2059e-03, -2.7922e-03, -1.3474e-02,\n",
       "                        3.6450e-02,  7.0219e-02,  6.5782e-02, -1.7412e-03,  4.3386e-02,\n",
       "                       -3.6895e-03, -4.2182e-02, -5.8059e-02, -2.2665e-03, -5.7482e-02,\n",
       "                       -9.4000e-03,  3.1009e-02, -6.0081e-02,  2.9139e-02,  1.0468e-01,\n",
       "                        1.1024e-01,  8.5318e-02, -6.7113e-02, -1.1693e-01,  2.0401e-03,\n",
       "                        9.4724e-03,  4.8819e-02,  7.7481e-03,  7.7007e-02, -2.4200e-03,\n",
       "                        8.8408e-02, -5.8496e-02, -5.1439e-04,  9.0237e-02,  3.7648e-02,\n",
       "                        6.7163e-02, -6.7338e-02,  1.0306e-01,  5.6972e-02,  6.1626e-02,\n",
       "                        5.8335e-03,  4.4375e-03, -7.0211e-02,  2.6161e-03,  5.2987e-02,\n",
       "                       -6.7511e-02, -2.0358e-02,  1.0349e-01,  5.6568e-02,  2.9279e-02,\n",
       "                       -7.6973e-02,  5.6301e-02,  3.8001e-02, -7.7740e-02,  2.8528e-02,\n",
       "                        5.9497e-02, -5.6108e-02, -2.2918e-03,  6.8027e-04, -4.1869e-03,\n",
       "                        1.2244e-03,  5.1292e-02,  3.3933e-02,  1.4602e-03, -4.8650e-02,\n",
       "                        1.5021e-01,  2.3874e-02,  9.1171e-04,  5.1501e-04,  3.2667e-02,\n",
       "                        6.0254e-02,  4.0823e-02,  6.8889e-04, -5.0441e-02,  2.6259e-02,\n",
       "                       -2.2578e-03, -1.6464e-01, -4.4331e-02,  1.3884e-03, -8.8885e-02,\n",
       "                       -6.9349e-02,  1.5955e-01,  5.2212e-03,  3.4174e-02, -1.0216e-02,\n",
       "                       -4.7145e-02, -5.4640e-03,  4.1004e-02,  1.3680e-01,  3.7153e-02,\n",
       "                        1.3271e-01, -1.7563e-02, -7.9908e-02, -5.3408e-03,  6.6469e-02,\n",
       "                       -3.7583e-03, -7.7805e-02, -3.3602e-02, -8.1072e-02,  8.2813e-02,\n",
       "                       -5.8939e-02,  2.5783e-02,  5.9611e-03,  5.1634e-02, -1.8126e-03,\n",
       "                       -2.9491e-02,  6.7121e-02, -3.0367e-03, -3.8643e-03, -9.6008e-02,\n",
       "                       -1.0055e-01,  9.4307e-03,  2.6973e-02, -7.6093e-03, -3.8869e-02,\n",
       "                       -1.6433e-03, -5.9397e-02, -7.7529e-02,  5.9596e-02, -8.4991e-03,\n",
       "                        4.8007e-02, -5.4996e-02, -6.5658e-02,  1.5903e-04, -9.2767e-02,\n",
       "                        7.7916e-03,  1.5767e-04, -5.0047e-02, -3.0773e-02, -8.7600e-02,\n",
       "                        8.4599e-02,  1.3865e-03,  9.1907e-03, -1.3307e-04, -4.5890e-03,\n",
       "                        1.2302e-03, -6.6371e-02,  2.2931e-03, -3.8944e-03,  1.7272e-02,\n",
       "                       -2.2133e-02, -5.1664e-02,  5.3131e-04, -1.9438e-02,  3.2887e-02,\n",
       "                       -1.1220e-02, -4.9104e-02,  3.0505e-02,  2.3949e-02, -6.2865e-04,\n",
       "                        7.8438e-02, -3.3102e-04, -1.7982e-03, -3.1845e-02,  3.5578e-02,\n",
       "                        1.4502e-03]], device='cuda:0')),\n",
       "             ('value_net.bias', tensor([0.0009], device='cuda:0'))])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sb3_model.policy.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01be5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
